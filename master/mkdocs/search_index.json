{
    "docs": [
        {
            "location": "/index.html", 
            "text": "Introduction\n\n\nWelcome to the \nCloudbreak\n documentation!\n\n\nCloudbreak simplifies the provisioning, management, and monitoring of on-demand HDP clusters in virtual and cloud environments. It leverages cloud infrastructure to create host instances, and uses Apache Ambari via Ambari blueprints to provision and manage HDP clusters. \n\n\nCloudbreak allows you to create clusters using the Cloudbreak web UI, Cloudbreak Shell, and Cloudbreak REST API. Clusters can be launched on public cloud infrastructure platforms including \nMicrosoft Azure\n, \nAmazon Web Services (AWS)\n, and \nGoogle Cloud Platform (GCP)\n, and on the private cloud infrastructure platform \nOpenStack\n.\n\n\n    \n\n\nUse Cases\n\n\nCloudbreak allows you to create, manage, and monitor your clusters on your chosen cloud platform:\n\n\n\n\nCreate a cluster based on your chosen blueprint and specify cluster properties based on the requirements of your workloads. \n\n\nCreate ephemeral clusters to run specific workloads.\n\n\nManage and monitor your clusters using Cloudbreak UI: upscale, downscale, and when they are no longer needed, terminate them.\n\n\nEnable Kerberos and HA for your clusters. \n\n\nAutomate cluster creation using the Cloudbreak shell.  \n\n\nDevelop your application using Cloudbreak API. \n\n\n\n\nArchitecture\n\n\nRefer to \nArchitecture\n.\n\n\nGet Started\n\n\nTo get started with Cloudbreak:\n\n\n\n\nSelect the \ncloud platform\n on which you would like to launch Cloudbreak.   \n\n\nSelect the \ndeployment option\n that you would like to use. \n\n\nLaunch Cloudbreak\n. \n\n\n\n\nCloud Platforms\n\n\nYou can deploy and use Cloudbreak on the following cloud platforms:\n\n\n\n\nAmazon Web Services (AWS)\n\n\nMicrosoft Azure\n\n\nGoogle Cloud Platform (GCP)\n\n\nOpenStack\n\n\n\n\nDeployment Options\n\n\nThere are two basic deployment options:\n\n\n\n\n\n\n\n\nDeployment Option\n\n\nWhen to use\n\n\n\n\n\n\n\n\n\n\nInstantiate one of the pre-built cloud images\n\n\nThis is the recommended basic deployment option.\n The cloud images include Cloudbreak Deployer pre-installed on a CentOS VM.\n\n\n\n\n\n\nInstall the Cloudbreak Deployer on your own VM\n\n\nThis is an advanced deployment option.\n \nSelect this option if you have custom VM requirements. The supported operating systems are RHEL, CentOS, and Oracle Linux 7 (64-bit).\n\n\n\n\n\n\n\n\nLaunch Cloudbreak\n\n\nBased on the choices made, launch Cloudbreak from one of the pre-built images:  \n\n\n\n\nLaunch on AWS\n  \n\n\nLaunch on Azure\n  \n\n\nLaunch on GCP\n   \n\n\nLaunch on OpenStack\n   \n\n\n\n\nOr launch Cloudbreak \non your own VM\n on one of these cloud platforms. \n\n\nIn general, the steps include:\n\n\n\n\nMeet the prerequisites  \n\n\nLaunch Cloudbreak   \n\n\nCreate Cloudbreak credential  \n\n\nDefine infrastructure templates or use defaults \n\n\nDefine cluster blueprints or use defaults  \n\n\nCreate clusters  \n\n\nManage and monitor clusters  \n\n\n\n\n\n    \nNote\n\n    \nThe Cloudbreak software runs in your cloud environment. You are responsible for cloud infrastructure related charges while running Cloudbreak and the clusters being managed by Cloudbreak.", 
            "title": "Introduction"
        }, 
        {
            "location": "/index.html#introduction", 
            "text": "Welcome to the  Cloudbreak  documentation!  Cloudbreak simplifies the provisioning, management, and monitoring of on-demand HDP clusters in virtual and cloud environments. It leverages cloud infrastructure to create host instances, and uses Apache Ambari via Ambari blueprints to provision and manage HDP clusters.   Cloudbreak allows you to create clusters using the Cloudbreak web UI, Cloudbreak Shell, and Cloudbreak REST API. Clusters can be launched on public cloud infrastructure platforms including  Microsoft Azure ,  Amazon Web Services (AWS) , and  Google Cloud Platform (GCP) , and on the private cloud infrastructure platform  OpenStack .", 
            "title": "Introduction"
        }, 
        {
            "location": "/index.html#use-cases", 
            "text": "Cloudbreak allows you to create, manage, and monitor your clusters on your chosen cloud platform:   Create a cluster based on your chosen blueprint and specify cluster properties based on the requirements of your workloads.   Create ephemeral clusters to run specific workloads.  Manage and monitor your clusters using Cloudbreak UI: upscale, downscale, and when they are no longer needed, terminate them.  Enable Kerberos and HA for your clusters.   Automate cluster creation using the Cloudbreak shell.    Develop your application using Cloudbreak API.", 
            "title": "Use Cases"
        }, 
        {
            "location": "/index.html#architecture", 
            "text": "Refer to  Architecture .", 
            "title": "Architecture"
        }, 
        {
            "location": "/index.html#get-started", 
            "text": "To get started with Cloudbreak:   Select the  cloud platform  on which you would like to launch Cloudbreak.     Select the  deployment option  that you would like to use.   Launch Cloudbreak .", 
            "title": "Get Started"
        }, 
        {
            "location": "/index.html#cloud-platforms", 
            "text": "You can deploy and use Cloudbreak on the following cloud platforms:   Amazon Web Services (AWS)  Microsoft Azure  Google Cloud Platform (GCP)  OpenStack", 
            "title": "Cloud Platforms"
        }, 
        {
            "location": "/index.html#deployment-options", 
            "text": "There are two basic deployment options:     Deployment Option  When to use      Instantiate one of the pre-built cloud images  This is the recommended basic deployment option.  The cloud images include Cloudbreak Deployer pre-installed on a CentOS VM.    Install the Cloudbreak Deployer on your own VM  This is an advanced deployment option.   Select this option if you have custom VM requirements. The supported operating systems are RHEL, CentOS, and Oracle Linux 7 (64-bit).", 
            "title": "Deployment Options"
        }, 
        {
            "location": "/index.html#launch-cloudbreak", 
            "text": "Based on the choices made, launch Cloudbreak from one of the pre-built images:     Launch on AWS     Launch on Azure     Launch on GCP      Launch on OpenStack       Or launch Cloudbreak  on your own VM  on one of these cloud platforms.   In general, the steps include:   Meet the prerequisites    Launch Cloudbreak     Create Cloudbreak credential    Define infrastructure templates or use defaults   Define cluster blueprints or use defaults    Create clusters    Manage and monitor clusters     \n     Note \n     The Cloudbreak software runs in your cloud environment. You are responsible for cloud infrastructure related charges while running Cloudbreak and the clusters being managed by Cloudbreak.", 
            "title": "Launch Cloudbreak"
        }, 
        {
            "location": "/architecture/index.html", 
            "text": "Architecture\n\n\nCloudbreak deployer\n installs Cloudbreak components on your AWS VM. Once these components are deployed, you can use \nCloudbreak application\n to create, manage, and monitor clusters. \n\n\nCloudbreak Deployer Architecture\n\n\nCloudbreak deployer includes the following components:\n\n\n\n\n\n\n\n\nComponent\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nCloudbreak Application\n\n\nCloudbreak application is built on the foundation of cloud provider APIs and Apache Ambari.\n\n\n\n\n\n\nUluwatu\n\n\nThis is Cloudbreak web UI, which can be used to create, manage, and monitor clusters.\n\n\n\n\n\n\nCloudbreak Shell\n\n\nThis is Cloudbreak's command line tool, which can be used to create, manage, and monitor clusters.\n\n\n\n\n\n\nUAA\n\n\nThis is Cloudbreak's OAuth identity server implementation, which utilizes UAA.\n\n\n\n\n\n\nSultans\n\n\nThis is Cloudbreak's user management system.\n\n\n\n\n\n\nPeriscope\n\n\nThis is Cloudbreak's autoscaling application, which is responsible for automatically increasing or decreasing the capacity of the cluster when your pre-defined conditions are met.\n\n\n\n\n\n\n\n\n\n\nThese component names are used in Cloudbreak logs, so for troubleshooting purposes it is useful to know what they refer to.\n\n\n\n\nSystem Level Containers\n\n\nCloudbreak deployer utilizes \ncontainerization\n - also known as container-based virtualization or application containerization - which is an OS-level virtualization method for deploying and running distributed applications. \n\n\nCloudbreak deployer includes the following system-level containers:\n\n\n\n\nConsul: Cloudbreak service registry  \n\n\nRegistrator: Automatically registers/unregisters containers with consul \n\n\nDatabase: Database container for cloudbreak, autoscaling, and UAA  \n\n\nTraefik: Proxy container \n\n\n\n\nCloudbreak Application Architecture\n\n\nThe Cloudbreak application is a web application that communicates with the cloud provider account to create cloud resources on your behalf. Once the cloud resources are in place, Cloudbreak uses Apache Ambari to deploy and configure the cluster on cloud VMs. Once your cluster is deployed, you can use Cloudbreak to scale the cluster.\n\n\nCloudbreak application is built on the foundation of cloud provider APIs and Apache Ambari:\n\n\n\n\n\n\nCloudbreak uses \nApache Ambari\n to provision, manage, and monitor HDP clusters. \n\n\nAmbari \nblueprints\n are used as a declarative definition of a cluster. With a blueprint, you can specify stack, component layout, and configurations to materialize an HDP cluster instance via Ambari REST API, without having to use the Ambari cluster install wizard. \n\n\n\n\n\n\nCloudbreak uses \ncloud provider APIs\n to create cloud resources required for the HDP clusters. \n\n\nYou can define these resources via \ntemplates\n for networks, security groups, and VMs and storage in the Cloudbreak web UI. Resources are only provisioned once you create a cluster using the templates.  \n\n\n\n\n\n\nThe use of blueprints and templates is illustrated in the following image:\n\n\n \n\n\nSaltStack\n\n\nUnder the hood, Cloudbreak uses SaltStack to manage nodes of the cluster, install packages, change configuration files, and execute recipes. \nBy default Salt master is installed on the same node where Ambari server is installed.  \n\n\nCloud Resources Used\n\n\nCloubbreak and clusters deployed by it run in your cloud infrastructure. In general, Cloudbreak uses the following types of cloud resources provisioned on your cloud account:\n\n\n\n\n\n\n\n\nCategory\n\n\nDescription\n\n\nAWS\n\n\nAzure\n\n\nGCP\n\n\nOpenStack\n\n\n\n\n\n\n\n\n\n\nVMs and Storage\n\n\nCloudbreak and cluster nodes created by it run on \nVMs\n.\n\n\nAmazon EC2\n\n\nVirtual machines\n\n\nCompute Engine\n\n\n????\n\n\n\n\n\n\nNetwork and Security\n\n\nVMs run within a \nvirtual network\n and \nsubnets\n. An \nInternet gateway\n is used to enable outbound access to the Internet from the Cloudbreak instance and the cluster instances, and a route table is used to connect the subnet to the Internet gateway. \nSecurity groups\n control the inbound and outbound traffic to and from the VMs.\n\n\nAmazon VPC\n\n\nVirtual network\n\n\nVirtual Private Cloud\n\n\n????\n\n\n\n\n\n\nAccess Control\n\n\n\n\nAWS IAM\n\n\nActive Directory\n\n\nIAM\n\n\n????\n\n\n\n\n\n\nResource Management\n\n\nCloudbreak uses a designated cloud service to create and manage a collection of related AWS resources.\n\n\nAWS CloudFormation\n\n\nResource Groups\n\n\n????\n\n\n????\n\n\n\n\n\n\nCloud Storage\n\n\n\n\nAmazon S3\n\n\nADLS and \nWASB\n\n\nGoogle Cloud Storage\n\n\n????\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTO-DO: Need to get this reviewed. Is there anything else that I should mention here?", 
            "title": "Architecture"
        }, 
        {
            "location": "/architecture/index.html#architecture", 
            "text": "Cloudbreak deployer  installs Cloudbreak components on your AWS VM. Once these components are deployed, you can use  Cloudbreak application  to create, manage, and monitor clusters.", 
            "title": "Architecture"
        }, 
        {
            "location": "/architecture/index.html#cloudbreak-deployer-architecture", 
            "text": "Cloudbreak deployer includes the following components:     Component  Description      Cloudbreak Application  Cloudbreak application is built on the foundation of cloud provider APIs and Apache Ambari.    Uluwatu  This is Cloudbreak web UI, which can be used to create, manage, and monitor clusters.    Cloudbreak Shell  This is Cloudbreak's command line tool, which can be used to create, manage, and monitor clusters.    UAA  This is Cloudbreak's OAuth identity server implementation, which utilizes UAA.    Sultans  This is Cloudbreak's user management system.    Periscope  This is Cloudbreak's autoscaling application, which is responsible for automatically increasing or decreasing the capacity of the cluster when your pre-defined conditions are met.      These component names are used in Cloudbreak logs, so for troubleshooting purposes it is useful to know what they refer to.", 
            "title": "Cloudbreak Deployer Architecture"
        }, 
        {
            "location": "/architecture/index.html#system-level-containers", 
            "text": "Cloudbreak deployer utilizes  containerization  - also known as container-based virtualization or application containerization - which is an OS-level virtualization method for deploying and running distributed applications.   Cloudbreak deployer includes the following system-level containers:   Consul: Cloudbreak service registry    Registrator: Automatically registers/unregisters containers with consul   Database: Database container for cloudbreak, autoscaling, and UAA    Traefik: Proxy container", 
            "title": "System Level Containers"
        }, 
        {
            "location": "/architecture/index.html#cloudbreak-application-architecture", 
            "text": "The Cloudbreak application is a web application that communicates with the cloud provider account to create cloud resources on your behalf. Once the cloud resources are in place, Cloudbreak uses Apache Ambari to deploy and configure the cluster on cloud VMs. Once your cluster is deployed, you can use Cloudbreak to scale the cluster.  Cloudbreak application is built on the foundation of cloud provider APIs and Apache Ambari:    Cloudbreak uses  Apache Ambari  to provision, manage, and monitor HDP clusters.   Ambari  blueprints  are used as a declarative definition of a cluster. With a blueprint, you can specify stack, component layout, and configurations to materialize an HDP cluster instance via Ambari REST API, without having to use the Ambari cluster install wizard.     Cloudbreak uses  cloud provider APIs  to create cloud resources required for the HDP clusters.   You can define these resources via  templates  for networks, security groups, and VMs and storage in the Cloudbreak web UI. Resources are only provisioned once you create a cluster using the templates.      The use of blueprints and templates is illustrated in the following image:", 
            "title": "Cloudbreak Application Architecture"
        }, 
        {
            "location": "/architecture/index.html#saltstack", 
            "text": "Under the hood, Cloudbreak uses SaltStack to manage nodes of the cluster, install packages, change configuration files, and execute recipes. \nBy default Salt master is installed on the same node where Ambari server is installed.", 
            "title": "SaltStack"
        }, 
        {
            "location": "/architecture/index.html#cloud-resources-used", 
            "text": "Cloubbreak and clusters deployed by it run in your cloud infrastructure. In general, Cloudbreak uses the following types of cloud resources provisioned on your cloud account:     Category  Description  AWS  Azure  GCP  OpenStack      VMs and Storage  Cloudbreak and cluster nodes created by it run on  VMs .  Amazon EC2  Virtual machines  Compute Engine  ????    Network and Security  VMs run within a  virtual network  and  subnets . An  Internet gateway  is used to enable outbound access to the Internet from the Cloudbreak instance and the cluster instances, and a route table is used to connect the subnet to the Internet gateway.  Security groups  control the inbound and outbound traffic to and from the VMs.  Amazon VPC  Virtual network  Virtual Private Cloud  ????    Access Control   AWS IAM  Active Directory  IAM  ????    Resource Management  Cloudbreak uses a designated cloud service to create and manage a collection of related AWS resources.  AWS CloudFormation  Resource Groups  ????  ????    Cloud Storage   Amazon S3  ADLS and  WASB  Google Cloud Storage  ????         TO-DO: Need to get this reviewed. Is there anything else that I should mention here?", 
            "title": "Cloud Resources Used"
        }, 
        {
            "location": "/aws-launch/index.html", 
            "text": "Launch Cloudbreak on AWS\n\n\nMeet the Prerequisites\n\n\nBefore launching Cloudbreak on AWS, you must meet the following prerequisites.\n\n\nAWS Account\n\n\nIn order to launch Cloudbreak on Azure, you must log in to your AWS account. If you don't have an account, you can create one at \nhttps://aws.amazon.com/\n.\n\n\nAWS Region\n\n\nDecide in which AWS region you would like to launch Cloudbreak. The following AWS regions are supported: \n\n\n\n\n\n\n\n\nRegion Name\n\n\nRegion\n\n\n\n\n\n\n\n\n\n\nEU (Ireland)\n\n\neu-west-1\n\n\n\n\n\n\nEU (Frankfurt)\n\n\neu-central-1\n\n\n\n\n\n\nUS East (N. Virginia)\n\n\nus-east-1\n\n\n\n\n\n\nUS West (N. California)\n\n\nus-west-1\n\n\n\n\n\n\nUS West (Oregon)\n\n\nus-west-2\n\n\n\n\n\n\nSouth America (S\u00e3o Paulo)\n\n\nsa-east-1\n\n\n\n\n\n\nAsia Pacific (Tokyo)\n\n\nap-northeast-1\n\n\n\n\n\n\nAsia Pacific (Singapore)\n\n\nap-southeast-1\n\n\n\n\n\n\nAsia Pacific (Sydney)\n\n\nap-southeast-2\n\n\n\n\n\n\n\n\nClusters created via Cloudbreak can be in the same or different region as Cloudbreak; when you launch a cluster, you select the region in which to launch it.\n\n\nFor detailed information about AWS regions, refer to \nAWS documentation\n. \n\n\nSSH Key Pair\n\n\nImport an existing key pair or generate a new key pair in the AWS region which you are planning to use for launching Cloudbreak and clusters. You can access this option by navigating to the \nEC2 Console\n and selecting \nNETWORK AND SECURITY\n \n \nKey Pairs\n from the left pane. Refer to \nAWS documentation\n for detailed instructions on how to create a key pair in a selected region.\n\n\nYou will need this SSH key pair to SSH to the Cloudbreak instance and start Cloudbreak. \n\n\nAuthorization for Cloudbreak\n\n\nBefore you can start using Cloudbreak for provisioning clusters, you must set up authorization for Cloudbreak to connect to your AWS account and create resources on your behalf. There are two ways to do this: \n\n\n\n\n\n\nKey-based\n: This is a simpler option which does not require additional configuration at this point. It requires that you provide your AWS access key and secret key pair in the Cloudbreak web UI later.\n\n\n\n\n\n\nRole-based\n: This requires that you or your AWS admin create two IAM roles: one to grant Cloudbreak access to allow Cloudbreak to assume AWS roles (\"AssumeRole\" policy) and the second one to provide Cloudbreak with the capabilities required for cluster creation (\"cb-policy\" policy).\n\n\n\n\n\n\nOption 1: Key-based\n\n\nThis option requires your AWS access key and secret key pair. Cloudbreak will use these keys to launch the resources. If you choose this option, you must provide the access and secret keys later in the Cloudbreak web UI later when creating a credential. \n\n\nAll you need to do at this point is check your AWS account and make sure that you can access this key pair. You can generate new access and secret keys from the \nIAM Console\n \n \nUsers\n. Next, select a user and click on the \nSecurity credentials\n tab.\n\n\nOption2: Role-based\n\n\nThis requires that you create two IAM roles: one to grant Cloudbreak access to allow Cloudbreak to assume AWS roles (using the \"AssumeRole\" policy) and the second one to provide Cloudbreak with the capabilities required for cluster creation (using the \"cb-policy\" policy). You can perform these steps in the \nIAM console\n, on the \nPolicies\n page via the \nCreate Policy\n option, and on the \nRoles\n page via the \nCreate Role\n option. \n\n\n\n\n\n\nDefine a new policy called \"AssumeRole\" using the following policy definition and then create a role called \"CloudbreakRole\" and attach the \"AssumeRole\" policy to it. The \"AssumeRole\" policy definition is provided below.\n\n\n\n\n\n\nDefine another policy called \"cb-policy\" using the following policy definition and then create a new IAM role called \"CredentialRole\" and attach the \"cb-policy\" policy to it.  The \"cb-policy\" policy definition is provided below.\n\n\n\n\nAlternatively, you can generate the second role later once your VM is running by first \nconfiguring AWS CLI\n on your VM and then running the \ncbd aws generate-role\n command. This command creates a role with the name \"cbreak-deployer\" (equivalent to the \"CredentialRole\") by default.\n\n\nThis alternative method also allows you to customize the name of the role. If you'd like to create role with a different name, you must add \nexport AWS_ROLE_NAME=my-cloudbreak-role-name\n (where \"my-cloudbreak-role-name\" is your custom role name) as a new line to your Profile. \n\n\n\n\n\n\n\n\nThis is all that you need to do at this point. Here is why you need these roles:     \n\n\n\n\n\n\n\n\nRole\n\n\nPurpose\n\n\nConfiguration\n\n\n\n\n\n\n\n\n\n\nCloudbreakRole\n\n\nFor Cloudbreak to assume other IAM roles - specifically the CredentialRole\n\n\nOption 1: When launching your Cloudbreak VM, during \nStep 3: Configure Instance Details\n \n \nIAM\n, you will attach the \"CloudbreakRole\" IAM role.\n Option 2: Alternatively, instead of attaching the \"CloudbreakRole\" role during the VM launch, you can assign the \"CloudbreakRole\" to an IAM user and then add the access and security key of that user to your 'Profile'.\n\n\n\n\n\n\nCredentialRole\n\n\nFor Cloudbreak to create AWS resources required for clusters\n\n\nOnce you log in to the Cloudbreak UI and are ready to create clusters, you will use this role to create the Credential for Cloudbreak.\n\n\n\n\n\n\n\n\nFor more information about IAM, refer to \nUsing Instance Profiles\n and \nUsing an IAM Role to Grant Permissions to Applications Running on Amazon EC2 Instances\n.\n\n\nThe \"AssumeRole\" policy definition: \n\n\n{\n\u2002\u2002\"Version\": \"2012-10-17\",\n\u2002\u2002\"Statement\": [\n\u2002\u2002\u2002\u2002{\n\u2002\u2002\u2002\u2002\u2002\u2002\"Sid\": \"Stmt1400068149000\",\n\u2002\u2002\u2002\u2002\u2002\u2002\"Effect\": \"Allow\",\n\u2002\u2002\u2002\u2002\u2002\u2002\"Action\": [\n\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\"sts:AssumeRole\"\n\u2002\u2002\u2002\u2002\u2002\u2002],\n\u2002\u2002\u2002\u2002\u2002\u2002\"Resource\": [\n\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\"*\"\n\u2002\u2002\u2002\u2002\u2002\u2002]\n\u2002\u2002\u2002\u2002}\n\u2002\u2002]\n}\n\n\n\nThe \"cb-policy\" policy definition: \n\n\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Action\": [ \"cloudformation:*\" ],\n      \"Resource\": [ \"*\" ]\n    },\n    {\n      \"Effect\": \"Allow\",\n      \"Action\": [ \"ec2:*\" ],\n      \"Resource\": [ \"*\" ]\n    },\n    {\n      \"Effect\": \"Allow\",\n      \"Action\": [ \"iam:PassRole\" ],\n      \"Resource\": [ \"*\" ]\n    },\n    {\n      \"Effect\": \"Allow\",\n      \"Action\": [ \"autoscaling:*\" ],\n      \"Resource\": [ \"*\" ]\n    }\n  ]\n}\n\n\n\nLaunch the VM\n\n\nNow that you've met the prerequisites, you can launch the Cloudbreak deployer VM available as a Community AMI.\n\n\n\n\n\n\nIn the AWS Management Console, navigate to the EC2 Console.  \n\n\n\n\n\n\nIn the top right corner, select the region in which you want to launch Cloudbreak.  \n\n\n \n\n\n\n\n\n\nFrom the left pane, select \nINSTANCES\n \n \nInstances\n.  \n\n\n\n\n\n\nClick on \nLaunch Instance\n.\n\n\n\n\n\n\nIn \nStep 1: Choose an Amazon Machine Image (AMI)\n page, from the left pane, select \nCommunity AMIs\n. \n\n\n \n\n\n\n\n\n\nIn the search box, enter the image name. The following Cloudbreak deplouer images are available:\n\n\n\n\n\n\n\n\nRegion\n\n\nImage Name\n\n\n\n\n\n\n\n\n\n\neu-west-1\n\n\nami-711d0317\n\n\n\n\n\n\nsa-east-1\n\n\nami-bd365dd1\n\n\n\n\n\n\nus-east-1\n\n\nami-10a78606\n\n\n\n\n\n\nus-west-1\n\n\nami-01735e61\n\n\n\n\n\n\nus-west-2\n\n\nami-6ccbc015\n\n\n\n\n\n\neu-central-1\n\n\nami-d116b2be\n\n\n\n\n\n\nap-northeast-1\n\n\nami-97c4ccf0\n\n\n\n\n\n\nap-southeast-1\n\n\nami-d162e0b2\n\n\n\n\n\n\nap-southeast-2\n\n\nami-a7dacbc4\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTO-DO: This table should be automatically generated.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nClick \nSelect\n.  \n\n\n\n\nThe steps listed below only mention required parameters. You may optionally review and adjust additional parameters. \n\n\n\n\n\n\n\n\nIn \nStep2: Choose Instance Type\n, choose an instance type. The minimum instance type which is suitable for Cloudbreak is \nm3.large\n. Minimum requirements are 8GB RAM, 10GB disk, 2 cores. Click \nNext\n.\n\n\n   \n\n\n\n\n\n\n(Perform this step only if you are using role-based authorization) In \nStep 3: Configure Instance Details\n \n \nIAM\n, select the \"CloudbreakRole\" IAM role which you \ncreated earlier\n.\n\n\n\n\n\n\nIn \nStep 6: Configure Security Group\n, open the following ports: 22 (for access via SSH) and 443 (for access via HTTPS). Click \nReview and Launch\n.\n\n\n \n\n\n\n\n\n\nIn \nStep 7: Review Instance Launch\n, review the information carefully and then click \nLaunch\n. \n\n\n\n\n\n\nWhen prompted select an existing key pair or create a new one. Next, acknowledge that you have access to the private key file and click \nLaunch Instance\n. \n\n\n  \n\n\n\n\n\n\nClick on the instance ID to navigate to the \nInstances\n view in your EC2 console. \n\n\n  \n\n\n\n\n\n\nSSH to the VM\n\n\nNow that your VM is ready, access it via SSH: \n\n\n\n\nUse the private key from the key pair that you selected when launching the instance. \n\n\nThe SSH user is called \"cloudbreak\".\n\n\nYou can obtain the host IP from the EC2 console \n \nInstances\n view by selecting the instance, selecting the \nDescription\n tab, and copying the value of the \nPublic DNS (IPv4)\n\n or \nIPv4 Public IP\n parameter.\n\n\n\n\nLaunch Cloudbreak Deployer\n\n\nAfter accessing the VM via SSH: \n\n\n\n\n\n\nNavigate to the cloudbreak-deployment directory:\n\n\ncd /var/lib/cloudbreak-deployment/\n\n\nThis directory contains configuration files and the supporting binaries for Cloudbreak deployer.\n\n\n\n\n\n\nInitialize your profile by creating a new file called \nProfile\n and adding the following content:\n\n\nexport UAA_DEFAULT_SECRET=MY-SECRET\nexport UAA_DEFAULT_USER_PW=MY-PASSWORD\n  \n\n\nFor example: \n\n\nexport UAA_DEFAULT_SECRET=MySecret123\nexport UAA_DEFAULT_USER_PW=MySecurePassword123\n \n\n\n\n\nYou will need to provide the password when logging in to the Cloudbreak web UI and when using the Cloudbreak Shell. The secret will be used by Cloudbreak for authentication.  \n\n\n\n\n\n\n\n\nStart the Cloudbreak application by using the following command:\n\n\ncbd start\n\n\nThis will start the Docker containers and initialize the application. The first time you start the Coudbreak app, the process will take longer than usual due to the download of all the necessary docker images.\n\n\nThe \ncbd start\n command includes the \ncbd generate\n command which applies the following steps:\n\n\n\n\nCreates the \ndocker-compose.yml\n file, which describes the configuration of all the Docker containers needed for the Cloudbreak deployment.\n\n\nCreates the \nuaa.yml\n file, which holds the configuration of the identity server used to authenticate users with Cloudbreak.\n\n\n\n\n\n\nOnce the \ncbd start\n has finished, it returns the \"Uluwatu (Cloudbreak UI) url\" which you can later paste in your browser and log in to Cloudbreak web UI. \n\n\n\n\n\n\n\n\nCheck Cloudbreak deployer version and health: \n\n\ncbd doctor\n\n\n\n\n\n\nNext, check Cloudbreak Application logs: \n\n\ncbd logs cloudbreak\n\n\nYou should see a message like this in the log: \nStarted CloudbreakApplication in 36.823 seconds.\n Cloudbreak normally takes less than a minute to start.\n\n\n\n\n\n\nAccess Cloudbreak UI\n\n\n\n\n\n\nYou can log into the Cloudbreak application at \nhttps://IPv4_Public_IP\n/\n or \nhttps://Public_DNS\n. For example \nhttps://34.212.141.253\n or \nhttps://ec2-34-212-141-253.us-west-2.compute.amazonaws.com\n. \n\n\n\n\n\n\nConfirm the security exception to proceed to the Cloudbreak web UI.\n\n\nThe first time you access Cloudbreak UI, Cloudbreak will automatically generate a self-signed certificate, due to which your browser will warn you about an untrusted connection and will ask you to confirm a security exception.\n\n\n\n\n\n\nLog in to the Cloudbreak web UI: \n\n\n\n\nThe default username is \nadmin@example.com\n but you should sign up with your own email address.\n\n\nThe password is the value of the \nUAA_DEFAULT_USER_PW\n variable that you configured in your \nProfile\n file when \nlaunching Cloudbreak deployer\n.\n\n\n\n\n  \n\n\n\n\n\n\nCreate Cloudbreak Credential\n\n\nAs part of the prerequisites, you had two options to \nauthorize Cloudbreak\n to create resources on your behalf: key-based or role-based authorization. \n\n\nDepending on your earlier choice, you must configure a key-based or role-based credential. Without this credential, you will not be able to create clusters via Cloudbreak. \n\n\nCreate Key-Based Credential\n\n\nTo perform these steps, you must know your access and secret key as well as your public SSH key. If needed, you can generate new access and secret keys from the \nIAM Console\n \n \nUsers\n. Next, select a user and click on the \nSecurity credentials\n tab. \n\n\n  \n\n\n\n\n\n\nIn the Cloudbreak web UI, open the \nmanage credentials\n pane. \n\n\n\n\n\n\nClick \n+create credential\n. \n\n\n\n\n\n\nProvide the following information:\n\n\n\n\n\n\n\n\nParameter\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nSelect Credential Type\n\n\nSelect \nKey Based\n.\n\n\n\n\n\n\nName\n\n\nEnter a name for your credential.\n\n\n\n\n\n\nDescription\n\n\n(Optional) Enter a description.\n\n\n\n\n\n\nAccess Key\n\n\nPaste your access key.\n\n\n\n\n\n\nSecret Access Key\n\n\nPaste your secret key.\n\n\n\n\n\n\nSSH Public Key\n\n\nPaste your SSH public key.\n\n\n\n\n\n\nSelect Platform\n\n\n(Optional) Select a platform (if previously configured).\n\n\n\n\n\n\nPublic In Account\n\n\n(Optional) If you check this, other users added to your Cloudbreak instance will be able to use this credential to create clusters.\n\n\n\n\n\n\n\n\n\n\n\n\nClick \n+create credential\n.\n\n\n\n\n\n\nYour credential should now be displayed in the \nmanage credentials\n tab.\n\n\nCongratulations! You've successfully launched and configured Cloudbreak. Now you can use Cloudbreak to \ncreate clusters\n. \n\n\n\n\n\n\nCreate Role-Based Credential\n\n\nTo perform these steps, you must know the \nIAM Role ARN\n corresponding to the \"CredentialRole\" (configured as a \nprerequisite\n). You must also have your public SSH key. \n\n\n  \n\n\n\n\n\n\nIn the Cloudbreak web UI, open the \nmanage credentials\n pane. \n\n\n\n\n\n\nClick \n+create credential\n. \n\n\n\n\n\n\nProvide the following information:\n\n\n\n\n\n\n\n\nParameter\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nSelect Credential Type\n\n\nSelect \nRole Based\n.\n\n\n\n\n\n\nName\n\n\nEnter a name for your credential.\n\n\n\n\n\n\nDescription\n\n\n(Optional) Enter a description.\n\n\n\n\n\n\nIAM Role ARN\n\n\nPaste the \nIAM Role ARN\n corresponding to the \"CredentialRole\" that you created earlier. For example \narn:aws:iam::315627065446:role/CredentialRole\n\n\n\n\n\n\nSSH Public Key\n\n\nPaste your SSH public key.\n\n\n\n\n\n\nSelect Platform\n\n\n(Optional) Select a platform (if previously configured).\n\n\n\n\n\n\nPublic In Account\n\n\n(Optional) If you check this, other users added to your Cloudbreak instance will be able to use this credential to create clusters.\n\n\n\n\n\n\n\n\n\n\n\n\nClick \n+create credential\n.\n\n\n\n\n\n\nYour credential should now be displayed in the \nmanage credentials\n tab.\n\n\nCongratulations! You've successfully launched and configured Cloudbreak.\n\n\n\n\n\n\n\n\nNext: Define Infrastructure Templates", 
            "title": "Launch on AWS"
        }, 
        {
            "location": "/aws-launch/index.html#launch-cloudbreak-on-aws", 
            "text": "", 
            "title": "Launch Cloudbreak on AWS"
        }, 
        {
            "location": "/aws-launch/index.html#meet-the-prerequisites", 
            "text": "Before launching Cloudbreak on AWS, you must meet the following prerequisites.", 
            "title": "Meet the Prerequisites"
        }, 
        {
            "location": "/aws-launch/index.html#aws-account", 
            "text": "In order to launch Cloudbreak on Azure, you must log in to your AWS account. If you don't have an account, you can create one at  https://aws.amazon.com/ .", 
            "title": "AWS Account"
        }, 
        {
            "location": "/aws-launch/index.html#aws-region", 
            "text": "Decide in which AWS region you would like to launch Cloudbreak. The following AWS regions are supported:      Region Name  Region      EU (Ireland)  eu-west-1    EU (Frankfurt)  eu-central-1    US East (N. Virginia)  us-east-1    US West (N. California)  us-west-1    US West (Oregon)  us-west-2    South America (S\u00e3o Paulo)  sa-east-1    Asia Pacific (Tokyo)  ap-northeast-1    Asia Pacific (Singapore)  ap-southeast-1    Asia Pacific (Sydney)  ap-southeast-2     Clusters created via Cloudbreak can be in the same or different region as Cloudbreak; when you launch a cluster, you select the region in which to launch it.  For detailed information about AWS regions, refer to  AWS documentation .", 
            "title": "AWS Region"
        }, 
        {
            "location": "/aws-launch/index.html#ssh-key-pair", 
            "text": "Import an existing key pair or generate a new key pair in the AWS region which you are planning to use for launching Cloudbreak and clusters. You can access this option by navigating to the  EC2 Console  and selecting  NETWORK AND SECURITY     Key Pairs  from the left pane. Refer to  AWS documentation  for detailed instructions on how to create a key pair in a selected region.  You will need this SSH key pair to SSH to the Cloudbreak instance and start Cloudbreak.", 
            "title": "SSH Key Pair"
        }, 
        {
            "location": "/aws-launch/index.html#authorization-for-cloudbreak", 
            "text": "Before you can start using Cloudbreak for provisioning clusters, you must set up authorization for Cloudbreak to connect to your AWS account and create resources on your behalf. There are two ways to do this:     Key-based : This is a simpler option which does not require additional configuration at this point. It requires that you provide your AWS access key and secret key pair in the Cloudbreak web UI later.    Role-based : This requires that you or your AWS admin create two IAM roles: one to grant Cloudbreak access to allow Cloudbreak to assume AWS roles (\"AssumeRole\" policy) and the second one to provide Cloudbreak with the capabilities required for cluster creation (\"cb-policy\" policy).    Option 1: Key-based  This option requires your AWS access key and secret key pair. Cloudbreak will use these keys to launch the resources. If you choose this option, you must provide the access and secret keys later in the Cloudbreak web UI later when creating a credential.   All you need to do at this point is check your AWS account and make sure that you can access this key pair. You can generate new access and secret keys from the  IAM Console     Users . Next, select a user and click on the  Security credentials  tab.  Option2: Role-based  This requires that you create two IAM roles: one to grant Cloudbreak access to allow Cloudbreak to assume AWS roles (using the \"AssumeRole\" policy) and the second one to provide Cloudbreak with the capabilities required for cluster creation (using the \"cb-policy\" policy). You can perform these steps in the  IAM console , on the  Policies  page via the  Create Policy  option, and on the  Roles  page via the  Create Role  option.     Define a new policy called \"AssumeRole\" using the following policy definition and then create a role called \"CloudbreakRole\" and attach the \"AssumeRole\" policy to it. The \"AssumeRole\" policy definition is provided below.    Define another policy called \"cb-policy\" using the following policy definition and then create a new IAM role called \"CredentialRole\" and attach the \"cb-policy\" policy to it.  The \"cb-policy\" policy definition is provided below.   Alternatively, you can generate the second role later once your VM is running by first  configuring AWS CLI  on your VM and then running the  cbd aws generate-role  command. This command creates a role with the name \"cbreak-deployer\" (equivalent to the \"CredentialRole\") by default.  This alternative method also allows you to customize the name of the role. If you'd like to create role with a different name, you must add  export AWS_ROLE_NAME=my-cloudbreak-role-name  (where \"my-cloudbreak-role-name\" is your custom role name) as a new line to your Profile.      This is all that you need to do at this point. Here is why you need these roles:          Role  Purpose  Configuration      CloudbreakRole  For Cloudbreak to assume other IAM roles - specifically the CredentialRole  Option 1: When launching your Cloudbreak VM, during  Step 3: Configure Instance Details     IAM , you will attach the \"CloudbreakRole\" IAM role.  Option 2: Alternatively, instead of attaching the \"CloudbreakRole\" role during the VM launch, you can assign the \"CloudbreakRole\" to an IAM user and then add the access and security key of that user to your 'Profile'.    CredentialRole  For Cloudbreak to create AWS resources required for clusters  Once you log in to the Cloudbreak UI and are ready to create clusters, you will use this role to create the Credential for Cloudbreak.     For more information about IAM, refer to  Using Instance Profiles  and  Using an IAM Role to Grant Permissions to Applications Running on Amazon EC2 Instances .  The \"AssumeRole\" policy definition:   {\n\u2002\u2002\"Version\": \"2012-10-17\",\n\u2002\u2002\"Statement\": [\n\u2002\u2002\u2002\u2002{\n\u2002\u2002\u2002\u2002\u2002\u2002\"Sid\": \"Stmt1400068149000\",\n\u2002\u2002\u2002\u2002\u2002\u2002\"Effect\": \"Allow\",\n\u2002\u2002\u2002\u2002\u2002\u2002\"Action\": [\n\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\"sts:AssumeRole\"\n\u2002\u2002\u2002\u2002\u2002\u2002],\n\u2002\u2002\u2002\u2002\u2002\u2002\"Resource\": [\n\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\"*\"\n\u2002\u2002\u2002\u2002\u2002\u2002]\n\u2002\u2002\u2002\u2002}\n\u2002\u2002]\n}  The \"cb-policy\" policy definition:   {\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Action\": [ \"cloudformation:*\" ],\n      \"Resource\": [ \"*\" ]\n    },\n    {\n      \"Effect\": \"Allow\",\n      \"Action\": [ \"ec2:*\" ],\n      \"Resource\": [ \"*\" ]\n    },\n    {\n      \"Effect\": \"Allow\",\n      \"Action\": [ \"iam:PassRole\" ],\n      \"Resource\": [ \"*\" ]\n    },\n    {\n      \"Effect\": \"Allow\",\n      \"Action\": [ \"autoscaling:*\" ],\n      \"Resource\": [ \"*\" ]\n    }\n  ]\n}", 
            "title": "Authorization for Cloudbreak"
        }, 
        {
            "location": "/aws-launch/index.html#launch-the-vm", 
            "text": "Now that you've met the prerequisites, you can launch the Cloudbreak deployer VM available as a Community AMI.    In the AWS Management Console, navigate to the EC2 Console.      In the top right corner, select the region in which you want to launch Cloudbreak.         From the left pane, select  INSTANCES     Instances .      Click on  Launch Instance .    In  Step 1: Choose an Amazon Machine Image (AMI)  page, from the left pane, select  Community AMIs .        In the search box, enter the image name. The following Cloudbreak deplouer images are available:     Region  Image Name      eu-west-1  ami-711d0317    sa-east-1  ami-bd365dd1    us-east-1  ami-10a78606    us-west-1  ami-01735e61    us-west-2  ami-6ccbc015    eu-central-1  ami-d116b2be    ap-northeast-1  ami-97c4ccf0    ap-southeast-1  ami-d162e0b2    ap-southeast-2  ami-a7dacbc4         TO-DO: This table should be automatically generated.        Click  Select .     The steps listed below only mention required parameters. You may optionally review and adjust additional parameters.      In  Step2: Choose Instance Type , choose an instance type. The minimum instance type which is suitable for Cloudbreak is  m3.large . Minimum requirements are 8GB RAM, 10GB disk, 2 cores. Click  Next .         (Perform this step only if you are using role-based authorization) In  Step 3: Configure Instance Details     IAM , select the \"CloudbreakRole\" IAM role which you  created earlier .    In  Step 6: Configure Security Group , open the following ports: 22 (for access via SSH) and 443 (for access via HTTPS). Click  Review and Launch .       In  Step 7: Review Instance Launch , review the information carefully and then click  Launch .     When prompted select an existing key pair or create a new one. Next, acknowledge that you have access to the private key file and click  Launch Instance .         Click on the instance ID to navigate to the  Instances  view in your EC2 console.", 
            "title": "Launch the VM"
        }, 
        {
            "location": "/aws-launch/index.html#ssh-to-the-vm", 
            "text": "Now that your VM is ready, access it via SSH:    Use the private key from the key pair that you selected when launching the instance.   The SSH user is called \"cloudbreak\".  You can obtain the host IP from the EC2 console    Instances  view by selecting the instance, selecting the  Description  tab, and copying the value of the  Public DNS (IPv4)  or  IPv4 Public IP  parameter.", 
            "title": "SSH to the VM"
        }, 
        {
            "location": "/aws-launch/index.html#launch-cloudbreak-deployer", 
            "text": "After accessing the VM via SSH:     Navigate to the cloudbreak-deployment directory:  cd /var/lib/cloudbreak-deployment/  This directory contains configuration files and the supporting binaries for Cloudbreak deployer.    Initialize your profile by creating a new file called  Profile  and adding the following content:  export UAA_DEFAULT_SECRET=MY-SECRET\nexport UAA_DEFAULT_USER_PW=MY-PASSWORD     For example:   export UAA_DEFAULT_SECRET=MySecret123\nexport UAA_DEFAULT_USER_PW=MySecurePassword123     You will need to provide the password when logging in to the Cloudbreak web UI and when using the Cloudbreak Shell. The secret will be used by Cloudbreak for authentication.       Start the Cloudbreak application by using the following command:  cbd start  This will start the Docker containers and initialize the application. The first time you start the Coudbreak app, the process will take longer than usual due to the download of all the necessary docker images.  The  cbd start  command includes the  cbd generate  command which applies the following steps:   Creates the  docker-compose.yml  file, which describes the configuration of all the Docker containers needed for the Cloudbreak deployment.  Creates the  uaa.yml  file, which holds the configuration of the identity server used to authenticate users with Cloudbreak.    Once the  cbd start  has finished, it returns the \"Uluwatu (Cloudbreak UI) url\" which you can later paste in your browser and log in to Cloudbreak web UI.      Check Cloudbreak deployer version and health:   cbd doctor    Next, check Cloudbreak Application logs:   cbd logs cloudbreak  You should see a message like this in the log:  Started CloudbreakApplication in 36.823 seconds.  Cloudbreak normally takes less than a minute to start.", 
            "title": "Launch Cloudbreak Deployer"
        }, 
        {
            "location": "/aws-launch/index.html#access-cloudbreak-ui", 
            "text": "You can log into the Cloudbreak application at  https://IPv4_Public_IP /  or  https://Public_DNS . For example  https://34.212.141.253  or  https://ec2-34-212-141-253.us-west-2.compute.amazonaws.com .     Confirm the security exception to proceed to the Cloudbreak web UI.  The first time you access Cloudbreak UI, Cloudbreak will automatically generate a self-signed certificate, due to which your browser will warn you about an untrusted connection and will ask you to confirm a security exception.    Log in to the Cloudbreak web UI:    The default username is  admin@example.com  but you should sign up with your own email address.  The password is the value of the  UAA_DEFAULT_USER_PW  variable that you configured in your  Profile  file when  launching Cloudbreak deployer .", 
            "title": "Access Cloudbreak UI"
        }, 
        {
            "location": "/aws-launch/index.html#create-cloudbreak-credential", 
            "text": "As part of the prerequisites, you had two options to  authorize Cloudbreak  to create resources on your behalf: key-based or role-based authorization.   Depending on your earlier choice, you must configure a key-based or role-based credential. Without this credential, you will not be able to create clusters via Cloudbreak.", 
            "title": "Create Cloudbreak Credential"
        }, 
        {
            "location": "/aws-launch/index.html#create-key-based-credential", 
            "text": "To perform these steps, you must know your access and secret key as well as your public SSH key. If needed, you can generate new access and secret keys from the  IAM Console     Users . Next, select a user and click on the  Security credentials  tab.         In the Cloudbreak web UI, open the  manage credentials  pane.     Click  +create credential .     Provide the following information:     Parameter  Description      Select Credential Type  Select  Key Based .    Name  Enter a name for your credential.    Description  (Optional) Enter a description.    Access Key  Paste your access key.    Secret Access Key  Paste your secret key.    SSH Public Key  Paste your SSH public key.    Select Platform  (Optional) Select a platform (if previously configured).    Public In Account  (Optional) If you check this, other users added to your Cloudbreak instance will be able to use this credential to create clusters.       Click  +create credential .    Your credential should now be displayed in the  manage credentials  tab.  Congratulations! You've successfully launched and configured Cloudbreak. Now you can use Cloudbreak to  create clusters .", 
            "title": "Create Key-Based Credential"
        }, 
        {
            "location": "/aws-launch/index.html#create-role-based-credential", 
            "text": "To perform these steps, you must know the  IAM Role ARN  corresponding to the \"CredentialRole\" (configured as a  prerequisite ). You must also have your public SSH key.         In the Cloudbreak web UI, open the  manage credentials  pane.     Click  +create credential .     Provide the following information:     Parameter  Description      Select Credential Type  Select  Role Based .    Name  Enter a name for your credential.    Description  (Optional) Enter a description.    IAM Role ARN  Paste the  IAM Role ARN  corresponding to the \"CredentialRole\" that you created earlier. For example  arn:aws:iam::315627065446:role/CredentialRole    SSH Public Key  Paste your SSH public key.    Select Platform  (Optional) Select a platform (if previously configured).    Public In Account  (Optional) If you check this, other users added to your Cloudbreak instance will be able to use this credential to create clusters.       Click  +create credential .    Your credential should now be displayed in the  manage credentials  tab.  Congratulations! You've successfully launched and configured Cloudbreak.     Next: Define Infrastructure Templates", 
            "title": "Create Role-Based Credential"
        }, 
        {
            "location": "/aws-config/index.html", 
            "text": "Define Infrastructure Templates\n\n\nAfter you've logged in to Cloudbreak and created a Cloudbreak credential, you have two options:\n\n\n\n\nCreate clusters using default infrastructure templates      \n\n\nDefine your own infrastructure templates   \n\n\n\n\nThe \ninfrastructure templates\n for resources such as \nnetworks\n, \nsecurity groups\n, and \nVMs and storage\n are saved to Cloudbreak's database and can be reused with multiple clusters to describe the infrastructure. When you add these resources in Cloudbreak web UI, Cloudbreak does not make any requests to your cloud provider account. Resources are only created on your cloud provider account after the create cluster button has been pushed. \n\n\nThis is illustrated and further explained in the \nArchitecture\n documentation.\n\n\nWe recommend that you review the default infrastructure  templates for networks, security groups, and VMs and storage to check if they meet your requirements. You can do this by expanding  their corresponding panes in the Cloudbreak web UI (shown in the screenshot) or by reading the documentation below.  \n\n\n \n\n\nThe following table describes the basic configurations that require an infrastructure template. If the default infrastructure templates don't work for you, you must create custom templates.\n\n\n\n\n\n\n\n\nConfiguration\n\n\nDescription\n\n\nCreate Cluster\n\n\n\n\n\n\n\n\n\n\nNetworks\n\n\n(Required) Virtual networks provide the networking infrastructure (network, subnet, Internet gateway, and so on) in which your clusters run. A virtual network on AWS is called Amazon Virtual Private Cloud (Amazon VPC). You can create new virtual networks or reuse existing virtual networks for your clusters. For basic information about VPCs and subnets on AWS, refer to \nAWS documentation\n.\n\n\nYou can select the network configuration for your clusters in the \nCreate Cluster\n wizard \n \nSet up Network and Security\n page.\n\n\n\n\n\n\nSecurity Groups\n\n\n(Required) Security groups include rules which define inbound traffic allowed to the instances in your cluster. You can define different security group configurations for different nodes of your cluster. For basic information about security groups on AWS, refer to \nAWS documentation\n.\n\n\nYou can select the security group configurations for each host group in the \nCreate Cluster\n wizard \n \nChoose Blueprint\n page. If no custom security groups are selected, default is used.\n\n\n\n\n\n\nVMs and Storage\n\n\n(Required) \"Templates\" define the AWS infrastructure for the instances on which your cluster runs. You can select the EC2 instance types and their attached storage, including storage type, size, count, and encryption settings. You can reuse the same template for different cluster host groups or create different templates for different host groups.\n\n\nYou can select a template for each host group in the \nCreate Cluster\n wizard \n \nChoose Blueprint\n page. If no custom templates are selected, default is used.\n\n\n\n\n\n\n\n\nNetworks\n\n\nYou have four options:\n\n\n\n\nUse the default network configuration template\n: This requires no further action. Every time a cluster is created with this kind of network setup a new VPC and a new subnet with the specified IP range will be created for the instances on AWS.  \n\n\nCreate a new VPC and a new subnet\n: Every time a cluster is created with this kind of network setup a new VPC and a new subnet with the specified IP range will be created for the instances on AWS.  \n\n\nCreate a new subnet in an existing VPC\n: Use this option if you already have a VPC on AWS where you'd like to put the cluster but you'd like to have a separate subnet for it. This setup is only supported for basic VPCs, where an Internet Gateway is configured and instances have public IP addresses to access the Internet.        \n\n\nUse an existing subnet in an existing VPC\n: Use this option (1) If you have an existing VPC with one or more subnets on AWS and you'd like to start the cluster in one (or more) of these subnets. (2) If you have a custom VPC setup (VGW, NAT, private subnets, and so on).  In this setup, instances in the subnet don't need to have public IP addresses. If using multiple subnets, the subnets can be in different availability zones.    \n\n\n\n\nIf you are planning to use an existing VPC, consider these restrictions:\n\n\n\n\nThe subnet CIDRs cannot overlap in a VPC. Make sure that the new subnets that you define don't overlap with already deployed subnets in that VPC.  \n\n\nSince subnet CIDRs cannot overlap in a VPC, if you want to launch multiple clusters in the same VPC, you must create a different network template for each cluster. For example, you can create three different clusters with three different network templates for multiple subnets (\n10.0.0.0/24\n, \n10.0.1.0/24\n, \n10.0.2.0/24\n respectively) with the same VPC and IGW identifiers.  \n\n\n\n\nIf using an existing subnet, consider these restrictions: \n\n\n\n\nBefore using an existing subnet, make sure you have enough room within your network space for the new instances.   \n\n\nInstances in the subnet must be able to reach the Internet to download yum packages (this can be done through a Virtual Gateway, a NAT instance, an Internet Gateway, or by other means).  \n\n\nThe VM on which Cloudbreak is deployed must be able to reach the instances in the cluster on port 443, either by being in the same subnet or through a router from another subnet.  \n\n\n\n\nDefault Network\n\n\nCloudbreak includes one pre-defined network configuration called \ndefault-aws-network\n, which is used by default when creating a cluster.  You can see it in the \nmanage networks\n tab. The configuration is: \n\n\n\n\n\n\n\n\nParameter\n\n\nValue\n\n\n\n\n\n\n\n\n\n\nName\n\n\ndefault-aws-network\n\n\n\n\n\n\nDescription\n\n\nDefault network settings for AWS clusters.\n\n\n\n\n\n\nSubnet (CIDR)\n\n\n10.0.0.0/16\n\n\n\n\n\n\n\n\nWith this default configuration, a new VPC with a 10.0.0.0/16 subnet will be created every time a cluster is created. No resources will be created until you create a cluster using this configuration.\n\n\nAdd New VPC and Subnet\n\n\nYou can define reusable network configurations for your clusters in the \nmanage networks\n tab:\n\n\n\n\n\n\nClick on \nCreate a new VPC and a new subnet\n.\n\n\n\n\n\n\nProvide required parameters:\n\n\n\n\n\n\n\n\nParameter\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nName\n\n\nEnter a name for your configuration.\n\n\n\n\n\n\nDescription\n\n\n(Optional) Enter a description.\n\n\n\n\n\n\nSubnet (CIDR)\n\n\nEnter a valid \nCIDR\n for a new subnet that will be created within the VPC. For example \n10.0.0.0/24\n.\n\n\n\n\n\n\nPublic In Account\n\n\n(Optional) If this option is checked, all the users belonging to your account will be able to use this network template to create clusters, but they cannot delete it.\n\n\n\n\n\n\nSelect Platform\n\n\n(Optional) Select a previously created platform.\n\n\n\n\n\n\n\n\n\n\n\n\nClick on \n+create network\n.\n\n\nNo resources will be created until you create a cluster using this configuration.\n\n\n\n\n\n\nAdd New Subnet in Existing VPC\n\n\nYou can define reusable network configurations for your clusters in the \nmanage networks\n tab:\n\n\n\n\n\n\nClick on \nCreate a new subnet in an existing VPC\n.\n\n\n\n\n\n\nProvide required parameters: \n\n\n\n\n\n\n\n\nParameter\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nName\n\n\nEnter a name for your configuration.\n\n\n\n\n\n\nDescription\n\n\n(Optional) Enter a description.\n\n\n\n\n\n\nVPC Identifier\n\n\nPaste the \"VPC ID\" of your existing VPC as it appears in your VPC Dashboard on AWS. The \"VPC ID\" should be in the format \"vpc-12345678\".\n\n\n\n\n\n\nInternet Gateway Identifier\n\n\nPaste the \"ID\" of the Internet Gateway associated with the chosen VPC as it appears in your VPC Dashboard on AWS. The \"ID\" should be in the format \"igw-12345678\".\n\n\n\n\n\n\nSubnet (CIDR)\n\n\nEnter a valid \nCIDR\n for a new subnet that will be created within the VPC. For example \n10.0.0.0/24\n.\n\n\n\n\n\n\nPublic In Account\n\n\n(Optional) If this option is checked, all the users belonging to your account will be able to use this network template to create clusters, but they cannot delete it.\n\n\n\n\n\n\nSelect Platform\n\n\n(Optional) Select a previously created platform.\n\n\n\n\n\n\n\n\n\n\n\n\nClick on \n+create network\n.\n\n\nNo resources will be created until you create a cluster using this configuration.\n\n\n\n\n\n\nUse Existing VPC and Subnet\n\n\nYou can define reusable network configurations for your clusters in the \nmanage networks\n tab:\n\n\n\n\n\n\nClick on \nUse an existing subnet in an existing VPC\n. \n\n\n\n\n\n\nProvide required parameters: \n\n\n\n\n\n\n\n\nParameter\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nName\n\n\nEnter a name for your configuration.\n\n\n\n\n\n\nDescription\n\n\n(Optional) Enter a description.\n\n\n\n\n\n\nVPC Identifier\n\n\nPaste the \"VPC ID\" of your existing VPC as it appears in your VPC Dashboard on AWS. The \"VPC ID\" should be in the format \"vpc-12345678\".\n\n\n\n\n\n\nSubnet Identifier\n\n\nPaste the \"Subnet ID\" of your existing subnet as it appears in your VPC Dashboard on AWS. The subnet must be within the VPC specified above. The 'Subnet ID\" should be in the format \"subnet-12345678\". You can set a single subnet or a comma separated list of subnets.\n\n\n\n\n\n\nPublic In Account\n\n\n(Optional) If this option is checked, all the users belonging to your account will be able to use this network template to create clusters, but they cannot delete it.\n\n\n\n\n\n\nSelect Platform\n\n\n(Optional) Select a previously created platform.\n\n\n\n\n\n\n\n\n\n\n\n\nClick on \n+create network\n.\n\n\nNo resources will be created until you create a cluster using this configuration.\n\n\n\n\n\n\nSecurity Groups\n\n\nYou have three options:\n\n\n\n\nUse the default security group configuration\n: This requires no further action.  \n\n\nAdd your own custom security group configuration\n: You can define your own security group by adding the ports, protocols, and \nCIDR\n ranges that you'd like to use. The rules defined here don't need to contain the internal rules (these are automatically added by Cloudbreak to the security group on AWS).  \n\n\nCopy rules from an existing security group\n: Use this option if you have an existing security group and you'd like to apply the same rules. \n\n\n\n\nYou can define different security group configurations for different nodes of your cluster.\n\n\nDefault Security Group\n\n\nCloudbreak includes one pre-defined security group configuration called \ndefault-aws-only-ssh-and-ssl\n, which is used by default when creating a cluster. You can see it in the \nmanage security groups\n tab. The configuration is: \n\n\n\n\n\n\n\n\nCIDR\n\n\nPort\n\n\nProtocol\n\n\n\n\n\n\n\n\n\n\n0.0.0.0/0\n\n\n22\n\n\ntcp\n\n\n\n\n\n\n0.0.0.0/0\n\n\n433\n\n\ntcp\n\n\n\n\n\n\n0.0.0.0/0\n\n\n9443\n\n\ntcp\n\n\n\n\n\n\n\n\nNo resources will be created until you create a cluster using this configuration.\n\n\nAdd Custom Security Group\n\n\nYou can define reusable security group configurations for your clusters in the \nmanage security groups\n tab: \n\n\n\n\nClick on \nCreate a new security group\n.\n\n\n\n\nProvide required parameters:\n\n\n\n\n\n\n\n\nParameter\n\n\nValue\n\n\n\n\n\n\n\n\n\n\nName\n\n\nEnter a name for your security group configuration template.\n\n\n\n\n\n\nDescription\n\n\n(Optional) Enter a description.\n\n\n\n\n\n\nPublic In Account\n\n\n(Optional) If this option is checked, all the users belonging to your account will be able to use this security group template to create clusters, but they cannot delete it.\n\n\n\n\n\n\n\n\n\n\n\n\nProvide the following parameters in order to define \nSecurity Rules\n for this security group:\n\n\n\n\n\n\n\n\nParameter\n\n\nValue\n\n\n\n\n\n\n\n\n\n\nCIDR\n\n\nEnter a valid \nCIDR IP\n, from which the cluster will be accessed.\n\n\n\n\n\n\nPort\n\n\nEnter ports that you want to open. You can either list multiple ports, separated by a comma (for example \"22,443,9443\"), or you can define port ranges (for example \"1-65355\").\n\n\n\n\n\n\nProtocol\n\n\nEnter protocol that you want to use.\n\n\n\n\n\n\n\n\n\n\nPorts 22, 443, and 9443 must be open on every security group; otherwise Cloudbreak will not be able to communicate with your provisioned cluster.\n\n\n\n\n\n\n\n\nClick \n+Add Rule\n to save the security rules. If needed, click \n+Add Rule\n again to display a new \nSecurity Rules\n form and add another set of rules. \n\n\n\n\n\n\nClick \n+create security group\n to save the configuration. \n\n\nNo resources will be created until you create a cluster using this configuration.\n\n\n\n\n\n\nUse Existing Security Group\n\n\nYou can copy rules of an existing security group by using the \nUse an existing security group\n option available in the \nmanage security groups\n tab: \n\n\n\n\n\n\nClick on \nUse an existing security group\n.\n\n\n\n\n\n\nProvide required parameters:\n\n\n\n\n\n\n\n\nParameter\n\n\nValue\n\n\n\n\n\n\n\n\n\n\nName\n\n\nEnter a name for your configuration.\n\n\n\n\n\n\nDescription\n\n\n(Optional) Enter a description.\n\n\n\n\n\n\nSecurity Group Identifier\n\n\nEnter the \"Group ID\" of an existing security group whose settings you would like to reuse. The \"Group ID\" should be in the following format \"sg-12345678\".\n\n\n\n\n\n\nPublic In Account\n\n\n(Optional) If this option is checked, all the users belonging to your account will be able to use this security group to create clusters, but they cannot delete it.\n\n\n\n\n\n\n\n\n\n\nPorts 22, 443, and 9443 must be open on every security group; otherwise Cloudbreak will not be able to communicate with your provisioned cluster.\n\n\n\n\n\n\n\n\nClick \n+create security group\n to save the configuration. \n\n\nNo resources will be created until you create a cluster using this configuration. \n\n\n\n\n\n\n\n\nPorts used by Hadoop services: Ambari (8080) Consul (8500) NN (50070) RM Web (8088) Scheduler (8030RM) IPC (8050RM) Job history server (19888) HBase master (60000) HBase master web (60010) HBase RS (16020) HBase RS info (60030) Falcon (15000) Storm (8744) Hive metastore (9083) Hive server (10000) Hive server HTTP (10001) Accumulo master (9999) Accumulo Tserver (9997) Atlas (21000) KNOX (8443) Oozie (11000) Spark HS (18080) NM Web (8042) Zeppelin WebSocket (9996) Zeppelin UI (9995) Kibana (3080) Elasticsearch (9200)\n\n\n\n\nVMs and Storage\n\n\nYou have two options:\n\n\n\n\nUse the default template\n: This requires no further action.  \n\n\nAdd your own custom template\n: Use this option if you have specific requirements for your cluster node infrastructure. A typical setup may combine multiple templates in a cluster for the different types of nodes. For example you may want to attach multiple large disks to the data nodes or have memory optimized instances for Spark nodes.   \n\n\n\n\nDefault Template\n\n\nCloudbreak includes one pre-defined template called \nminviable-aws\n, which is used by default when creating a cluster. You can see it in the \nmanage templates\n tab. The configuration is:\n\n\n\n\n\n\n\n\nParameter\n\n\nValue\n\n\n\n\n\n\n\n\n\n\nName\n\n\nminviable-aws\n\n\n\n\n\n\nInstance Type\n\n\nm3.large\n\n\n\n\n\n\nVolume Type\n\n\nGeneral Purpose (SSD)\n\n\n\n\n\n\nAttached Volumes Per Instance\n\n\n1\n\n\n\n\n\n\nVolume Size (GB)\n\n\n100\n\n\n\n\n\n\nEBS Encryption\n\n\nFalse\n\n\n\n\n\n\n\n\nAdd Custom Template\n\n\nYou can define reusable configurations in the \nmanage templates\n tab: \n\n\n\n\n\n\nClick on \n+create template\n.\n\n\n\n\n\n\nProvide required parameters: \n\n\n\n\n\n\n\n\nParameter\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nName\n\n\nEnter a name for your template.\n\n\n\n\n\n\nDescription\n\n\n(Optional) Enter a description.\n\n\n\n\n\n\nInstance Type\n\n\nSelect an instance type. For more information about instance types on AWS refer to \nAWS documentation\n.\n\n\n\n\n\n\nVolume Type\n\n\nSelect the volume type. The options are:\nMagnetic\nEphemeral\nGeneral Purpose (SSD)\nThroughput Optimized HDD\nFor more information about these options refer to \nAWS documentation\n.\n\n\n\n\n\n\nAttached Volumes Per Instance\n\n\nEnter the number of volumes attached per instance. Default is 1.\n\n\n\n\n\n\nVolume Size (GB)\n\n\nEnter the size in GBs for each volume. Default is 100.\n\n\n\n\n\n\nSpot Price (USD)\n\n\nIf you would like to use spot instances, enter your bid. Cloudbreak will request spot price instances (which might take a while or never be fulfilled by Amazon). This option is not supported by the default RedHat images.\n\n\n\n\n\n\nEBS Encryption\n\n\nCheck the box to enable EBS encryption. If this option is checked, then all the attached disks will be encrypted using the AWS KMS master keys. Refer to \nAWS documentation\n.\n\n\n\n\n\n\nPublic In Account\n\n\n(Optional) If this option is checked, all the users belonging to your account will be able to use this template to create clusters, but they cannot delete it.\n\n\n\n\n\n\nSelect Platform\n\n\n(Optional) Select a previously created platform.\n\n\n\n\n\n\n\n\n\n\n\n\nClick on \n+create template\n.\n\n\nNo resources will be created until you create a cluster using this configuration.\n\n\n\n\n\n\n\n\nNext: Create a Cluster", 
            "title": "Define Infrastructure Templates"
        }, 
        {
            "location": "/aws-config/index.html#define-infrastructure-templates", 
            "text": "After you've logged in to Cloudbreak and created a Cloudbreak credential, you have two options:   Create clusters using default infrastructure templates        Define your own infrastructure templates      The  infrastructure templates  for resources such as  networks ,  security groups , and  VMs and storage  are saved to Cloudbreak's database and can be reused with multiple clusters to describe the infrastructure. When you add these resources in Cloudbreak web UI, Cloudbreak does not make any requests to your cloud provider account. Resources are only created on your cloud provider account after the create cluster button has been pushed.   This is illustrated and further explained in the  Architecture  documentation.  We recommend that you review the default infrastructure  templates for networks, security groups, and VMs and storage to check if they meet your requirements. You can do this by expanding  their corresponding panes in the Cloudbreak web UI (shown in the screenshot) or by reading the documentation below.       The following table describes the basic configurations that require an infrastructure template. If the default infrastructure templates don't work for you, you must create custom templates.     Configuration  Description  Create Cluster      Networks  (Required) Virtual networks provide the networking infrastructure (network, subnet, Internet gateway, and so on) in which your clusters run. A virtual network on AWS is called Amazon Virtual Private Cloud (Amazon VPC). You can create new virtual networks or reuse existing virtual networks for your clusters. For basic information about VPCs and subnets on AWS, refer to  AWS documentation .  You can select the network configuration for your clusters in the  Create Cluster  wizard    Set up Network and Security  page.    Security Groups  (Required) Security groups include rules which define inbound traffic allowed to the instances in your cluster. You can define different security group configurations for different nodes of your cluster. For basic information about security groups on AWS, refer to  AWS documentation .  You can select the security group configurations for each host group in the  Create Cluster  wizard    Choose Blueprint  page. If no custom security groups are selected, default is used.    VMs and Storage  (Required) \"Templates\" define the AWS infrastructure for the instances on which your cluster runs. You can select the EC2 instance types and their attached storage, including storage type, size, count, and encryption settings. You can reuse the same template for different cluster host groups or create different templates for different host groups.  You can select a template for each host group in the  Create Cluster  wizard    Choose Blueprint  page. If no custom templates are selected, default is used.", 
            "title": "Define Infrastructure Templates"
        }, 
        {
            "location": "/aws-config/index.html#networks", 
            "text": "You have four options:   Use the default network configuration template : This requires no further action. Every time a cluster is created with this kind of network setup a new VPC and a new subnet with the specified IP range will be created for the instances on AWS.    Create a new VPC and a new subnet : Every time a cluster is created with this kind of network setup a new VPC and a new subnet with the specified IP range will be created for the instances on AWS.    Create a new subnet in an existing VPC : Use this option if you already have a VPC on AWS where you'd like to put the cluster but you'd like to have a separate subnet for it. This setup is only supported for basic VPCs, where an Internet Gateway is configured and instances have public IP addresses to access the Internet.          Use an existing subnet in an existing VPC : Use this option (1) If you have an existing VPC with one or more subnets on AWS and you'd like to start the cluster in one (or more) of these subnets. (2) If you have a custom VPC setup (VGW, NAT, private subnets, and so on).  In this setup, instances in the subnet don't need to have public IP addresses. If using multiple subnets, the subnets can be in different availability zones.       If you are planning to use an existing VPC, consider these restrictions:   The subnet CIDRs cannot overlap in a VPC. Make sure that the new subnets that you define don't overlap with already deployed subnets in that VPC.    Since subnet CIDRs cannot overlap in a VPC, if you want to launch multiple clusters in the same VPC, you must create a different network template for each cluster. For example, you can create three different clusters with three different network templates for multiple subnets ( 10.0.0.0/24 ,  10.0.1.0/24 ,  10.0.2.0/24  respectively) with the same VPC and IGW identifiers.     If using an existing subnet, consider these restrictions:    Before using an existing subnet, make sure you have enough room within your network space for the new instances.     Instances in the subnet must be able to reach the Internet to download yum packages (this can be done through a Virtual Gateway, a NAT instance, an Internet Gateway, or by other means).    The VM on which Cloudbreak is deployed must be able to reach the instances in the cluster on port 443, either by being in the same subnet or through a router from another subnet.", 
            "title": "Networks"
        }, 
        {
            "location": "/aws-config/index.html#default-network", 
            "text": "Cloudbreak includes one pre-defined network configuration called  default-aws-network , which is used by default when creating a cluster.  You can see it in the  manage networks  tab. The configuration is:      Parameter  Value      Name  default-aws-network    Description  Default network settings for AWS clusters.    Subnet (CIDR)  10.0.0.0/16     With this default configuration, a new VPC with a 10.0.0.0/16 subnet will be created every time a cluster is created. No resources will be created until you create a cluster using this configuration.", 
            "title": "Default Network"
        }, 
        {
            "location": "/aws-config/index.html#add-new-vpc-and-subnet", 
            "text": "You can define reusable network configurations for your clusters in the  manage networks  tab:    Click on  Create a new VPC and a new subnet .    Provide required parameters:     Parameter  Description      Name  Enter a name for your configuration.    Description  (Optional) Enter a description.    Subnet (CIDR)  Enter a valid  CIDR  for a new subnet that will be created within the VPC. For example  10.0.0.0/24 .    Public In Account  (Optional) If this option is checked, all the users belonging to your account will be able to use this network template to create clusters, but they cannot delete it.    Select Platform  (Optional) Select a previously created platform.       Click on  +create network .  No resources will be created until you create a cluster using this configuration.", 
            "title": "Add New VPC and Subnet"
        }, 
        {
            "location": "/aws-config/index.html#add-new-subnet-in-existing-vpc", 
            "text": "You can define reusable network configurations for your clusters in the  manage networks  tab:    Click on  Create a new subnet in an existing VPC .    Provide required parameters:      Parameter  Description      Name  Enter a name for your configuration.    Description  (Optional) Enter a description.    VPC Identifier  Paste the \"VPC ID\" of your existing VPC as it appears in your VPC Dashboard on AWS. The \"VPC ID\" should be in the format \"vpc-12345678\".    Internet Gateway Identifier  Paste the \"ID\" of the Internet Gateway associated with the chosen VPC as it appears in your VPC Dashboard on AWS. The \"ID\" should be in the format \"igw-12345678\".    Subnet (CIDR)  Enter a valid  CIDR  for a new subnet that will be created within the VPC. For example  10.0.0.0/24 .    Public In Account  (Optional) If this option is checked, all the users belonging to your account will be able to use this network template to create clusters, but they cannot delete it.    Select Platform  (Optional) Select a previously created platform.       Click on  +create network .  No resources will be created until you create a cluster using this configuration.", 
            "title": "Add New Subnet in Existing VPC"
        }, 
        {
            "location": "/aws-config/index.html#use-existing-vpc-and-subnet", 
            "text": "You can define reusable network configurations for your clusters in the  manage networks  tab:    Click on  Use an existing subnet in an existing VPC .     Provide required parameters:      Parameter  Description      Name  Enter a name for your configuration.    Description  (Optional) Enter a description.    VPC Identifier  Paste the \"VPC ID\" of your existing VPC as it appears in your VPC Dashboard on AWS. The \"VPC ID\" should be in the format \"vpc-12345678\".    Subnet Identifier  Paste the \"Subnet ID\" of your existing subnet as it appears in your VPC Dashboard on AWS. The subnet must be within the VPC specified above. The 'Subnet ID\" should be in the format \"subnet-12345678\". You can set a single subnet or a comma separated list of subnets.    Public In Account  (Optional) If this option is checked, all the users belonging to your account will be able to use this network template to create clusters, but they cannot delete it.    Select Platform  (Optional) Select a previously created platform.       Click on  +create network .  No resources will be created until you create a cluster using this configuration.", 
            "title": "Use Existing VPC and Subnet"
        }, 
        {
            "location": "/aws-config/index.html#security-groups", 
            "text": "You have three options:   Use the default security group configuration : This requires no further action.    Add your own custom security group configuration : You can define your own security group by adding the ports, protocols, and  CIDR  ranges that you'd like to use. The rules defined here don't need to contain the internal rules (these are automatically added by Cloudbreak to the security group on AWS).    Copy rules from an existing security group : Use this option if you have an existing security group and you'd like to apply the same rules.    You can define different security group configurations for different nodes of your cluster.", 
            "title": "Security Groups"
        }, 
        {
            "location": "/aws-config/index.html#default-security-group", 
            "text": "Cloudbreak includes one pre-defined security group configuration called  default-aws-only-ssh-and-ssl , which is used by default when creating a cluster. You can see it in the  manage security groups  tab. The configuration is:      CIDR  Port  Protocol      0.0.0.0/0  22  tcp    0.0.0.0/0  433  tcp    0.0.0.0/0  9443  tcp     No resources will be created until you create a cluster using this configuration.", 
            "title": "Default Security Group"
        }, 
        {
            "location": "/aws-config/index.html#add-custom-security-group", 
            "text": "You can define reusable security group configurations for your clusters in the  manage security groups  tab:    Click on  Create a new security group .   Provide required parameters:     Parameter  Value      Name  Enter a name for your security group configuration template.    Description  (Optional) Enter a description.    Public In Account  (Optional) If this option is checked, all the users belonging to your account will be able to use this security group template to create clusters, but they cannot delete it.       Provide the following parameters in order to define  Security Rules  for this security group:     Parameter  Value      CIDR  Enter a valid  CIDR IP , from which the cluster will be accessed.    Port  Enter ports that you want to open. You can either list multiple ports, separated by a comma (for example \"22,443,9443\"), or you can define port ranges (for example \"1-65355\").    Protocol  Enter protocol that you want to use.      Ports 22, 443, and 9443 must be open on every security group; otherwise Cloudbreak will not be able to communicate with your provisioned cluster.     Click  +Add Rule  to save the security rules. If needed, click  +Add Rule  again to display a new  Security Rules  form and add another set of rules.     Click  +create security group  to save the configuration.   No resources will be created until you create a cluster using this configuration.", 
            "title": "Add Custom Security Group"
        }, 
        {
            "location": "/aws-config/index.html#use-existing-security-group", 
            "text": "You can copy rules of an existing security group by using the  Use an existing security group  option available in the  manage security groups  tab:     Click on  Use an existing security group .    Provide required parameters:     Parameter  Value      Name  Enter a name for your configuration.    Description  (Optional) Enter a description.    Security Group Identifier  Enter the \"Group ID\" of an existing security group whose settings you would like to reuse. The \"Group ID\" should be in the following format \"sg-12345678\".    Public In Account  (Optional) If this option is checked, all the users belonging to your account will be able to use this security group to create clusters, but they cannot delete it.      Ports 22, 443, and 9443 must be open on every security group; otherwise Cloudbreak will not be able to communicate with your provisioned cluster.     Click  +create security group  to save the configuration.   No resources will be created until you create a cluster using this configuration.      Ports used by Hadoop services: Ambari (8080) Consul (8500) NN (50070) RM Web (8088) Scheduler (8030RM) IPC (8050RM) Job history server (19888) HBase master (60000) HBase master web (60010) HBase RS (16020) HBase RS info (60030) Falcon (15000) Storm (8744) Hive metastore (9083) Hive server (10000) Hive server HTTP (10001) Accumulo master (9999) Accumulo Tserver (9997) Atlas (21000) KNOX (8443) Oozie (11000) Spark HS (18080) NM Web (8042) Zeppelin WebSocket (9996) Zeppelin UI (9995) Kibana (3080) Elasticsearch (9200)", 
            "title": "Use Existing Security Group"
        }, 
        {
            "location": "/aws-config/index.html#vms-and-storage", 
            "text": "You have two options:   Use the default template : This requires no further action.    Add your own custom template : Use this option if you have specific requirements for your cluster node infrastructure. A typical setup may combine multiple templates in a cluster for the different types of nodes. For example you may want to attach multiple large disks to the data nodes or have memory optimized instances for Spark nodes.", 
            "title": "VMs and Storage"
        }, 
        {
            "location": "/aws-config/index.html#default-template", 
            "text": "Cloudbreak includes one pre-defined template called  minviable-aws , which is used by default when creating a cluster. You can see it in the  manage templates  tab. The configuration is:     Parameter  Value      Name  minviable-aws    Instance Type  m3.large    Volume Type  General Purpose (SSD)    Attached Volumes Per Instance  1    Volume Size (GB)  100    EBS Encryption  False", 
            "title": "Default Template"
        }, 
        {
            "location": "/aws-config/index.html#add-custom-template", 
            "text": "You can define reusable configurations in the  manage templates  tab:     Click on  +create template .    Provide required parameters:      Parameter  Description      Name  Enter a name for your template.    Description  (Optional) Enter a description.    Instance Type  Select an instance type. For more information about instance types on AWS refer to  AWS documentation .    Volume Type  Select the volume type. The options are: Magnetic Ephemeral General Purpose (SSD) Throughput Optimized HDD For more information about these options refer to  AWS documentation .    Attached Volumes Per Instance  Enter the number of volumes attached per instance. Default is 1.    Volume Size (GB)  Enter the size in GBs for each volume. Default is 100.    Spot Price (USD)  If you would like to use spot instances, enter your bid. Cloudbreak will request spot price instances (which might take a while or never be fulfilled by Amazon). This option is not supported by the default RedHat images.    EBS Encryption  Check the box to enable EBS encryption. If this option is checked, then all the attached disks will be encrypted using the AWS KMS master keys. Refer to  AWS documentation .    Public In Account  (Optional) If this option is checked, all the users belonging to your account will be able to use this template to create clusters, but they cannot delete it.    Select Platform  (Optional) Select a previously created platform.       Click on  +create template .  No resources will be created until you create a cluster using this configuration.     Next: Create a Cluster", 
            "title": "Add Custom Template"
        }, 
        {
            "location": "/aws-blueprints/index.html", 
            "text": "Define Cluster Blueprints\n\n\nCluster blueprints\n are your declarative definition of a Hadoop cluster, defining the host groups and which components to install on which host group. Ambari uses them as a base for your clusters. \n\n\nYou have three options:\n\n\n\n\nUse one of the pre-defined blueprints.  \n\n\nCopy and edit one of the pre-defined blueprints.   \n\n\nAdd your custom blueprint by uploading a JSON file or pasting the JSON text. \n\n\n\n\nWe recommend that you review the default blueprints to check if they meet your requirements. You can do this by expanding  the \nmanage bluerints\n pane in the Cloudbreak web UI (shown in the screenshot) or by reading the documentation below.  \n\n\n \n\n\nHere\n is an example of a blueprint. \n\n\nThe host groups in the JSON will be mapped to a set of instances when starting the cluster, and the specified services and components will be installed on the corresponding nodes. It is not necessary to define a complete configuration in the blueprint. If a configuration is missing, Ambari will fill that with a default value. \n\n\nA blueprint can be modified later from the Ambari UI.\n\n\nA blueprint can be exported from a running Ambari cluster and can be reused in Cloudbreak after slight modifications. When a blueprint is exported, some configurations are hardcoded for example domain names, memory configurations, and so on, that won't be applicable to the Cloudbreak cluster. There is no automatic way to modify an exported blueprint and make it instantly usable in Cloudbreak, the modifications have to be done manually.\n\n\nDefault Blueprints\n\n\nCloudbreak includes three default HDP cluster blueprints:\n\n\nHDP Version: \nHDP 2.6\n\n\n\n\n\n\n\n\nCluster Type\n\n\nServices\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nData Science\n\n\n Spark 1.6,\nZeppelin 0.7.0\n\n\nThis cluster configuration includes Spark 1.6 with Zeppelin.\n\n\n\n\n\n\nData Science\n\n\n Spark 2.1,\nZeppelin 0.7.0\n\n\nThis cluster configuration includes Spark 2.1 with Zeppelin.\n\n\n\n\n\n\nEDW - Analytics\n\n\n Hive 2 LLAP\n,\nZeppelin 0.7.0\n\n\nThis cluster configuration includes Hive 2 LLAP.\n\n\n\n\n\n\nEDW - ETL\n\n\n Hive 1.2.1,\nSpark 1.6\n\n\nThis cluster configuration includes Hive and Spark 1.6.\n\n\n\n\n\n\nEDW - ETL\n\n\n Hive 1.2.1,\n Spark 2.1\n\n\nThis cluster configuration includes Hive and Spark 2.1.\n\n\n\n\n\n\nBI\n\n\n Druid 0.9.2\n\n\nThis cluster configuration includes a Technical Preview of Druid.\n\n\n\n\n\n\n\n\nHDP Version: \nHDP 2.5\n\n\n\n\n\n\n\n\nCluster Type\n\n\nServices\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nData Science\n\n\n Spark 1.6,\nZeppelin 0.6.0\n\n\nThis cluster configuration includes Spark 1.6 and Zeppelin.\n\n\n\n\n\n\nEDW - ETL\n\n\n Hive 1.2.1,\nSpark 1.6\n\n\nThis cluster configuration includes Hive and Spark 1.6.\n\n\n\n\n\n\nEDW - ETL\n\n\n Hive 1.2.1,\n Spark 2.0\n\n\nThis cluster configuration includes a Technical Preview of Spark 2.0.\n\n\n\n\n\n\nEDW - Analytics\n\n\n Hive 2 LLAP\n,\nZeppelin 0.6.0\n\n\nThis cluster configuration includes a Technical Preview of Hive 2 LLAP.\n\n\n\n\n\n\n\n\n\n    \nChoosing Your Configuration\n\n    \n\nWhen creating a cluster, you can choose a more stable cluster configuration for a predicable experience.\nAlternatively, you can try the latest capabilities by choosing a cluster configuration\nthat is much more experimental. The following configuration classification applies:\n\n\n\n Stable configurations are the best choice if you want to avoid issues and other problems with launching and using clusters.\n\n\n If you want to use a Technical Preview version of a component in a release of HDP, use these configurations.\n\n\n These are the most cutting edge of the configurations, including Technical Preview components in a Technical Preview HDP release.\n\n\n\n\n\n\n\n\n\nCopy and Edit Existing Blueprint\n\n\nYou can modify default or previously added blueprints in the \nmanage blueprints\n tab. To do that, expand the entry in the Cloudbreak UI and then click \ncopy \n edit\n. \n\n\nAdd Custom Blueprint\n\n\nYou can define reusable blueprints for your clusters in the \nmanage blueprints\n tab. To add your own blueprint, click \n+create blueprint\n and enter the following parameters:\n\n\n\n\n\n\n\n\nParameter\n\n\nValue\n\n\n\n\n\n\n\n\n\n\nName\n\n\nEnter a name for your blueprint.\n\n\n\n\n\n\nDescription\n\n\n(Optional) Enter a description for your blueprint.\n\n\n\n\n\n\nBlueprint Source\n\n\nSelect one of: \nText\n: Paste blueprint in JSON format.\n \nFile\n: Upload a file that contains the blueprint.\n \nURL\n: Specify the URL for your blueprint.\n\n\n\n\n\n\nPublic In Account\n\n\n(Optional) If this option is checked, all the users belonging to your account will be able to use this blueprint to create clusters, but they cannot delete it.\n\n\n\n\n\n\n\n\n\n\nNext: Create a Cluster", 
            "title": "Define Cluster Blueprints"
        }, 
        {
            "location": "/aws-blueprints/index.html#define-cluster-blueprints", 
            "text": "Cluster blueprints  are your declarative definition of a Hadoop cluster, defining the host groups and which components to install on which host group. Ambari uses them as a base for your clusters.   You have three options:   Use one of the pre-defined blueprints.    Copy and edit one of the pre-defined blueprints.     Add your custom blueprint by uploading a JSON file or pasting the JSON text.    We recommend that you review the default blueprints to check if they meet your requirements. You can do this by expanding  the  manage bluerints  pane in the Cloudbreak web UI (shown in the screenshot) or by reading the documentation below.       Here  is an example of a blueprint.   The host groups in the JSON will be mapped to a set of instances when starting the cluster, and the specified services and components will be installed on the corresponding nodes. It is not necessary to define a complete configuration in the blueprint. If a configuration is missing, Ambari will fill that with a default value.   A blueprint can be modified later from the Ambari UI.  A blueprint can be exported from a running Ambari cluster and can be reused in Cloudbreak after slight modifications. When a blueprint is exported, some configurations are hardcoded for example domain names, memory configurations, and so on, that won't be applicable to the Cloudbreak cluster. There is no automatic way to modify an exported blueprint and make it instantly usable in Cloudbreak, the modifications have to be done manually.", 
            "title": "Define Cluster Blueprints"
        }, 
        {
            "location": "/aws-blueprints/index.html#default-blueprints", 
            "text": "Cloudbreak includes three default HDP cluster blueprints:", 
            "title": "Default Blueprints"
        }, 
        {
            "location": "/aws-blueprints/index.html#hdp-version-hdp-26", 
            "text": "Cluster Type  Services  Description      Data Science   Spark 1.6, Zeppelin 0.7.0  This cluster configuration includes Spark 1.6 with Zeppelin.    Data Science   Spark 2.1, Zeppelin 0.7.0  This cluster configuration includes Spark 2.1 with Zeppelin.    EDW - Analytics   Hive 2 LLAP , Zeppelin 0.7.0  This cluster configuration includes Hive 2 LLAP.    EDW - ETL   Hive 1.2.1, Spark 1.6  This cluster configuration includes Hive and Spark 1.6.    EDW - ETL   Hive 1.2.1,  Spark 2.1  This cluster configuration includes Hive and Spark 2.1.    BI   Druid 0.9.2  This cluster configuration includes a Technical Preview of Druid.", 
            "title": "HDP Version: HDP 2.6"
        }, 
        {
            "location": "/aws-blueprints/index.html#hdp-version-hdp-25", 
            "text": "Cluster Type  Services  Description      Data Science   Spark 1.6, Zeppelin 0.6.0  This cluster configuration includes Spark 1.6 and Zeppelin.    EDW - ETL   Hive 1.2.1, Spark 1.6  This cluster configuration includes Hive and Spark 1.6.    EDW - ETL   Hive 1.2.1,  Spark 2.0  This cluster configuration includes a Technical Preview of Spark 2.0.    EDW - Analytics   Hive 2 LLAP , Zeppelin 0.6.0  This cluster configuration includes a Technical Preview of Hive 2 LLAP.     \n     Choosing Your Configuration \n     \nWhen creating a cluster, you can choose a more stable cluster configuration for a predicable experience.\nAlternatively, you can try the latest capabilities by choosing a cluster configuration\nthat is much more experimental. The following configuration classification applies:   Stable configurations are the best choice if you want to avoid issues and other problems with launching and using clusters.   If you want to use a Technical Preview version of a component in a release of HDP, use these configurations.   These are the most cutting edge of the configurations, including Technical Preview components in a Technical Preview HDP release.", 
            "title": "HDP Version: HDP 2.5"
        }, 
        {
            "location": "/aws-blueprints/index.html#copy-and-edit-existing-blueprint", 
            "text": "You can modify default or previously added blueprints in the  manage blueprints  tab. To do that, expand the entry in the Cloudbreak UI and then click  copy   edit .", 
            "title": "Copy and Edit Existing Blueprint"
        }, 
        {
            "location": "/aws-blueprints/index.html#add-custom-blueprint", 
            "text": "You can define reusable blueprints for your clusters in the  manage blueprints  tab. To add your own blueprint, click  +create blueprint  and enter the following parameters:     Parameter  Value      Name  Enter a name for your blueprint.    Description  (Optional) Enter a description for your blueprint.    Blueprint Source  Select one of:  Text : Paste blueprint in JSON format.   File : Upload a file that contains the blueprint.   URL : Specify the URL for your blueprint.    Public In Account  (Optional) If this option is checked, all the users belonging to your account will be able to use this blueprint to create clusters, but they cannot delete it.      Next: Create a Cluster", 
            "title": "Add Custom Blueprint"
        }, 
        {
            "location": "/aws-create/index.html", 
            "text": "Create a Cluster on AWS\n\n\nTo create a cluster via CLoudbreak UI:\n\n\n\n\n\n\nLog in to the Cloudbreak UI.\n\n\n\n\n\n\nIn the top right corner, select the credential that you want to use to create a cluster:\n\n\n  \n\n\n\n\n\n\nClick \n+create cluster\n and the \nCreate cluster\n form is displayed.\n\n\n\n\n\n\nOn the \nConfigure Cluster\n page, provide the following parameters:\n\n\n\n\nTo view advanced options, click \nShow Advanced Options\n. To learn about advanced options, refer to \nAdvanced Options\n.\n\n\n\n\n\n\n\n\n\n\nParameter\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nCluster Name\n\n\nEnter a name for your cluster. The name must be between 5 and 40 characters, must start with a letter, must only include lowercase letters, numbers, and hyphens.\n\n\n\n\n\n\nTags\n\n\n(Optional) You can optionally add tags, which will help you find your cluster-related resources, such as VMs, in your cloud provider account.\n\n\n\n\n\n\nRegion\n\n\nSelect the region in which you would like to launch your cluster.\n\n\n\n\n\n\nSend Email When Cluster is Ready\n\n\n(Optional) Check this to receive an email each time the cluster status changes.\n\n\n\n\n\n\nPublic In Account\n\n\n(Optional) If this option is checked, all the users belonging to your account will be able to use this cluster, but they cannot delete it.\n\n\n\n\n\n\n\n\n\n\nBy default, Ambari Username and Ambari Password are set to \nadmin\n. You can override it in the \"\nConfigure Cluster\n\" tab.\n\n\n\n\n\n\n\n\nOn the \nSet up Network and Security\n page, provide the following parameters:\n\n\n\n\n\n\n\n\nParameter\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nNetwork\n\n\nSelect the virtual network in which you would like your cluster to be provisioned. You can define custom network configurations or use default network configurations.\n\n\n\n\n\n\nEnable Knox Gateway\n\n\n(Optional) Select this option to enable secure access to Ambari web UI and other cluster UIs via Knox gateway.\n\n\n\n\n\n\nEnable Kerberos Security\n\n\n(Optional) Select this option to enable Kerberos for your cluster. You will have an option to create a new kerberos or use an existing one. For more information refer to Kerberos \ndocumentation\n.\n\n\n\n\n\n\n\n\n\n\n\n\nOn the \nChoose Blueprint\n page, select the blueprint that you would like to use for your cluster. You can either choose one of the pre-configured blueprints, or add your own in the \nmanage blueprints\n tab.\n\n\nFor each host group you must provide the following:\n\n\n\n\n\n\n\n\nParameter\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nGroup Size\n\n\nEnter a number defining how many nodes to create per host group. Default is 1. The \"Group Size\" for that host group on which Ambari Server is installed must be set to \"1\".\n\n\n\n\n\n\nTemplate\n\n\nIf you have previously created a template for VMs and storage, you can select it here. If you don't make a selection, default will be used.\n\n\n\n\n\n\nSecurity Group\n\n\nIf you have previously created a template for a security group, you can select it here. If you don't make a selection, default will be used.\n\n\n\n\n\n\nAmbari Server\n\n\nYou must select one node for Ambari Server. The \"Group Size\" for that host group must be set to \"1\".\n\n\n\n\n\n\nRecipes\n\n\nYou can select a previously added recipe (custom script) to be executed on all nodes of the host group. Refer to \nRecipes\n.\n\n\n\n\n\n\n\n\n\n\n\n\nClick on \nReview and Launch\n and then \n+create and start cluster\n.\n\n\n\n\n\n\nYou will be redirected to the Cloudbreak dashboard, and a new tile representing your cluster will appear at the top of the page.\n\n\n\n\n\n\nAdvanced Options\n\n\nClick on \nShow Advanced Options\n to enter additional configuration options.\n\n\nConfigure Cluster\n\n\nYou can optionally configure the following advanced parameters:\n\n\n\n\n\n\n\n\nParameter\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nAmbari Username\n\n\nYou can log in to the Ambari UI using this username. By default, this is set to \nadmin\n.\n\n\n\n\n\n\nAmbari Password\n\n\nYou can log in to the Ambari UI using this password. By default, this is set to \nadmin\n.\n\n\n\n\n\n\nProvision Cluster\n\n\nSALT\n is pre-selected to provision your cluster.\n\n\n\n\n\n\nUse dedicated instances\n\n\nSelect this to use dedicated instances (i.e. EC2 instances that run in a virtual private cloud (VPC) on hardware that's dedicated to a single customer). For more information about dedicated instances, refer to \nAWS documentation\n.\n\n\n\n\n\n\nEnable Lifetime Management\n\n\nCheck this option if you would like your cluster to be automatically terminated after a specific amount of time (defined as \"Time to Live\" in minuter) has passed.\n\n\n\n\n\n\nFlex Subscription\n\n\nThis option will appear if you have configured your deployment for a \nFlex Subscription\n.\n\n\n\n\n\n\n\n\nChoose Blueprint\n\n\nAfter selecting a blueprint, you can optionally configure the following advanced parameters:\n\n\n\n\n\n\n\n\nParameter\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nConfig Recommendation Strategy (Stack Advisor)\n\n\nSelect how configuration recommendations generated by stack advisor will be applied. Select one of \nALWAYS_APPLY: Configuration recommendations will be applied automatically.\nALWAYS_APPLY_DONT_OVERRIDE_CUSTOM_VALUES: Configuration recommendations will be applied automatically, but they will be ignored for custom configurations.\nNEVER_APPLY: Configuration recommendations will be ignored.\nONLY_STACK_DEFAULTS_APPLY: Configuration recommendations will be applied only on the default configurations for all included services.\n\n\n\n\n\n\nValidate Blueprint\n\n\nSelect to validate the blueprint.\n\n\n\n\n\n\nInstance Profile\n\n\nThis option allows you to optionally create or reuse an existing instance profile for your cluster VMs. An instance profile is a container for an IAM role that you can use to pass role information to an EC2 instance when the instance starts. You can use this option to allow access to AWS resources such as Amazon S3 object storage. The following choices are available:\nDisable Instance Profile attaching by default\nCreate Instance Profile and attach to the instance\nDefine existing Instance Profile and attach to the instances\n For more information about instance profile, refer to \nAWS documentation\n.\n\n\n\n\n\n\n\n\nChoose Failure Action\n\n\nYou can optionally select what to do if cluster creation fails or if there aren't enough instances available to create all requested nodes:\n\n\n\n\n\n\n\n\nParameter\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nFailure Action\n\n\nSelect one of: \ndo NOT rollback resources\n (default) or \nrollback resources\n. \nBy default, if creating a cluster fails, the Azure resources that were created up to that point will not be rolled back. This means that they will remain accessible for troubleshooting and you will need to to delete them manually.\n\n\n\n\n\n\nMinimum Cluster Size\n\n\nThis defines the provisioning strategy in case the cloud provider cannot allocate all the requested nodes. Select \nbest effort\n or \nexact\n.\n\n\n\n\n\n\n\n\nConfigure Ambari Repos\n\n\nYou can optionally configure a different version of Ambari than the default by providing the following information:\n\n\n\n\n\n\n\n\nParameter\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nAmbari Version\n\n\nEnter Ambari version.\n\n\n\n\n\n\nAmbari Repo URL\n\n\nEnter Ambari repo URL.\n\n\n\n\n\n\nAmbari Repo Gpg Key URL\n\n\nEnter gpgkey URL.\n\n\n\n\n\n\n\n\nConfigure HDP Repos\n\n\nYou can optionally configure a different version of HDP than the default by providing the following information:\n\n\n\n\n\n\n\n\nParameter\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nStack\n\n\nEnter stack name.\n\n\n\n\n\n\nVersion\n\n\nEnter stack version.\n\n\n\n\n\n\nStack Repo ID\n\n\nEnter stack repo ID.\n\n\n\n\n\n\nBase URL\n\n\nEner stack repo base URL.\n\n\n\n\n\n\nUtils Repo ID\n\n\nEnter Utils repo ID.\n\n\n\n\n\n\nUtils Base URL\n\n\nEnter Utils repo base URL.\n\n\n\n\n\n\nVerify\n\n\nSelect to verify the repo information.\n\n\n\n\n\n\n\n\nConfigure Ambari Database\n\n\nBy default, Ambari stores data on an embedded database, which is sufficient for ephemeral or test clusters. However, as Ambari and Cloudbreak don't perform backups of this database, it is insufficient for long-running production clusters, and you may need to configure a remote database for Ambari and Cloudbreak.\n\n\n\n\n\n\n\n\nParameter\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nVendor\n\n\nSelect database vendor from the list.\n\n\n\n\n\n\nHost\n\n\nEnter database host IP.\n\n\n\n\n\n\nPort\n\n\nEnter port number.\n\n\n\n\n\n\nName\n\n\nEnter database name.\n\n\n\n\n\n\nUser Name\n\n\nEnter database user name.\n\n\n\n\n\n\nPassword\n\n\nEnter database password.\n\n\n\n\n\n\n\n\n\n\nNext: Manage \n&\n Monitor Clusters", 
            "title": "Create a Cluster"
        }, 
        {
            "location": "/aws-create/index.html#create-a-cluster-on-aws", 
            "text": "To create a cluster via CLoudbreak UI:    Log in to the Cloudbreak UI.    In the top right corner, select the credential that you want to use to create a cluster:        Click  +create cluster  and the  Create cluster  form is displayed.    On the  Configure Cluster  page, provide the following parameters:   To view advanced options, click  Show Advanced Options . To learn about advanced options, refer to  Advanced Options .      Parameter  Description      Cluster Name  Enter a name for your cluster. The name must be between 5 and 40 characters, must start with a letter, must only include lowercase letters, numbers, and hyphens.    Tags  (Optional) You can optionally add tags, which will help you find your cluster-related resources, such as VMs, in your cloud provider account.    Region  Select the region in which you would like to launch your cluster.    Send Email When Cluster is Ready  (Optional) Check this to receive an email each time the cluster status changes.    Public In Account  (Optional) If this option is checked, all the users belonging to your account will be able to use this cluster, but they cannot delete it.      By default, Ambari Username and Ambari Password are set to  admin . You can override it in the \" Configure Cluster \" tab.     On the  Set up Network and Security  page, provide the following parameters:     Parameter  Description      Network  Select the virtual network in which you would like your cluster to be provisioned. You can define custom network configurations or use default network configurations.    Enable Knox Gateway  (Optional) Select this option to enable secure access to Ambari web UI and other cluster UIs via Knox gateway.    Enable Kerberos Security  (Optional) Select this option to enable Kerberos for your cluster. You will have an option to create a new kerberos or use an existing one. For more information refer to Kerberos  documentation .       On the  Choose Blueprint  page, select the blueprint that you would like to use for your cluster. You can either choose one of the pre-configured blueprints, or add your own in the  manage blueprints  tab.  For each host group you must provide the following:     Parameter  Description      Group Size  Enter a number defining how many nodes to create per host group. Default is 1. The \"Group Size\" for that host group on which Ambari Server is installed must be set to \"1\".    Template  If you have previously created a template for VMs and storage, you can select it here. If you don't make a selection, default will be used.    Security Group  If you have previously created a template for a security group, you can select it here. If you don't make a selection, default will be used.    Ambari Server  You must select one node for Ambari Server. The \"Group Size\" for that host group must be set to \"1\".    Recipes  You can select a previously added recipe (custom script) to be executed on all nodes of the host group. Refer to  Recipes .       Click on  Review and Launch  and then  +create and start cluster .    You will be redirected to the Cloudbreak dashboard, and a new tile representing your cluster will appear at the top of the page.", 
            "title": "Create a Cluster on AWS"
        }, 
        {
            "location": "/aws-create/index.html#advanced-options", 
            "text": "Click on  Show Advanced Options  to enter additional configuration options.", 
            "title": "Advanced Options"
        }, 
        {
            "location": "/aws-create/index.html#configure-cluster", 
            "text": "You can optionally configure the following advanced parameters:     Parameter  Description      Ambari Username  You can log in to the Ambari UI using this username. By default, this is set to  admin .    Ambari Password  You can log in to the Ambari UI using this password. By default, this is set to  admin .    Provision Cluster  SALT  is pre-selected to provision your cluster.    Use dedicated instances  Select this to use dedicated instances (i.e. EC2 instances that run in a virtual private cloud (VPC) on hardware that's dedicated to a single customer). For more information about dedicated instances, refer to  AWS documentation .    Enable Lifetime Management  Check this option if you would like your cluster to be automatically terminated after a specific amount of time (defined as \"Time to Live\" in minuter) has passed.    Flex Subscription  This option will appear if you have configured your deployment for a  Flex Subscription .", 
            "title": "Configure Cluster"
        }, 
        {
            "location": "/aws-create/index.html#choose-blueprint", 
            "text": "After selecting a blueprint, you can optionally configure the following advanced parameters:     Parameter  Description      Config Recommendation Strategy (Stack Advisor)  Select how configuration recommendations generated by stack advisor will be applied. Select one of  ALWAYS_APPLY: Configuration recommendations will be applied automatically. ALWAYS_APPLY_DONT_OVERRIDE_CUSTOM_VALUES: Configuration recommendations will be applied automatically, but they will be ignored for custom configurations. NEVER_APPLY: Configuration recommendations will be ignored. ONLY_STACK_DEFAULTS_APPLY: Configuration recommendations will be applied only on the default configurations for all included services.    Validate Blueprint  Select to validate the blueprint.    Instance Profile  This option allows you to optionally create or reuse an existing instance profile for your cluster VMs. An instance profile is a container for an IAM role that you can use to pass role information to an EC2 instance when the instance starts. You can use this option to allow access to AWS resources such as Amazon S3 object storage. The following choices are available: Disable Instance Profile attaching by default Create Instance Profile and attach to the instance Define existing Instance Profile and attach to the instances  For more information about instance profile, refer to  AWS documentation .", 
            "title": "Choose Blueprint"
        }, 
        {
            "location": "/aws-create/index.html#choose-failure-action", 
            "text": "You can optionally select what to do if cluster creation fails or if there aren't enough instances available to create all requested nodes:     Parameter  Description      Failure Action  Select one of:  do NOT rollback resources  (default) or  rollback resources .  By default, if creating a cluster fails, the Azure resources that were created up to that point will not be rolled back. This means that they will remain accessible for troubleshooting and you will need to to delete them manually.    Minimum Cluster Size  This defines the provisioning strategy in case the cloud provider cannot allocate all the requested nodes. Select  best effort  or  exact .", 
            "title": "Choose Failure Action"
        }, 
        {
            "location": "/aws-create/index.html#configure-ambari-repos", 
            "text": "You can optionally configure a different version of Ambari than the default by providing the following information:     Parameter  Description      Ambari Version  Enter Ambari version.    Ambari Repo URL  Enter Ambari repo URL.    Ambari Repo Gpg Key URL  Enter gpgkey URL.", 
            "title": "Configure Ambari Repos"
        }, 
        {
            "location": "/aws-create/index.html#configure-hdp-repos", 
            "text": "You can optionally configure a different version of HDP than the default by providing the following information:     Parameter  Description      Stack  Enter stack name.    Version  Enter stack version.    Stack Repo ID  Enter stack repo ID.    Base URL  Ener stack repo base URL.    Utils Repo ID  Enter Utils repo ID.    Utils Base URL  Enter Utils repo base URL.    Verify  Select to verify the repo information.", 
            "title": "Configure HDP Repos"
        }, 
        {
            "location": "/aws-create/index.html#configure-ambari-database", 
            "text": "By default, Ambari stores data on an embedded database, which is sufficient for ephemeral or test clusters. However, as Ambari and Cloudbreak don't perform backups of this database, it is insufficient for long-running production clusters, and you may need to configure a remote database for Ambari and Cloudbreak.     Parameter  Description      Vendor  Select database vendor from the list.    Host  Enter database host IP.    Port  Enter port number.    Name  Enter database name.    User Name  Enter database user name.    Password  Enter database password.      Next: Manage  &  Monitor Clusters", 
            "title": "Configure Ambari Database"
        }, 
        {
            "location": "/aws-cb-ui/index.html", 
            "text": "Manage and Monitor Clusters\n\n\nYou can manage monitor your clusters from the Cloudbreak UI. To do that, click on the title representing the cluster that you want to access: \n\n\n \n\n\nAccessing Links to Cluster Services\n\n\nYou can access links to cluster services from the \nServices\n tab.\n\n\nManaging Cluster Nodes\n\n\nYou can view details about your cluster nodes (for example, Public IP addresses) from the \nNodes\n tab. You can also delete nodes using the \nTERMINATE\n option.\n\n\nAccessing Event Log\n\n\nYou can access cluster event log from the \nEvent History\n tab.\n\n\nRepairing Your Cluster\n\n\nTo trigger repair process for your cluster, click \nrepair\n. Faulty nodes will be deleted from the cluster and new ones will be added in their place. \n\n\nTerminating Your Cluster\n\n\nTo terminate your cluster, click \nterminate\n. All cluster-related resources will be deleted, unless the network is used by other VMs, in which case it will not be deleted.", 
            "title": "Manage and Monitor Clusters"
        }, 
        {
            "location": "/aws-cb-ui/index.html#manage-and-monitor-clusters", 
            "text": "You can manage monitor your clusters from the Cloudbreak UI. To do that, click on the title representing the cluster that you want to access:", 
            "title": "Manage and Monitor Clusters"
        }, 
        {
            "location": "/aws-cb-ui/index.html#accessing-links-to-cluster-services", 
            "text": "You can access links to cluster services from the  Services  tab.", 
            "title": "Accessing Links to Cluster Services"
        }, 
        {
            "location": "/aws-cb-ui/index.html#managing-cluster-nodes", 
            "text": "You can view details about your cluster nodes (for example, Public IP addresses) from the  Nodes  tab. You can also delete nodes using the  TERMINATE  option.", 
            "title": "Managing Cluster Nodes"
        }, 
        {
            "location": "/aws-cb-ui/index.html#accessing-event-log", 
            "text": "You can access cluster event log from the  Event History  tab.", 
            "title": "Accessing Event Log"
        }, 
        {
            "location": "/aws-cb-ui/index.html#repairing-your-cluster", 
            "text": "To trigger repair process for your cluster, click  repair . Faulty nodes will be deleted from the cluster and new ones will be added in their place.", 
            "title": "Repairing Your Cluster"
        }, 
        {
            "location": "/aws-cb-ui/index.html#terminating-your-cluster", 
            "text": "To terminate your cluster, click  terminate . All cluster-related resources will be deleted, unless the network is used by other VMs, in which case it will not be deleted.", 
            "title": "Terminating Your Cluster"
        }, 
        {
            "location": "/aws-data/index.html", 
            "text": "Accessing Data on S3\n\n\nPrerequisites\n\n\nTo use S3 storage, you must have one or more S3 buckets on your AWS account. For instructions on how to create a bucket on S3, refer to \nAWS documentation\n.\n\n\nConfiguring Access to S3\n\n\nAmazon S3 is not supported as a default file system, but access to data in S3 from your cluster VMs can be automatically configured through attaching an instance profile allowing access to S3. You can optionally create or attach an existing instance profile during \ncluster creation\n, on the \nChoose Blueprint\n page. \n\n\nAccess Path\n\n\nAmazon S3 access path syntax is:\n\n\ns3a://\n/\n/\n\n\n\nFor example, to access a file called \"mytestfile\" in a directory called \"mytestdir\", which is stored in a bucket called \"mytestbucket\", the URL is:\n\n\ns3a://mytestbucket/mytestdir/mytestfile\n\n\n\nThe following FileSystem shell commands demonstrate access to a bucket named \"mytestbucket\": \n\n\nhadoop fs -ls s3a://mytestbucket/\n\nhadoop fs -mkdir s3a://mytestbucket/testDir\n\nhadoop fs -put testFile s3a://mytestbucket/testFile\n\nhadoop fs -cat s3a://mytestbucket/testFile\ntest file content\n\n\n\nLearn More\n\n\nFor more information about configuring the S3 connector and working with data stored on S3, refer to \nCloud Data Access\n documentation.", 
            "title": "Access Data on S3"
        }, 
        {
            "location": "/aws-data/index.html#accessing-data-on-s3", 
            "text": "", 
            "title": "Accessing Data on S3"
        }, 
        {
            "location": "/aws-data/index.html#prerequisites", 
            "text": "To use S3 storage, you must have one or more S3 buckets on your AWS account. For instructions on how to create a bucket on S3, refer to  AWS documentation .", 
            "title": "Prerequisites"
        }, 
        {
            "location": "/aws-data/index.html#configuring-access-to-s3", 
            "text": "Amazon S3 is not supported as a default file system, but access to data in S3 from your cluster VMs can be automatically configured through attaching an instance profile allowing access to S3. You can optionally create or attach an existing instance profile during  cluster creation , on the  Choose Blueprint  page.", 
            "title": "Configuring Access to S3"
        }, 
        {
            "location": "/aws-data/index.html#access-path", 
            "text": "Amazon S3 access path syntax is:  s3a:// / /  For example, to access a file called \"mytestfile\" in a directory called \"mytestdir\", which is stored in a bucket called \"mytestbucket\", the URL is:  s3a://mytestbucket/mytestdir/mytestfile  The following FileSystem shell commands demonstrate access to a bucket named \"mytestbucket\":   hadoop fs -ls s3a://mytestbucket/\n\nhadoop fs -mkdir s3a://mytestbucket/testDir\n\nhadoop fs -put testFile s3a://mytestbucket/testFile\n\nhadoop fs -cat s3a://mytestbucket/testFile\ntest file content", 
            "title": "Access Path"
        }, 
        {
            "location": "/aws-data/index.html#learn-more", 
            "text": "For more information about configuring the S3 connector and working with data stored on S3, refer to  Cloud Data Access  documentation.", 
            "title": "Learn More"
        }, 
        {
            "location": "/azure-launch/index.html", 
            "text": "Launch Cloudbreak on Azure\n\n\nMeet the Prerequisites\n\n\nBefore launching Cloudbreak on Azure, you must meet the following prerequisites.\n\n\nAzure Account\n\n\nIn order to launch Cloubdreak on the Azure Marketplace, you need to log in to your existing Microsoft Azure account. If you don't have an account, you can set it up at \nhttps://azure.microsoft.com\n.\n\n\nAzure Roles\n\n\nIn order to provision clusters on Azure, Cloudbreak must be able to assume a sufficient Azure role (\"Owner\" or \"Contributor\") via Cloudbreak credential: \n\n\n\n\n\n\nYour account must have the \"\nOwner\n\" role in the subscription in order to \ncreate a Cloudbreak credential\n using the interactive credential method. \n\n\n\n\n\n\nYour account must have the \"\nContributor\n\" role (or higher) in the subscription in order to \ncreate a Cloudbreak credential\n using the app-based credential method. \n\n\n\n\n\n\nTo check the roles that your subscription has, in your Azure account navigate to \nSubscriptions\n. \n\n\nAzure Region\n\n\nDecide in which Azure region you would like to launch Cloudbreak. You can launch Cloudbreak and provision your clusters in all regions \nsupported by Microsoft Azure\n. \n\n\nClusters created via Cloudbreak can be in the same or different region as Cloudbreak; when you launch a cluster, you select the region in which to launch it.\n\n\nSSH Key Pair\n\n\nWhen launching Cloudbreak, you will be required to provide your public SSH key. If needed, you can generate a new SSH keypair using \nssh-keygen -t rsa -b 4096 -C \"your_email@example.com\"\n\n\nLaunch Cloudbreak\n\n\nYou have two options to launch Cloudbreak on Azure:\n\n\n\n\nLaunch via Azure Resource Manager Template\n\n\nLaunch from Azure Marketplace (Technical Preview)\n\n\n\n\n(Option 1) Launch via Azure Resource Manager Template\n\n\n\n\n\n\nLog in to your \nAzure Portal\n.\n\n\n\n\n\n\nClick here to get started with Cloudbreak installation using the Azure Resource Manager template:\n\n\n \n\n\n\n\n\n\nThe template for installing Cloudbreak will appear. On the \nBasics\n page, provide the following basic parameters:   \n\n\nBASICS\n\n\n\n\n\n\n\n\nParameter\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nSubscription\n\n\nSelect which existing subscription you want to use.\n\n\n\n\n\n\nResource group\n\n\nOnly \nCreate new\n is supported. Select \nCreate new\n to create a new resource group and enter a name for your new resource group. Cloudbreak resources will later be accessible in that chosen resource group.\n\n\n\n\n\n\nLocation\n\n\nSelect an Azure region in which you want to deploy Cloudbreak.\n\n\n\n\n\n\n\n\nSETTINGS\n\n\n\n\n\n\n\n\nParameter\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nVM Size\n\n\nSelect virtual machine instance type to use for the Cloudbreak controller. The minimum instance type suitable for Cloudbreak is \nD2\n.\n\n\n\n\n\n\nAdmin Username\n\n\nCreate an admin login that you will use to log in to the Cloudbreak UI. Must be a valid email address.\n\n\n\n\n\n\nAdmin User Password\n\n\nPassword for the admin login. Must be at least 8 characters containing letters, numbers, and symbols.\n\n\n\n\n\n\nUsername\n\n\nEnter an admin username for the virtual machine. You will use it to SSH to the VM.\n\n\n\n\n\n\nSmartSense\n\n\nSelect whether you want to use SmartSense telemetry. Default is \"false\" (not using SmartSense telemetry).\n\n\n\n\n\n\nRemote Location\n\n\nAllow connections from this address range. Enter a valid \nCIDR IP\n or enter \nINTERNET\n. For example: \n10.0.0.0/24 will allow access from 10.0.0.0 through 10.0.0.255\nINTERNET will allow access from all.\nVIRTUAL_NETWORK and LOAD_BALANCER are currently not supported.\n\n\n\n\n\n\nSsh Key\n\n\nPaste your SSH public key.\nYou can use \npbcopy\n to quickly copy it. For example: \npbcopy \n /Users/homedir/.ssh/id_rsa.pub\n\n\n\n\n\n\n\n\n\n\n\n\nReview terms of use and check \"I agree to the terms and conditions stated above\". \n\n\n\n\n\n\nClick \nPurchase\n.\n\n\n\n\n\n\nProceed to the next step: \nExplore Newly Created Resources\n\n\n\n\n\n\n(Option 2) Launch from Azure Marketplace\n\n\n\n\nThis feature is Technical Preview.  \n\n\n\n\n\n\n\n\nLog in to your \nAzure Portal\n.\n\n\n\n\n\n\nFrom the services menu, select \n.\n\n\n\n\n\n\nIn the search box, enter \"Cloudbreak\":  \n\n\n  \n\n\n\n\n\n\nSelect \n.\n\n    The information about the Cloudbreak for Hortonworks Data Platform will be displayed.\n    In the bottom of the page, you will see a dropdown for selecting a deployment model, with the \nResource Manager\n deployment model pre-selected. This is the only deployment model available for this offering.\n\n\n\n\n\n\nClick \nCreate\n.   \n\n\n\n\n\n\nThe template for installing Cloudbreak will appear. On the \nBasics\n page, provide the following basic parameters:\n\n\n\n\n\n\n\n\nParameter\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nAdministrator email address\n\n\nCreate an admin login that you will use to log in to the Cloudbreak UI. Must be a valid email address.\n\n\n\n\n\n\nAdministrator user password\n\n\nPassword for the admin login. Must be at least 8 characters containing letters, numbers, and symbols.\n\n\n\n\n\n\nConfirm password\n\n\nConfirm the password for the admin login.\n\n\n\n\n\n\nVM Username\n\n\nEnter an admin username for the virtual machine. You will use it to SSH to the VM.\n\n\n\n\n\n\nVM SSH public key\n\n\nPaste your SSH public key.\nYou can use \npbcopy\n to quickly copy it. For example: \npbcopy \n /Users/homedir/.ssh/id_rsa.pub\n\n\n\n\n\n\nSubscription\n\n\nSelect which existing subscription you want to use.\n\n\n\n\n\n\nResource group\n\n\nOnly \nCreate new\n is supported. Select \nCreate new\n to create a new resource group and enter a name for your new resource group. Cloudbreak resources will later be accessible in that chosen resource group.\n\n\n\n\n\n\nLocation\n\n\nSelect an Azure region in which you want to deploy Cloudbreak.\n\n\n\n\n\n\n\n\n\n\n\n\nOnce done, click \nOK\n.\n\n\n\n\n\n\nOn the \nAdvanced Settings\n page, provide the following advanced parameters:\n\n\n\n\n\n\n\n\nParameter\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nController Instance Type\n\n\nSelect virtual machine instance type to use for the Cloudbreak controller. The minimum instance type suitable for Cloudbreak is \nD2\n. For more information about instance types on Azure refer to \nAzure documentation\n.\n\n\n\n\n\n\nAllow connections to the cloud controller from this address range or \ndefault tag\n\n\nEnter a valid \nCIDR IP\n or enter \nInternet\n. For example: \n10.0.0.0/24 will allow access from 10.0.0.0 through 10.0.0.255\n'Internet' will allow access from all.\n(Advanced) 'VirtualNetwork' will allow access from the address space of the Virtual Network.\n (Advanced) 'AzureLoadBalancer' will allow access from the address space of the load balancer.\nFor more information, refer to the \nAzure documentation\n.\n\n\n\n\n\n\nEnable SmartSense\n\n\n(Optional) Select whether to enable SmartSense telemetry. Default is \"I have read and opt-in to SmartSense telemetry. For more information about SmartSense, refer to the \nHortonworks website\n.\n\n\n\n\n\n\nEnter your existing SmartSenseID (if available). You must also opt-in to SmartSense telemetry above\n\n\n(Optional) Enter your existing SmartSenseID.\n\n\n\n\n\n\nVirtual network\n\n\nCreate a new Vnet (default) or select an existing Vnet.\n\n\n\n\n\n\nSubnets\n\n\nIf you created a new Vnet, create subnets within it. If selected an existing Vnet, select exiting subnets.\n\n\n\n\n\n\n\n\n\n\n\n\nOnce done, click \nOK\n.\n\n\n\n\n\n\nOn the \nSummary\n page, validate the information that you provided. \n    Before proceeding to the next page, you have an option to \nDownload template and parameters\n. You can use them to create the Cloudbreak controller via CLI. Once done, click \nOK\n.\n\n\n\n\n\n\nReview terms of use and click \nPurchase\n.\n\n\n\n\n\n\nProceed to the next step: \nExplore Newly Created Resources\n\n\n\n\n\n\nExplore Newly Created Resources\n\n\n\n\nThis step is optional.  \n\n\n\n\nWhile the deployment is in progress, you can optionally navigate to the newly created resource group and see what Azure resources are being created.\n\n\n\n\n\n\nFrom the left pane, select \n.\n\n\n\n\n\n\nFind the the resource group that you just created and select it to view details.\n\n\n\n\n\n\nThe following resources should have been created in your resource group:\n\n\n\n\n\n\nIf you chose to use an existing virtual network, the virtual network will not be added to the resource group. \n\n\n\n\n\n\nVirtual network\n (VNet) securely connects Azure resources to each other.    \n\n\nNetwork security group\n (NSG) defines inbound and outbound security rules, which control network traffic flow.  \n\n\nVirtual machine\n runs Cloudbreak.   \n\n\nPublic IP address\n is assigned to your VM so that it can communicate with other Azure resources.  \n\n\nNetwork interface\n (NIC) attached to the VM provides the interconnection between the VM and the underlying software network.    \n\n\nBlob storage container\n is created to store Cloudbreak Deployer OS disk's data.  \n\n\n\n\n\n\n\n\nYou can click on each entry to view details of the resource. For example, click on \n to view details, including Cloudbreak IP address.\n\n\n\n\n\n\nOnce your deployment is ready, the status will change from \"Deploying\" to \"Success\".\n\n\n\n\n\n\nAccess Cloudbreak UI\n\n\n\n\n\n\nWhen your deployment succeeds, you will receive a notification in the top-right corner. Click on the notification to navigate to the deployed resource. \n\n\n\n\n\n\nFrom \nOutputs\n, you can copy the link by clicking on the \n icon:\n\n\n   \n\n\n\n\n\n\nPaste the link in your browser's address bar.\n\n\nThe first time you access Cloudbreak UI, Cloudbreak will automatically generate a self-signed certificate, due to which your browser will warn you about an untrusted connection and will ask you to confirm a security exception.\n\n\n\n\n\n\n\n\nBrowser\n\n\nSteps\n\n\n\n\n\n\n\n\n\n\nFirefox\n\n\nClick \nAdvanced\n \n Click \nAdd Exception...\n \n Click \nConfirm Security Exception\n\n\n\n\n\n\nSafari\n\n\nClick \nContinue\n\n\n\n\n\n\nChrome\n\n\nClick \nAdvanced\n \n Click \nProceed...\n\n\n\n\n\n\n\n\n\n\n\n\nNow you should be able to access Cloudbreak UI and log in with the \nAdmin email address\n and \nAdmin password\n that you created when launching Cloudbreak:\n\n\n\n\nThe last task that you need to perform before you can use Cloudbreak is to \ncreate a cloudbreak credential\n.     \n\n\n\n\n\n\nCreate Cloudbreak Credential\n\n\nThe first time you log in to the Cloudbreak UI, you should see \nmanage credentials\n tab open, informing you that to use Cloudbreak you first need to create a credential associated with your Azure subscription. Cloudbreak works by connecting your Azure account through this credential, and then uses it to create resources on your behalf.\n\n\nBefore you can start provisioning cluster using Cloudbreak, you must create a Cloudbreak credential. There are two ways to do this: \n\n\n\n\n\n\nInteractive\n: This is the recommended simpler method. The advantage of using this method is that the app and service principal creation and role assignment is fully automated, so the only input that you need to provide is the name and the SSH key. To configure an interactive credential, refer to \nCreate an Interactive Credential\n.  \n\n\n\n\n\n\nApp-based\n: This is the more complex method. The advantage of the app-based credential creation is that it allows you to create a credential without logging in to the Azure account, as long as you have been given all the information. In addition to providing your \ntenant_id\n and \nsubscription_id\n, you must provide information for your previously created Azure AD application, including its password. When using this method, we recommend that you use a utility called \nazure-cli-tools\n. The utility supports app creation and role assignment. It is available at \nhttps://github.com/sequenceiq/azure-cli-tools/blob/master/cli_tools\n. If you choose not to use this utility, the app-based configuration process is error-prone with many steps involved. To configure an app based credential, refer to \nCreate an App Based Credential\n.  \n\n\n\n\n\n\nCreate an Interactive Credential\n\n\n\n\n\n\nOpen the \nmanage credentials\n pane:\n\n\n\n\n\n\n\n\nClick \nNext\n.\n\n\n\n\n\n\nOn the \nConfigure credentials\n page, provide the following parameters:\n\n\n\n\n\n\n\n\nParameter\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nSelect Credential Type\n\n\nThe \nInteractive\n credential type should be pre-selected.\n\n\n\n\n\n\nName\n\n\nEnter a name for your credential.\n\n\n\n\n\n\nDescription\n\n\n(Optional) Enter a description.\n\n\n\n\n\n\nSSH Public Key\n\n\nThe SSH key that you provided when launching Cloudbreak should be pre-entered.\n\n\n\n\n\n\nSelect Azure role type\n\n\nYou have the following options:\n\"Use existing Contributor role\" (default): If you select this option, Cloudbreak will use the \"\nContributor\n\" role to create resources. This requires no further input.\n\"Reuse existing custom role\": If you select this option and enter the name of an existing role, Cloudbreak will use this role to create resources.\n\"Let Cloudbreak create a custom role\": If you select this option and enter a name for the new role, the role will be created. When choosing role name, make sure that there is no existing role with the name chosen. For information on creating custom roles, refer to \nAzure\n documentation. \nIf using a custom role, make sure that it includes the necessary Action set for Cloudbreak to be able to manage clusters: \nMicrosoft.Compute/*\n, \nMicrosoft.Network/*\n, \nMicrosoft.Storage/*\n, \nMicrosoft.Resources/*\n.\n\n\n\n\n\n\nSelect Platform\n\n\n(Optional) Select a platform (if previously configured).\n\n\n\n\n\n\nPublic In Account\n\n\n(Optional) If you check this, other users added to your Cloudbreak instance will be able to use this credential to create clusters.\n\n\n\n\n\n\n\n\n\n\n\n\nClick \nNext\n.\n\n\n\n\n\n\nOn the \nFinish\n page, click on the \n icon next to the randomly generated code to copy it.\n\n\n\n\n\n\nClick \nAzure login\n and a new \nDevice login\n page will open in a new browser tab:\n\n\n  \n\n\n\n\n\n\nNext, paste the code in field on the  \nDevice login\n page and click \nContinue\n.\n\n\n\n\n\n\nConfirm your account by selecting it:\n\n\n\n\n\n\n\n\nA confirmation page will appear, confirming that you have signed in to the Microsoft Azure Cross-platform Command Line Interface application on your device. You may now close this window.\n\n\n\n\n\n\nYour credential should now be displayed in the \nmanage credentials\n tab.\n\n\nCongratulations! You've successfully launched and configured Cloudbreak. Now you can use Cloudbreak to \ncreate clusters\n.\n\n\n\n\n\n\nCreate an App Based Credential\n\n\n\n\n\n\nOn Azure Portal, navigate to the \nAzure Active Directory\n and register a new application:\n\n\n\n\n\n\n\n\nNavigate to the \nSubscriptions\n and assign the \"Contributor\" role to your newly created application:\n\n\n   \n\n\n\n\n\n\nIn the Cloudbreak web UI, open the \nmanage credentials\n pane:\n\n\n\n\n\n\n\n\nClick \nNext\n.\n\n\n\n\n\n\nOn the \nConfigure credential\n page, provide the following parameters:\n\n\n\n\n\n\n\n\nParameter\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nSelect Credential Type\n\n\nSelect \nApp based\n.\n\n\n\n\n\n\nName\n\n\nEnter a name for your credential.\n\n\n\n\n\n\nDescription\n\n\n(Optional) Enter a description.\n\n\n\n\n\n\nSubscription Id\n\n\nCopy and paste the Subscription ID from your \nSubscriptions\n.\n\n\n\n\n\n\nApp Id\n\n\nCopy and paste the Application ID from your \nAzure Active Directory\n app registration's \nSettings\n \n \nProperties\n.\n\n\n\n\n\n\nPassword\n\n\nThis is your application key. You can obtain it from your from your \nAzure Active Directory\n app registration's \nSettings\n \n \nKeys\n.\n\n\n\n\n\n\nApp Owner Tenant Id\n\n\nPaste your App Owner Tenant Id. There are multiple ways to obtain it. For example, you can find it in the \nPortalDiagnostics.json\n file, which can be downloaded by clicking on \n in the top-right corner and then selecting \nShow Diagnostics\n.\n\n\n\n\n\n\nSSH Public Key\n\n\nThe SSH key that you provided when launching Cloudbreak should be pre-entered.\n\n\n\n\n\n\nSelect Azure role type\n\n\nYou have the following options:\n\"Use existing Contributor role\" (default): If you select this option, Cloudbreak will use the \"\nContributor\n\" role to create resources. This requires no further input.\n\"Reuse existing custom role\": If you select this option and enter the name of an existing role, Cloudbreak will use this role to create resources.\n\"Let Cloudbreak create a custom role\": If you select this option and enter a name for the new role, the role will be created. When choosing role name, make sure that there is no existing role with the name chosen. For information on creating custom roles, refer to \nAzure\n documentation. \nIf using a custom role, make sure that it includes the necessary Action set for Cloudbreak to be able to manage clusters: \nMicrosoft.Compute/*\n, \nMicrosoft.Network/*\n, \nMicrosoft.Storage/*\n, \nMicrosoft.Resources/*\n.\n\n\n\n\n\n\nSelect Platform\n\n\n(Optional) Select a platform (if previously configured).\n\n\n\n\n\n\nPublic In Account\n\n\n(Optional) If you check this, other users added to your Cloudbreak instance will be able to use this credential to create clusters.\n\n\n\n\n\n\n\n\n\n\n\n\nClick \nNext\n and then \nFinish\n.\n\n\n\n\n\n\nYour credential should now be displayed at the top of the page in the \nmanage credentials\n tab.\n\n\nCongratulations! You've successfully launched and configured Cloudbreak. \n\n\n\n\n\n\n\n\nNext: Define Infrastructure Templates", 
            "title": "Launch on Azure"
        }, 
        {
            "location": "/azure-launch/index.html#launch-cloudbreak-on-azure", 
            "text": "", 
            "title": "Launch Cloudbreak on Azure"
        }, 
        {
            "location": "/azure-launch/index.html#meet-the-prerequisites", 
            "text": "Before launching Cloudbreak on Azure, you must meet the following prerequisites.", 
            "title": "Meet the Prerequisites"
        }, 
        {
            "location": "/azure-launch/index.html#azure-account", 
            "text": "In order to launch Cloubdreak on the Azure Marketplace, you need to log in to your existing Microsoft Azure account. If you don't have an account, you can set it up at  https://azure.microsoft.com .", 
            "title": "Azure Account"
        }, 
        {
            "location": "/azure-launch/index.html#azure-roles", 
            "text": "In order to provision clusters on Azure, Cloudbreak must be able to assume a sufficient Azure role (\"Owner\" or \"Contributor\") via Cloudbreak credential:     Your account must have the \" Owner \" role in the subscription in order to  create a Cloudbreak credential  using the interactive credential method.     Your account must have the \" Contributor \" role (or higher) in the subscription in order to  create a Cloudbreak credential  using the app-based credential method.     To check the roles that your subscription has, in your Azure account navigate to  Subscriptions .", 
            "title": "Azure Roles"
        }, 
        {
            "location": "/azure-launch/index.html#azure-region", 
            "text": "Decide in which Azure region you would like to launch Cloudbreak. You can launch Cloudbreak and provision your clusters in all regions  supported by Microsoft Azure .   Clusters created via Cloudbreak can be in the same or different region as Cloudbreak; when you launch a cluster, you select the region in which to launch it.", 
            "title": "Azure Region"
        }, 
        {
            "location": "/azure-launch/index.html#ssh-key-pair", 
            "text": "When launching Cloudbreak, you will be required to provide your public SSH key. If needed, you can generate a new SSH keypair using  ssh-keygen -t rsa -b 4096 -C \"your_email@example.com\"", 
            "title": "SSH Key Pair"
        }, 
        {
            "location": "/azure-launch/index.html#launch-cloudbreak", 
            "text": "You have two options to launch Cloudbreak on Azure:   Launch via Azure Resource Manager Template  Launch from Azure Marketplace (Technical Preview)", 
            "title": "Launch Cloudbreak"
        }, 
        {
            "location": "/azure-launch/index.html#option-1-launch-via-azure-resource-manager-template", 
            "text": "Log in to your  Azure Portal .    Click here to get started with Cloudbreak installation using the Azure Resource Manager template:       The template for installing Cloudbreak will appear. On the  Basics  page, provide the following basic parameters:     BASICS     Parameter  Description      Subscription  Select which existing subscription you want to use.    Resource group  Only  Create new  is supported. Select  Create new  to create a new resource group and enter a name for your new resource group. Cloudbreak resources will later be accessible in that chosen resource group.    Location  Select an Azure region in which you want to deploy Cloudbreak.     SETTINGS     Parameter  Description      VM Size  Select virtual machine instance type to use for the Cloudbreak controller. The minimum instance type suitable for Cloudbreak is  D2 .    Admin Username  Create an admin login that you will use to log in to the Cloudbreak UI. Must be a valid email address.    Admin User Password  Password for the admin login. Must be at least 8 characters containing letters, numbers, and symbols.    Username  Enter an admin username for the virtual machine. You will use it to SSH to the VM.    SmartSense  Select whether you want to use SmartSense telemetry. Default is \"false\" (not using SmartSense telemetry).    Remote Location  Allow connections from this address range. Enter a valid  CIDR IP  or enter  INTERNET . For example:  10.0.0.0/24 will allow access from 10.0.0.0 through 10.0.0.255 INTERNET will allow access from all. VIRTUAL_NETWORK and LOAD_BALANCER are currently not supported.    Ssh Key  Paste your SSH public key. You can use  pbcopy  to quickly copy it. For example:  pbcopy   /Users/homedir/.ssh/id_rsa.pub       Review terms of use and check \"I agree to the terms and conditions stated above\".     Click  Purchase .    Proceed to the next step:  Explore Newly Created Resources", 
            "title": "(Option 1) Launch via Azure Resource Manager Template"
        }, 
        {
            "location": "/azure-launch/index.html#option-2-launch-from-azure-marketplace", 
            "text": "This feature is Technical Preview.       Log in to your  Azure Portal .    From the services menu, select  .    In the search box, enter \"Cloudbreak\":          Select  . \n    The information about the Cloudbreak for Hortonworks Data Platform will be displayed.\n    In the bottom of the page, you will see a dropdown for selecting a deployment model, with the  Resource Manager  deployment model pre-selected. This is the only deployment model available for this offering.    Click  Create .       The template for installing Cloudbreak will appear. On the  Basics  page, provide the following basic parameters:     Parameter  Description      Administrator email address  Create an admin login that you will use to log in to the Cloudbreak UI. Must be a valid email address.    Administrator user password  Password for the admin login. Must be at least 8 characters containing letters, numbers, and symbols.    Confirm password  Confirm the password for the admin login.    VM Username  Enter an admin username for the virtual machine. You will use it to SSH to the VM.    VM SSH public key  Paste your SSH public key. You can use  pbcopy  to quickly copy it. For example:  pbcopy   /Users/homedir/.ssh/id_rsa.pub    Subscription  Select which existing subscription you want to use.    Resource group  Only  Create new  is supported. Select  Create new  to create a new resource group and enter a name for your new resource group. Cloudbreak resources will later be accessible in that chosen resource group.    Location  Select an Azure region in which you want to deploy Cloudbreak.       Once done, click  OK .    On the  Advanced Settings  page, provide the following advanced parameters:     Parameter  Description      Controller Instance Type  Select virtual machine instance type to use for the Cloudbreak controller. The minimum instance type suitable for Cloudbreak is  D2 . For more information about instance types on Azure refer to  Azure documentation .    Allow connections to the cloud controller from this address range or  default tag  Enter a valid  CIDR IP  or enter  Internet . For example:  10.0.0.0/24 will allow access from 10.0.0.0 through 10.0.0.255 'Internet' will allow access from all. (Advanced) 'VirtualNetwork' will allow access from the address space of the Virtual Network.  (Advanced) 'AzureLoadBalancer' will allow access from the address space of the load balancer. For more information, refer to the  Azure documentation .    Enable SmartSense  (Optional) Select whether to enable SmartSense telemetry. Default is \"I have read and opt-in to SmartSense telemetry. For more information about SmartSense, refer to the  Hortonworks website .    Enter your existing SmartSenseID (if available). You must also opt-in to SmartSense telemetry above  (Optional) Enter your existing SmartSenseID.    Virtual network  Create a new Vnet (default) or select an existing Vnet.    Subnets  If you created a new Vnet, create subnets within it. If selected an existing Vnet, select exiting subnets.       Once done, click  OK .    On the  Summary  page, validate the information that you provided. \n    Before proceeding to the next page, you have an option to  Download template and parameters . You can use them to create the Cloudbreak controller via CLI. Once done, click  OK .    Review terms of use and click  Purchase .    Proceed to the next step:  Explore Newly Created Resources", 
            "title": "(Option 2) Launch from Azure Marketplace"
        }, 
        {
            "location": "/azure-launch/index.html#explore-newly-created-resources", 
            "text": "This step is optional.     While the deployment is in progress, you can optionally navigate to the newly created resource group and see what Azure resources are being created.    From the left pane, select  .    Find the the resource group that you just created and select it to view details.    The following resources should have been created in your resource group:    If you chose to use an existing virtual network, the virtual network will not be added to the resource group.     Virtual network  (VNet) securely connects Azure resources to each other.      Network security group  (NSG) defines inbound and outbound security rules, which control network traffic flow.    Virtual machine  runs Cloudbreak.     Public IP address  is assigned to your VM so that it can communicate with other Azure resources.    Network interface  (NIC) attached to the VM provides the interconnection between the VM and the underlying software network.      Blob storage container  is created to store Cloudbreak Deployer OS disk's data.       You can click on each entry to view details of the resource. For example, click on   to view details, including Cloudbreak IP address.    Once your deployment is ready, the status will change from \"Deploying\" to \"Success\".", 
            "title": "Explore Newly Created Resources"
        }, 
        {
            "location": "/azure-launch/index.html#access-cloudbreak-ui", 
            "text": "When your deployment succeeds, you will receive a notification in the top-right corner. Click on the notification to navigate to the deployed resource.     From  Outputs , you can copy the link by clicking on the   icon:         Paste the link in your browser's address bar.  The first time you access Cloudbreak UI, Cloudbreak will automatically generate a self-signed certificate, due to which your browser will warn you about an untrusted connection and will ask you to confirm a security exception.     Browser  Steps      Firefox  Click  Advanced    Click  Add Exception...    Click  Confirm Security Exception    Safari  Click  Continue    Chrome  Click  Advanced    Click  Proceed...       Now you should be able to access Cloudbreak UI and log in with the  Admin email address  and  Admin password  that you created when launching Cloudbreak:   The last task that you need to perform before you can use Cloudbreak is to  create a cloudbreak credential .", 
            "title": "Access Cloudbreak UI"
        }, 
        {
            "location": "/azure-launch/index.html#create-cloudbreak-credential", 
            "text": "The first time you log in to the Cloudbreak UI, you should see  manage credentials  tab open, informing you that to use Cloudbreak you first need to create a credential associated with your Azure subscription. Cloudbreak works by connecting your Azure account through this credential, and then uses it to create resources on your behalf.  Before you can start provisioning cluster using Cloudbreak, you must create a Cloudbreak credential. There are two ways to do this:     Interactive : This is the recommended simpler method. The advantage of using this method is that the app and service principal creation and role assignment is fully automated, so the only input that you need to provide is the name and the SSH key. To configure an interactive credential, refer to  Create an Interactive Credential .      App-based : This is the more complex method. The advantage of the app-based credential creation is that it allows you to create a credential without logging in to the Azure account, as long as you have been given all the information. In addition to providing your  tenant_id  and  subscription_id , you must provide information for your previously created Azure AD application, including its password. When using this method, we recommend that you use a utility called  azure-cli-tools . The utility supports app creation and role assignment. It is available at  https://github.com/sequenceiq/azure-cli-tools/blob/master/cli_tools . If you choose not to use this utility, the app-based configuration process is error-prone with many steps involved. To configure an app based credential, refer to  Create an App Based Credential .", 
            "title": "Create Cloudbreak Credential"
        }, 
        {
            "location": "/azure-launch/index.html#create-an-interactive-credential", 
            "text": "Open the  manage credentials  pane:     Click  Next .    On the  Configure credentials  page, provide the following parameters:     Parameter  Description      Select Credential Type  The  Interactive  credential type should be pre-selected.    Name  Enter a name for your credential.    Description  (Optional) Enter a description.    SSH Public Key  The SSH key that you provided when launching Cloudbreak should be pre-entered.    Select Azure role type  You have the following options: \"Use existing Contributor role\" (default): If you select this option, Cloudbreak will use the \" Contributor \" role to create resources. This requires no further input. \"Reuse existing custom role\": If you select this option and enter the name of an existing role, Cloudbreak will use this role to create resources. \"Let Cloudbreak create a custom role\": If you select this option and enter a name for the new role, the role will be created. When choosing role name, make sure that there is no existing role with the name chosen. For information on creating custom roles, refer to  Azure  documentation.  If using a custom role, make sure that it includes the necessary Action set for Cloudbreak to be able to manage clusters:  Microsoft.Compute/* ,  Microsoft.Network/* ,  Microsoft.Storage/* ,  Microsoft.Resources/* .    Select Platform  (Optional) Select a platform (if previously configured).    Public In Account  (Optional) If you check this, other users added to your Cloudbreak instance will be able to use this credential to create clusters.       Click  Next .    On the  Finish  page, click on the   icon next to the randomly generated code to copy it.    Click  Azure login  and a new  Device login  page will open in a new browser tab:        Next, paste the code in field on the   Device login  page and click  Continue .    Confirm your account by selecting it:     A confirmation page will appear, confirming that you have signed in to the Microsoft Azure Cross-platform Command Line Interface application on your device. You may now close this window.    Your credential should now be displayed in the  manage credentials  tab.  Congratulations! You've successfully launched and configured Cloudbreak. Now you can use Cloudbreak to  create clusters .", 
            "title": "Create an Interactive Credential"
        }, 
        {
            "location": "/azure-launch/index.html#create-an-app-based-credential", 
            "text": "On Azure Portal, navigate to the  Azure Active Directory  and register a new application:     Navigate to the  Subscriptions  and assign the \"Contributor\" role to your newly created application:         In the Cloudbreak web UI, open the  manage credentials  pane:     Click  Next .    On the  Configure credential  page, provide the following parameters:     Parameter  Description      Select Credential Type  Select  App based .    Name  Enter a name for your credential.    Description  (Optional) Enter a description.    Subscription Id  Copy and paste the Subscription ID from your  Subscriptions .    App Id  Copy and paste the Application ID from your  Azure Active Directory  app registration's  Settings     Properties .    Password  This is your application key. You can obtain it from your from your  Azure Active Directory  app registration's  Settings     Keys .    App Owner Tenant Id  Paste your App Owner Tenant Id. There are multiple ways to obtain it. For example, you can find it in the  PortalDiagnostics.json  file, which can be downloaded by clicking on   in the top-right corner and then selecting  Show Diagnostics .    SSH Public Key  The SSH key that you provided when launching Cloudbreak should be pre-entered.    Select Azure role type  You have the following options: \"Use existing Contributor role\" (default): If you select this option, Cloudbreak will use the \" Contributor \" role to create resources. This requires no further input. \"Reuse existing custom role\": If you select this option and enter the name of an existing role, Cloudbreak will use this role to create resources. \"Let Cloudbreak create a custom role\": If you select this option and enter a name for the new role, the role will be created. When choosing role name, make sure that there is no existing role with the name chosen. For information on creating custom roles, refer to  Azure  documentation.  If using a custom role, make sure that it includes the necessary Action set for Cloudbreak to be able to manage clusters:  Microsoft.Compute/* ,  Microsoft.Network/* ,  Microsoft.Storage/* ,  Microsoft.Resources/* .    Select Platform  (Optional) Select a platform (if previously configured).    Public In Account  (Optional) If you check this, other users added to your Cloudbreak instance will be able to use this credential to create clusters.       Click  Next  and then  Finish .    Your credential should now be displayed at the top of the page in the  manage credentials  tab.  Congratulations! You've successfully launched and configured Cloudbreak.      Next: Define Infrastructure Templates", 
            "title": "Create an App Based Credential"
        }, 
        {
            "location": "/azure-config/index.html", 
            "text": "Define Infrastructure Templates\n\n\nAfter you've logged in to Cloudbreak and created a Cloudbreak credential, you have two options:\n\n\n\n\nCreate clusters using default infrastructure templates      \n\n\nDefine your own infrastructure templates   \n\n\n\n\nThe \ninfrastructure templates\n for resources such as \nnetworks\n, \nsecurity groups\n, and \nVMs and storage\n are saved to Cloudbreak's database and can be reused with multiple clusters to describe the infrastructure. When you add these resources in Cloudbreak web UI, Cloudbreak does not make any requests to your cloud provider account. Resources are only created on your cloud provider account after the create cluster button has been pushed. \n\n\nThis is illustrated and further explained in the \nArchitecture\n documentation.\n\n\nWe recommend that you review the default infrastructure  templates for networks, security groups, and VMs and storage to check if they meet your requirements. You can do this by expanding  their corresponding panes in the Cloudbreak web UI (shown in the screenshot) or by reading the documentation below.  \n\n\n \n\n\nThe following table describes the basic configurations that require an infrastructure template. If the default infrastructure templates don't work for you, you must create custom templates.\n\n\n\n\n\n\n\n\nConfiguration\n\n\nDescription\n\n\nCreate Cluster\n\n\n\n\n\n\n\n\n\n\nNetworks\n\n\n(Required) Virtual networks provide the networking infrastructure (network, subnet, Internet gateway, and so on) in which your clusters run. You can create new virtual networks or reuse existing virtual networks for your clusters. Virtual networks on Azure are called Azure Virtual Networks (VNets). For basic information about VNets, refer to \nAzure documentation\n.\n\n\nYou can select the network configuration for your clusters in the \nCreate Cluster\n wizard \n \nSet up Network and Security\n page. If no custom network is selected, default is used.\n\n\n\n\n\n\nSecurity Groups\n\n\n(Required) Security groups include rules which define inbound traffic allowed to the instances in your cluster. You can define different security group configurations for different nodes of your cluster. For basic information about security groups on Azure, refer to \nAzure documentation\n.\n\n\nYou can select the security group configurations for each host group in the \nCreate Cluster\n wizard \n \nChoose Blueprint\n page. If no custom security groups are selected, default is used.\n\n\n\n\n\n\nVMs and Storage\n\n\n(Required) \"Templates\" define the Azure infrastructure for the instances on which your cluster runs. You can select the VM types and their attached storage, including storage type, size, and count. You can reuse the same template for different cluster host groups or create different templates for different host groups.\n\n\nYou can select infrastructure templates for each host group in the \nCreate Cluster\n wizard \n \nChoose Blueprint\n page. If no custom templates are selected, default is used.\n\n\n\n\n\n\n\n\nNetworks\n\n\nYou have three options:\n\n\n\n\nUse the default network configuration template\n: This requires no further action. Every time a cluster is created with this kind of network setup a new virtual network and a new subnet with the specified IP range will be created for the instances on Azure.  \n\n\nCreate a new virtual network and a new subnet\n: Every time a cluster is created with this kind of network setup a new virtual network and a new subnet with the specified IP range will be created for the instances on Azure.          \n\n\nUse an existing subnet in an existing virtual network\n: Use this option if you have an existing virtual network with one or more subnets on Azure and you'd like to start the instances of a cluster in one of those subnets.\n\n\n\n\n\n\nIf you are using an existing subnet, ensure that you have opened all the additional ports required for accessing your cluster in the security group of your subnet.\n\n\n\n\nDefault Network\n\n\nCloudbreak includes one pre-defined network configuration called \ndefault-azure-network\n, which is used by default when creating a cluster.  You can see it in the \nmanage networks\n tab. The configuration is: \n\n\n\n\n\n\n\n\nParameter\n\n\nValue\n\n\n\n\n\n\n\n\n\n\nName\n\n\ndefault-azure-network\n\n\n\n\n\n\nDescription\n\n\nDefault network settings for Azure clusters.\n\n\n\n\n\n\nSubnet (CIDR)\n\n\n10.0.0.0/16\n\n\n\n\n\n\n\n\nWith this default configuration, a new virtual network with a 10.0.0.0/16 subnet will be created every time a cluster is created. No resources will be created until you create a cluster using this configuration.\n\n\nAdd New Network and Subnet\n\n\nYou can define reusable network configurations for your clusters in the \nmanage networks\n tab:\n\n\n\n\n\n\nClick on \nCreate a new virtual network and a new subnet\n.\n\n\n\n\n\n\nProvide required parameters:\n\n\n\n\n\n\n\n\nParameter\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nName\n\n\nEnter a name for your configuration.\n\n\n\n\n\n\nDescription\n\n\n(Optional) Enter a description.\n\n\n\n\n\n\nSubnet (CIDR)\n\n\nEnter a valid \nCIDR\n for a new subnet that will be created within the VNet. For example \n10.0.0.0/24\n.\n\n\n\n\n\n\nPublic In Account\n\n\n(Optional) If this option is checked, all the users belonging to your account will be able to use this network template to create clusters, but they cannot delete it.\n\n\n\n\n\n\nSelect Platform\n\n\n(Optional) Select a previously created platform.\n\n\n\n\n\n\n\n\n\n\n\n\nClick on \n+create network\n.\n\n\nNo resources will be created until you create a cluster using this configuration.\n\n\n\n\n\n\nUse Existing Network and Subnet\n\n\nYou can define reusable network configurations for your clusters in the \nmanage networks\n tab:\n\n\n\n\n\n\nClick on \nUse an existing subnet in an existing virtual network\n. \n\n\n\n\n\n\nProvide required parameters: \n\n\n\n\nMake sure that the new subnet defined here doesn't overlap with any of your already deployed subnets in the network. \n\n\n\n\n\n\n\n\n\n\nParameter\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nName\n\n\nEnter a name for your configuration.\n\n\n\n\n\n\nDescription\n\n\n(Optional) Enter a description.\n\n\n\n\n\n\nResource Group Identifier\n\n\nPaste the name of the resource group in which the network is located on Azure. You can obtain it from your Azure portal by navigating to the \"Properties\" of your virtual network and coping the value of the \"NAME\" property.\n\n\n\n\n\n\nVirtual Network Identifier\n\n\nPaste the name of your existing VNet. You can obtain it from your Azure Portal by coping the value of the \"NAME\" property.\n\n\n\n\n\n\nSubnet Identifier\n\n\nPaste the name of your existing subnet. You can obtain it from your Azure Portal  by coping the value of the \"NAME\" property.\n\n\n\n\n\n\nPublic In Account\n\n\n(Optional) If this option is checked, all the users belonging to your account will be able to use this network template to create clusters, but they cannot delete it.\n\n\n\n\n\n\nDon't create public IPs\n\n\nIf you enable this option, Cloudbreak will not assign public IP address to the VMs. You must make sure that Cloudbreak can access the launched instances and that the instances can reach the internet.\n\n\n\n\n\n\nDon't create new firewall rules\n\n\nIf you enable this option, Cloudbreak will not create security groups. You must make sure (by openining every port in the subnet) that the created instances in the subnet can reach each other.\n\n\n\n\n\n\nPublic In Account\n\n\n(Optional) If this option is checked, all the users belonging to your account will be able to use this network template to create clusters, but they cannot delete it.\n\n\n\n\n\n\nSelect Platform\n\n\n(Optional) Select a previously created platform.\n\n\n\n\n\n\n\n\n\n\n\n\nClick on \n+create network\n.\n\n\nNo resources will be created until you create a cluster using this configuration.\n\n\n\n\n\n\nSecurity Groups\n\n\nYou have two options:\n\n\n\n\nUse the default security group configuration\n: This requires no further action.  \n\n\nAdd your own custom security group configuration\n: You can define your own security group by adding the ports, protocols, and CIDR ranges that you'd like to use. The rules defined here don't need to contain the internal rules (these are automatically added by Cloudbreak to the security group on Azure). \n\n\n\n\nYou can define different security group configurations for different nodes of your cluster.\n\n\nDefault Security Group\n\n\nCloudbreak includes one pre-defined security group configuration called \ndefault-azure-only-ssh-and-ssl\n, which is used by default when creating a cluster. You can see it in the \nmanage security groups\n tab. The configuration is: \n\n\n\n\n\n\n\n\nCIDR\n\n\nPort\n\n\nProtocol\n\n\n\n\n\n\n\n\n\n\n0.0.0.0/0\n\n\n22\n\n\ntcp\n\n\n\n\n\n\n0.0.0.0/0\n\n\n433\n\n\ntcp\n\n\n\n\n\n\n0.0.0.0/0\n\n\n9443\n\n\ntcp\n\n\n\n\n\n\n\n\nNo resources will be created until you create a cluster using this configuration.\n\n\nAdd Custom Security Group\n\n\nYou can define reusable security group configurations for your clusters in the \nmanage security groups\n tab: \n\n\n\n\nClick on \nCreate a new security group\n.\n\n\n\n\nProvide required parameters:\n\n\n\n\n\n\n\n\nParameter\n\n\nValue\n\n\n\n\n\n\n\n\n\n\nName\n\n\nEnter a name for your security group configuration template.\n\n\n\n\n\n\nDescription\n\n\n(Optional) Enter a description.\n\n\n\n\n\n\nPublic In Account\n\n\n(Optional) If this option is checked, all the users belonging to your account will be able to use this security group template to create clusters, but they cannot delete it.\n\n\n\n\n\n\n\n\n\n\n\n\nProvide the following parameters in order to define \nSecurity Rules\n for this security group:\n\n\n\n\n\n\n\n\nParameter\n\n\nValue\n\n\n\n\n\n\n\n\n\n\nCIDR\n\n\nEnter a valid \nCIDR IP\n, from which the cluster will be accessed.\n\n\n\n\n\n\nPort\n\n\nEnter ports that you want to open. You can either list multiple ports, separated by a comma (for example \"22,443,9443\"), or you can define port ranges (for example \"1-65355\").\n\n\n\n\n\n\nProtocol\n\n\nEnter protocol that you want to use.\n\n\n\n\n\n\n\n\n\n\nPorts 22, 443, and 9443 must be open on every security group; otherwise Cloudbreak will not be able to communicate with your provisioned cluster.\n\n\n\n\n\n\n\n\nClick \n+Add Rule\n to save the security rules. If needed, click \n+Add Rule\n again to display a new \nSecurity Rules\n form and add another set of rules. \n\n\n\n\n\n\nClick \n+create security group\n to save the configuration. \n\n\nNo resources will be created until you create a cluster using this configuration.\n\n\n\n\n\n\n\n\nPorts used by Hadoop services: Ambari (8080) Consul (8500) NN (50070) RM Web (8088) Scheduler (8030RM) IPC (8050RM) Job history server (19888) HBase master (60000) HBase master web (60010) HBase RS (16020) HBase RS info (60030) Falcon (15000) Storm (8744) Hive metastore (9083) Hive server (10000) Hive server HTTP (10001) Accumulo master (9999) Accumulo Tserver (9997) Atlas (21000) KNOX (8443) Oozie (11000) Spark HS (18080) NM Web (8042) Zeppelin WebSocket (9996) Zeppelin UI (9995) Kibana (3080)  Elasticsearch (9200)\n\n\n\n\nVMs and Storage\n\n\nYou have two options:\n\n\n\n\nUse the default infrastructure template\n: This requires no further action.  \n\n\nAdd your own custom infrastructure template\n: Use this option if you have specific infrastructure requirements. A typical setup may combine multiple templates in a cluster for the different types of nodes. For example you may want to attach multiple large disks to the data nodes or have memory optimized instances for Spark nodes. \n\n\n\n\nDefault Template\n\n\nCloudbreak includes one pre-defined infrastructure template called \nminviable-azure\n, which is used by default when creating a cluster. You can see it in the \nmanage templates\n tab. The configuration is:\n\n\n\n\n\n\n\n\nParameter\n\n\nValue\n\n\n\n\n\n\n\n\n\n\nName\n\n\nminviable-azure\n\n\n\n\n\n\nVM Type\n\n\nStandard_D4\n\n\n\n\n\n\nVolume Type\n\n\nLocally-redundant storage\n\n\n\n\n\n\nAttached Volumes Per Instance\n\n\n1\n\n\n\n\n\n\nVolume Size (GB)\n\n\n100\n\n\n\n\n\n\n\n\nAdd Custom Template\n\n\nYou can define reusable cluster templates in the \nmanage templates\n tab: \n\n\n\n\n\n\nClick on \n+create template\n.\n\n\n\n\n\n\nProvide required parameters: \n\n\n\n\n\n\n\n\nParameter\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nName\n\n\nEnter a name for your configuration.\n\n\n\n\n\n\nDescription\n\n\n(Optional) Enter a description.\n\n\n\n\n\n\nInstance Type\n\n\nSelect a VM type. For more information about instance types on Azure refer to \nAzure documentation\n.\n\n\n\n\n\n\nVolume Type\n\n\nSelect the volume type. The options are:\nLocally-redundant storage\nGeo-redundant storage\nPremium locally-redundant storage\n For more information about these options refer to \nAzure documentation\n.\n\n\n\n\n\n\nAttached Volumes Per Instance\n\n\nEnter the number of volumes attached per instance. Default is 1.\n\n\n\n\n\n\nManaged disk\n\n\nSelect whether to use managed or unmanaged disk. Only \"Locally-redundant storage\" volume type is supported for managed disks. Disk sizes will be rounded as described in \nAzure documentation\n. For more information on managed disks refer to \nAzure documentation\n.\n\n\n\n\n\n\nVolume Size (GB)\n\n\nEnter the size in GBs for each volume. Default is 100.\n\n\n\n\n\n\nPublic In Account\n\n\n(Optional) If this option is checked, all the users belonging to your account will be able to use this template to create clusters, but they cannot delete it.\n\n\n\n\n\n\nSelect Platform\n\n\n(Optional) Select a previously created platform.\n\n\n\n\n\n\n\n\n\n\n\n\nClick on \n+create template\n.\n\n\nNo resources will be created until you create a cluster using this configuration.\n\n\n\n\n\n\n\n\nNext: Create a Cluster", 
            "title": "Define Infrastructure Templates"
        }, 
        {
            "location": "/azure-config/index.html#define-infrastructure-templates", 
            "text": "After you've logged in to Cloudbreak and created a Cloudbreak credential, you have two options:   Create clusters using default infrastructure templates        Define your own infrastructure templates      The  infrastructure templates  for resources such as  networks ,  security groups , and  VMs and storage  are saved to Cloudbreak's database and can be reused with multiple clusters to describe the infrastructure. When you add these resources in Cloudbreak web UI, Cloudbreak does not make any requests to your cloud provider account. Resources are only created on your cloud provider account after the create cluster button has been pushed.   This is illustrated and further explained in the  Architecture  documentation.  We recommend that you review the default infrastructure  templates for networks, security groups, and VMs and storage to check if they meet your requirements. You can do this by expanding  their corresponding panes in the Cloudbreak web UI (shown in the screenshot) or by reading the documentation below.       The following table describes the basic configurations that require an infrastructure template. If the default infrastructure templates don't work for you, you must create custom templates.     Configuration  Description  Create Cluster      Networks  (Required) Virtual networks provide the networking infrastructure (network, subnet, Internet gateway, and so on) in which your clusters run. You can create new virtual networks or reuse existing virtual networks for your clusters. Virtual networks on Azure are called Azure Virtual Networks (VNets). For basic information about VNets, refer to  Azure documentation .  You can select the network configuration for your clusters in the  Create Cluster  wizard    Set up Network and Security  page. If no custom network is selected, default is used.    Security Groups  (Required) Security groups include rules which define inbound traffic allowed to the instances in your cluster. You can define different security group configurations for different nodes of your cluster. For basic information about security groups on Azure, refer to  Azure documentation .  You can select the security group configurations for each host group in the  Create Cluster  wizard    Choose Blueprint  page. If no custom security groups are selected, default is used.    VMs and Storage  (Required) \"Templates\" define the Azure infrastructure for the instances on which your cluster runs. You can select the VM types and their attached storage, including storage type, size, and count. You can reuse the same template for different cluster host groups or create different templates for different host groups.  You can select infrastructure templates for each host group in the  Create Cluster  wizard    Choose Blueprint  page. If no custom templates are selected, default is used.", 
            "title": "Define Infrastructure Templates"
        }, 
        {
            "location": "/azure-config/index.html#networks", 
            "text": "You have three options:   Use the default network configuration template : This requires no further action. Every time a cluster is created with this kind of network setup a new virtual network and a new subnet with the specified IP range will be created for the instances on Azure.    Create a new virtual network and a new subnet : Every time a cluster is created with this kind of network setup a new virtual network and a new subnet with the specified IP range will be created for the instances on Azure.            Use an existing subnet in an existing virtual network : Use this option if you have an existing virtual network with one or more subnets on Azure and you'd like to start the instances of a cluster in one of those subnets.    If you are using an existing subnet, ensure that you have opened all the additional ports required for accessing your cluster in the security group of your subnet.", 
            "title": "Networks"
        }, 
        {
            "location": "/azure-config/index.html#default-network", 
            "text": "Cloudbreak includes one pre-defined network configuration called  default-azure-network , which is used by default when creating a cluster.  You can see it in the  manage networks  tab. The configuration is:      Parameter  Value      Name  default-azure-network    Description  Default network settings for Azure clusters.    Subnet (CIDR)  10.0.0.0/16     With this default configuration, a new virtual network with a 10.0.0.0/16 subnet will be created every time a cluster is created. No resources will be created until you create a cluster using this configuration.", 
            "title": "Default Network"
        }, 
        {
            "location": "/azure-config/index.html#add-new-network-and-subnet", 
            "text": "You can define reusable network configurations for your clusters in the  manage networks  tab:    Click on  Create a new virtual network and a new subnet .    Provide required parameters:     Parameter  Description      Name  Enter a name for your configuration.    Description  (Optional) Enter a description.    Subnet (CIDR)  Enter a valid  CIDR  for a new subnet that will be created within the VNet. For example  10.0.0.0/24 .    Public In Account  (Optional) If this option is checked, all the users belonging to your account will be able to use this network template to create clusters, but they cannot delete it.    Select Platform  (Optional) Select a previously created platform.       Click on  +create network .  No resources will be created until you create a cluster using this configuration.", 
            "title": "Add New Network and Subnet"
        }, 
        {
            "location": "/azure-config/index.html#use-existing-network-and-subnet", 
            "text": "You can define reusable network configurations for your clusters in the  manage networks  tab:    Click on  Use an existing subnet in an existing virtual network .     Provide required parameters:    Make sure that the new subnet defined here doesn't overlap with any of your already deployed subnets in the network.       Parameter  Description      Name  Enter a name for your configuration.    Description  (Optional) Enter a description.    Resource Group Identifier  Paste the name of the resource group in which the network is located on Azure. You can obtain it from your Azure portal by navigating to the \"Properties\" of your virtual network and coping the value of the \"NAME\" property.    Virtual Network Identifier  Paste the name of your existing VNet. You can obtain it from your Azure Portal by coping the value of the \"NAME\" property.    Subnet Identifier  Paste the name of your existing subnet. You can obtain it from your Azure Portal  by coping the value of the \"NAME\" property.    Public In Account  (Optional) If this option is checked, all the users belonging to your account will be able to use this network template to create clusters, but they cannot delete it.    Don't create public IPs  If you enable this option, Cloudbreak will not assign public IP address to the VMs. You must make sure that Cloudbreak can access the launched instances and that the instances can reach the internet.    Don't create new firewall rules  If you enable this option, Cloudbreak will not create security groups. You must make sure (by openining every port in the subnet) that the created instances in the subnet can reach each other.    Public In Account  (Optional) If this option is checked, all the users belonging to your account will be able to use this network template to create clusters, but they cannot delete it.    Select Platform  (Optional) Select a previously created platform.       Click on  +create network .  No resources will be created until you create a cluster using this configuration.", 
            "title": "Use Existing Network and Subnet"
        }, 
        {
            "location": "/azure-config/index.html#security-groups", 
            "text": "You have two options:   Use the default security group configuration : This requires no further action.    Add your own custom security group configuration : You can define your own security group by adding the ports, protocols, and CIDR ranges that you'd like to use. The rules defined here don't need to contain the internal rules (these are automatically added by Cloudbreak to the security group on Azure).    You can define different security group configurations for different nodes of your cluster.", 
            "title": "Security Groups"
        }, 
        {
            "location": "/azure-config/index.html#default-security-group", 
            "text": "Cloudbreak includes one pre-defined security group configuration called  default-azure-only-ssh-and-ssl , which is used by default when creating a cluster. You can see it in the  manage security groups  tab. The configuration is:      CIDR  Port  Protocol      0.0.0.0/0  22  tcp    0.0.0.0/0  433  tcp    0.0.0.0/0  9443  tcp     No resources will be created until you create a cluster using this configuration.", 
            "title": "Default Security Group"
        }, 
        {
            "location": "/azure-config/index.html#add-custom-security-group", 
            "text": "You can define reusable security group configurations for your clusters in the  manage security groups  tab:    Click on  Create a new security group .   Provide required parameters:     Parameter  Value      Name  Enter a name for your security group configuration template.    Description  (Optional) Enter a description.    Public In Account  (Optional) If this option is checked, all the users belonging to your account will be able to use this security group template to create clusters, but they cannot delete it.       Provide the following parameters in order to define  Security Rules  for this security group:     Parameter  Value      CIDR  Enter a valid  CIDR IP , from which the cluster will be accessed.    Port  Enter ports that you want to open. You can either list multiple ports, separated by a comma (for example \"22,443,9443\"), or you can define port ranges (for example \"1-65355\").    Protocol  Enter protocol that you want to use.      Ports 22, 443, and 9443 must be open on every security group; otherwise Cloudbreak will not be able to communicate with your provisioned cluster.     Click  +Add Rule  to save the security rules. If needed, click  +Add Rule  again to display a new  Security Rules  form and add another set of rules.     Click  +create security group  to save the configuration.   No resources will be created until you create a cluster using this configuration.     Ports used by Hadoop services: Ambari (8080) Consul (8500) NN (50070) RM Web (8088) Scheduler (8030RM) IPC (8050RM) Job history server (19888) HBase master (60000) HBase master web (60010) HBase RS (16020) HBase RS info (60030) Falcon (15000) Storm (8744) Hive metastore (9083) Hive server (10000) Hive server HTTP (10001) Accumulo master (9999) Accumulo Tserver (9997) Atlas (21000) KNOX (8443) Oozie (11000) Spark HS (18080) NM Web (8042) Zeppelin WebSocket (9996) Zeppelin UI (9995) Kibana (3080)  Elasticsearch (9200)", 
            "title": "Add Custom Security Group"
        }, 
        {
            "location": "/azure-config/index.html#vms-and-storage", 
            "text": "You have two options:   Use the default infrastructure template : This requires no further action.    Add your own custom infrastructure template : Use this option if you have specific infrastructure requirements. A typical setup may combine multiple templates in a cluster for the different types of nodes. For example you may want to attach multiple large disks to the data nodes or have memory optimized instances for Spark nodes.", 
            "title": "VMs and Storage"
        }, 
        {
            "location": "/azure-config/index.html#default-template", 
            "text": "Cloudbreak includes one pre-defined infrastructure template called  minviable-azure , which is used by default when creating a cluster. You can see it in the  manage templates  tab. The configuration is:     Parameter  Value      Name  minviable-azure    VM Type  Standard_D4    Volume Type  Locally-redundant storage    Attached Volumes Per Instance  1    Volume Size (GB)  100", 
            "title": "Default Template"
        }, 
        {
            "location": "/azure-config/index.html#add-custom-template", 
            "text": "You can define reusable cluster templates in the  manage templates  tab:     Click on  +create template .    Provide required parameters:      Parameter  Description      Name  Enter a name for your configuration.    Description  (Optional) Enter a description.    Instance Type  Select a VM type. For more information about instance types on Azure refer to  Azure documentation .    Volume Type  Select the volume type. The options are: Locally-redundant storage Geo-redundant storage Premium locally-redundant storage  For more information about these options refer to  Azure documentation .    Attached Volumes Per Instance  Enter the number of volumes attached per instance. Default is 1.    Managed disk  Select whether to use managed or unmanaged disk. Only \"Locally-redundant storage\" volume type is supported for managed disks. Disk sizes will be rounded as described in  Azure documentation . For more information on managed disks refer to  Azure documentation .    Volume Size (GB)  Enter the size in GBs for each volume. Default is 100.    Public In Account  (Optional) If this option is checked, all the users belonging to your account will be able to use this template to create clusters, but they cannot delete it.    Select Platform  (Optional) Select a previously created platform.       Click on  +create template .  No resources will be created until you create a cluster using this configuration.     Next: Create a Cluster", 
            "title": "Add Custom Template"
        }, 
        {
            "location": "/azure-blueprints/index.html", 
            "text": "Define Cluster Blueprints\n\n\nCluster blueprints\n are your declarative definition of a Hadoop cluster, defining the host groups and which components to install on which host group. Ambari uses them as a base for your clusters. \n\n\nYou have three options:\n\n\n\n\nUse one of the pre-defined blueprints.  \n\n\nCopy and edit one of the pre-defined blueprints.   \n\n\nAdd your custom blueprint by uploading a JSON file or pasting the JSON text. \n\n\n\n\nWe recommend that you review the default blueprints to check if they meet your requirements. You can do this by expanding  the \nmanage bluerints\n pane in the Cloudbreak web UI (shown in the screenshot) or by reading the documentation below.  \n\n\n \n\n\nHere\n is an example of a blueprint. \n\n\nThe host groups in the JSON will be mapped to a set of instances when starting the cluster, and the specified services and components will be installed on the corresponding nodes. It is not necessary to define a complete configuration in the blueprint. If a configuration is missing, Ambari will fill that with a default value. \n\n\nA blueprint can be modified later from the Ambari UI.\n\n\nA blueprint can be exported from a running Ambari cluster and can be reused in Cloudbreak after slight modifications. When a blueprint is exported, some configurations are hardcoded for example domain names, memory configurations, and so on, that won't be applicable to the Cloudbreak cluster. There is no automatic way to modify an exported blueprint and make it instantly usable in Cloudbreak, the modifications have to be done manually.\n\n\nDefault Blueprints\n\n\nCloudbreak includes three default HDP cluster blueprints:\n\n\nHDP Version: \nHDP 2.6\n\n\n\n\n\n\n\n\nCluster Type\n\n\nServices\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nData Science\n\n\n Spark 1.6,\nZeppelin 0.7.0\n\n\nThis cluster configuration includes Spark 1.6 with Zeppelin.\n\n\n\n\n\n\nData Science\n\n\n Spark 2.1,\nZeppelin 0.7.0\n\n\nThis cluster configuration includes Spark 2.1 with Zeppelin.\n\n\n\n\n\n\nEDW - Analytics\n\n\n Hive 2 LLAP\n,\nZeppelin 0.7.0\n\n\nThis cluster configuration includes Hive 2 LLAP.\n\n\n\n\n\n\nEDW - ETL\n\n\n Hive 1.2.1,\nSpark 1.6\n\n\nThis cluster configuration includes Hive and Spark 1.6.\n\n\n\n\n\n\nEDW - ETL\n\n\n Hive 1.2.1,\n Spark 2.1\n\n\nThis cluster configuration includes Hive and Spark 2.1.\n\n\n\n\n\n\nBI\n\n\n Druid 0.9.2\n\n\nThis cluster configuration includes a Technical Preview of Druid.\n\n\n\n\n\n\n\n\nHDP Version: \nHDP 2.5\n\n\n\n\n\n\n\n\nCluster Type\n\n\nServices\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nData Science\n\n\n Spark 1.6,\nZeppelin 0.6.0\n\n\nThis cluster configuration includes Spark 1.6 and Zeppelin.\n\n\n\n\n\n\nEDW - ETL\n\n\n Hive 1.2.1,\nSpark 1.6\n\n\nThis cluster configuration includes Hive and Spark 1.6.\n\n\n\n\n\n\nEDW - ETL\n\n\n Hive 1.2.1,\n Spark 2.0\n\n\nThis cluster configuration includes a Technical Preview of Spark 2.0.\n\n\n\n\n\n\nEDW - Analytics\n\n\n Hive 2 LLAP\n,\nZeppelin 0.6.0\n\n\nThis cluster configuration includes a Technical Preview of Hive 2 LLAP.\n\n\n\n\n\n\n\n\n\n    \nChoosing Your Configuration\n\n    \n\nWhen creating a cluster, you can choose a more stable cluster configuration for a predicable experience.\nAlternatively, you can try the latest capabilities by choosing a cluster configuration\nthat is much more experimental. The following configuration classification applies:\n\n\n\n Stable configurations are the best choice if you want to avoid issues and other problems with launching and using clusters.\n\n\n If you want to use a Technical Preview version of a component in a release of HDP, use these configurations.\n\n\n These are the most cutting edge of the configurations, including Technical Preview components in a Technical Preview HDP release.\n\n\n\n\n\n\n\n\n\nCopy and Edit Existing Blueprint\n\n\nYou can modify default or previously added blueprints in the \nmanage blueprints\n tab. To do that, expand the entry in the Cloudbreak UI and then click \ncopy \n edit\n. \n\n\nAdd Custom Blueprint\n\n\nYou can define reusable blueprints for your clusters in the \nmanage blueprints\n tab. To add your own blueprint, click \n+create blueprint\n and enter the following parameters:\n\n\n\n\n\n\n\n\nParameter\n\n\nValue\n\n\n\n\n\n\n\n\n\n\nName\n\n\nEnter a name for your blueprint.\n\n\n\n\n\n\nDescription\n\n\n(Optional) Enter a description for your blueprint.\n\n\n\n\n\n\nBlueprint Source\n\n\nSelect one of: \nText\n: Paste blueprint in JSON format.\n \nFile\n: Upload a file that contains the blueprint.\n \nURL\n: Specify the URL for your blueprint.\n\n\n\n\n\n\nPublic In Account\n\n\n(Optional) If this option is checked, all the users belonging to your account will be able to use this blueprint to create clusters, but they cannot delete it.\n\n\n\n\n\n\n\n\n\n\nNext: Create a Cluster", 
            "title": "Define Cluster Blueprints"
        }, 
        {
            "location": "/azure-blueprints/index.html#define-cluster-blueprints", 
            "text": "Cluster blueprints  are your declarative definition of a Hadoop cluster, defining the host groups and which components to install on which host group. Ambari uses them as a base for your clusters.   You have three options:   Use one of the pre-defined blueprints.    Copy and edit one of the pre-defined blueprints.     Add your custom blueprint by uploading a JSON file or pasting the JSON text.    We recommend that you review the default blueprints to check if they meet your requirements. You can do this by expanding  the  manage bluerints  pane in the Cloudbreak web UI (shown in the screenshot) or by reading the documentation below.       Here  is an example of a blueprint.   The host groups in the JSON will be mapped to a set of instances when starting the cluster, and the specified services and components will be installed on the corresponding nodes. It is not necessary to define a complete configuration in the blueprint. If a configuration is missing, Ambari will fill that with a default value.   A blueprint can be modified later from the Ambari UI.  A blueprint can be exported from a running Ambari cluster and can be reused in Cloudbreak after slight modifications. When a blueprint is exported, some configurations are hardcoded for example domain names, memory configurations, and so on, that won't be applicable to the Cloudbreak cluster. There is no automatic way to modify an exported blueprint and make it instantly usable in Cloudbreak, the modifications have to be done manually.", 
            "title": "Define Cluster Blueprints"
        }, 
        {
            "location": "/azure-blueprints/index.html#default-blueprints", 
            "text": "Cloudbreak includes three default HDP cluster blueprints:", 
            "title": "Default Blueprints"
        }, 
        {
            "location": "/azure-blueprints/index.html#hdp-version-hdp-26", 
            "text": "Cluster Type  Services  Description      Data Science   Spark 1.6, Zeppelin 0.7.0  This cluster configuration includes Spark 1.6 with Zeppelin.    Data Science   Spark 2.1, Zeppelin 0.7.0  This cluster configuration includes Spark 2.1 with Zeppelin.    EDW - Analytics   Hive 2 LLAP , Zeppelin 0.7.0  This cluster configuration includes Hive 2 LLAP.    EDW - ETL   Hive 1.2.1, Spark 1.6  This cluster configuration includes Hive and Spark 1.6.    EDW - ETL   Hive 1.2.1,  Spark 2.1  This cluster configuration includes Hive and Spark 2.1.    BI   Druid 0.9.2  This cluster configuration includes a Technical Preview of Druid.", 
            "title": "HDP Version: HDP 2.6"
        }, 
        {
            "location": "/azure-blueprints/index.html#hdp-version-hdp-25", 
            "text": "Cluster Type  Services  Description      Data Science   Spark 1.6, Zeppelin 0.6.0  This cluster configuration includes Spark 1.6 and Zeppelin.    EDW - ETL   Hive 1.2.1, Spark 1.6  This cluster configuration includes Hive and Spark 1.6.    EDW - ETL   Hive 1.2.1,  Spark 2.0  This cluster configuration includes a Technical Preview of Spark 2.0.    EDW - Analytics   Hive 2 LLAP , Zeppelin 0.6.0  This cluster configuration includes a Technical Preview of Hive 2 LLAP.     \n     Choosing Your Configuration \n     \nWhen creating a cluster, you can choose a more stable cluster configuration for a predicable experience.\nAlternatively, you can try the latest capabilities by choosing a cluster configuration\nthat is much more experimental. The following configuration classification applies:   Stable configurations are the best choice if you want to avoid issues and other problems with launching and using clusters.   If you want to use a Technical Preview version of a component in a release of HDP, use these configurations.   These are the most cutting edge of the configurations, including Technical Preview components in a Technical Preview HDP release.", 
            "title": "HDP Version: HDP 2.5"
        }, 
        {
            "location": "/azure-blueprints/index.html#copy-and-edit-existing-blueprint", 
            "text": "You can modify default or previously added blueprints in the  manage blueprints  tab. To do that, expand the entry in the Cloudbreak UI and then click  copy   edit .", 
            "title": "Copy and Edit Existing Blueprint"
        }, 
        {
            "location": "/azure-blueprints/index.html#add-custom-blueprint", 
            "text": "You can define reusable blueprints for your clusters in the  manage blueprints  tab. To add your own blueprint, click  +create blueprint  and enter the following parameters:     Parameter  Value      Name  Enter a name for your blueprint.    Description  (Optional) Enter a description for your blueprint.    Blueprint Source  Select one of:  Text : Paste blueprint in JSON format.   File : Upload a file that contains the blueprint.   URL : Specify the URL for your blueprint.    Public In Account  (Optional) If this option is checked, all the users belonging to your account will be able to use this blueprint to create clusters, but they cannot delete it.      Next: Create a Cluster", 
            "title": "Add Custom Blueprint"
        }, 
        {
            "location": "/azure-create/index.html", 
            "text": "Create a Cluster on Azure\n\n\nTo create a cluster via CLoudbreak UI:\n\n\n\n\n\n\nLog in to the Cloudbreak UI.\n\n\n\n\n\n\nIn the top right corner, select the credential that you want to use to create a cluster:\n\n\n  \n\n\n\n\n\n\nClick \n+create cluster\n and the \nCreate cluster\n form is displayed.\n\n\n\n\n\n\nOn the \nConfigure Cluster\n page, provide the following parameters:\n\n\n\n\nTo view advanced options, click \nShow Advanced Options\n. To learn about advanced options, refer to \nAdvanced Options\n.\n\n\n\n\n\n\n\n\n\n\nParameter\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nCluster Name\n\n\nEnter a name for your cluster. The name must be between 5 and 40 characters, must start with a letter, must only include lowercase letters, numbers, and hyphens.\n\n\n\n\n\n\nTags\n\n\n(Optional) You can optionally add tags, which will help you find your cluster-related resources, such as VMs, in your cloud provider account.\n\n\n\n\n\n\nRegion\n\n\nSelect the region in which you would like to launch your cluster.\n\n\n\n\n\n\nSend Email When Cluster is Ready\n\n\n(Optional) Check this to receive an email each time the cluster status changes.\n\n\n\n\n\n\nPublic In Account\n\n\n(Optional) If this option is checked, all the users belonging to your account will be able to use this cluster, but they cannot delete it.\n\n\n\n\n\n\n\n\n\n\nBy default, Ambari Username and Ambari Password are set to \nadmin\n. You can override it in the \"\nConfigure Cluster\n\" tab.\n\n\n\n\n\n\n\n\nOn the \nSet up Network and Security\n page, provide the following parameters:\n\n\n\n\n\n\n\n\nParameter\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nNetwork\n\n\nSelect the virtual network in which you would like your cluster to be provisioned. You can define custom network configurations or use default network configurations.\n\n\n\n\n\n\nEnable Knox Gateway\n\n\n(Optional) Select this option to enable secure access to Ambari web UI and other cluster UIs via Knox gateway.\n\n\n\n\n\n\nEnable Kerberos Security\n\n\n(Optional) Select this option to enable Kerberos for your cluster. You will have an option to create a new kerberos or use an existing one. For more information refer to Kerberos \ndocumentation\n.\n\n\n\n\n\n\n\n\n\n\n\n\nOn the \nChoose Blueprint\n page, select the blueprint that you would like to use for your cluster. You can either choose one of the pre-configured blueprints, or add your own in the \nmanage blueprints\n tab.\n\n\nFor each host group you must provide the following:\n\n\n\n\n\n\n\n\nParameter\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nGroup Size\n\n\nEnter a number defining how many nodes to create per host group. Default is 1. The \"Group Size\" for that host group on which Ambari Server is installed must be set to \"1\".\n\n\n\n\n\n\nTemplate\n\n\nIf you have previously created a template for VMs and storage, you can select it here. If you don't make a selection, default will be used.\n\n\n\n\n\n\nSecurity Group\n\n\nIf you have previously created a template for a security group, you can select it here. If you don't make a selection, default will be used.\n\n\n\n\n\n\nAmbari Server\n\n\nYou must select one node for Ambari Server. The \"Group Size\" for that host group must be set to \"1\".\n\n\n\n\n\n\nRecipes\n\n\nYou can select a previously added recipe (custom script) to be executed on all nodes of the host group. Refer to \nRecipes\n.\n\n\n\n\n\n\n\n\n\n\n\n\nOn the \nAdd File System\n page, select to use one of the following filesystems:\n\n\n\n\nLocal HDFS\n: No external storage outside of HDFS will be used\n\n\nWindows Azure Data Lake Storage\n: If you select this option, you must provide \nData Lake Store account name\n.  \n\n\nYou must configure access control for Cloudbreak's service principal manually after cluster installation. You can obtain the service principal ID from the Cloudbreak UI. For more information, refer to \nAzure documentation\n.  \n\n\n\n\n\n\n\n\nWindows Azure Blob Storage\n: If you select this option, you must provide:\n\n\n\n\n\n\n\n\nParameter\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nStorage Account Name\n\n\nEnter your account name.\n\n\n\n\n\n\nStorage Account Access Key\n\n\nEnter your access key.\n\n\n\n\n\n\nUse File System As Default\n\n\nSelect this option if you want to make WASB your default file system, instead of HDFS.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nClick on \nReview and Launch\n and then \n+create and start cluster\n.\n\n\n\n\n\n\nYou will be redirected to the Cloudbreak dashboard, and a new tile representing your cluster will appear at the top of the page.\n\n\n\n\n\n\nAdvanced Options\n\n\nClick on \nShow Advanced Options\n to enter additional configuration options.\n\n\nConfigure Cluster\n\n\nYou can optionally configure the following advanced parameters:\n\n\n\n\n\n\n\n\nParameter\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nAmbari Username\n\n\nYou can log in to the Ambari UI using this username. By default, this is set to \nadmin\n.\n\n\n\n\n\n\nAmbari Password\n\n\nYou can log in to the Ambari UI using this password. By default, this is set to \nadmin\n.\n\n\n\n\n\n\nProvision Cluster\n\n\nSALT\n is pre-selected to provision your cluster.\n\n\n\n\n\n\nEnable availability sets\n\n\nAzure implements the concept of \navailability sets\n to support fault tolerance for VM's. You can enable availability sets by using the checkbox, and then add the desired availability sets by providing a name and the desired fault domain count (2 or 3). Next, these defined availability sets can be assigned to specific host groups in the \nChoose Blueprint\n tab. For more information about availability sets, refer to \nAvailability Sets\n.\n\n\n\n\n\n\nEnable Lifetime Management\n\n\nCheck this option if you would like your cluster to be automatically terminated after a specific amount of time (defined as \"Time to Live\" in minuter) has passed.\n\n\n\n\n\n\nFlex Subscription\n\n\nThis option will appear if you have configured your deployment for a \nFlex Subscription\n.\n\n\n\n\n\n\n\n\nChoose Blueprint\n\n\nAfter selecting a blueprint, you can optionally configure the following advanced parameters:\n\n\n\n\n\n\n\n\nParameter\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nConfig Recommendation Strategy (Stack Advisor)\n\n\nSelect how configuration recommendations generated by stack advisor will be applied. Select one of \nALWAYS_APPLY: Configuration recommendations will be applied automatically.\nALWAYS_APPLY_DONT_OVERRIDE_CUSTOM_VALUES: Configuration recommendations will be applied automatically, but they will be ignored for custom configurations.\nNEVER_APPLY: Configuration recommendations will be ignored.\nONLY_STACK_DEFAULTS_APPLY: Configuration recommendations will be applied only on the default configurations for all included services.\n\n\n\n\n\n\nValidate Blueprint\n\n\nSelect to validate the blueprint.\n\n\n\n\n\n\n\n\nAdd File System\n\n\nAfter selecting the filesystem, you can optionally configure the following advanced parameters:\n\n\n\n\n\n\n\n\nParameter\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nAttached Storage Type\n\n\nSelect \nsingle storage for all VMs\n or \nseparate storage for every VM\n. Selecting single storage means that your whole cluster's OS disks will be placed in one storage account. Using separate storage for every VM will deploy as many storage accounts as the number of nodes in your cluster, avoiding the IOPS limit of a particular storage account.\n\n\n\n\n\n\nPersistent Storage Name\n\n\nEnter a name for the persistent storage directory. Default is \ncbstore\n.\n\n\n\n\n\n\n\n\nChoose Failure Action\n\n\nYou can optionally select what to do if cluster creation fails or if there aren't enough instances available to create all requested nodes:\n\n\n\n\n\n\n\n\nParameter\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nFailure Action\n\n\nSelect one of: \ndo NOT rollback resources\n (default) or \nrollback resources\n. \nBy default, if creating a cluster fails, the Azure resources that were created up to that point will not be rolled back. This means that they will remain accessible for troubleshooting and you will need to to delete them manually.\n\n\n\n\n\n\nMinimum Cluster Size\n\n\nThis defines the provisioning strategy in case the cloud provider cannot allocate all the requested nodes. Select \nbest effort\n or \nexact\n.\n\n\n\n\n\n\n\n\nConfigure Ambari Repos\n\n\nYou can optionally configure a different version of Ambari than the default by providing the following information:\n\n\n\n\n\n\n\n\nParameter\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nAmbari Version\n\n\nEnter Ambari version.\n\n\n\n\n\n\nAmbari Repo URL\n\n\nEnter Ambari repo URL.\n\n\n\n\n\n\nAmbari Repo Gpg Key URL\n\n\nEnter gpgkey URL.\n\n\n\n\n\n\n\n\nConfigure HDP Repos\n\n\nYou can optionally configure a different version of HDP than the default by providing the following information:\n\n\n\n\n\n\n\n\nParameter\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nStack\n\n\nEnter stack name.\n\n\n\n\n\n\nVersion\n\n\nEnter stack version.\n\n\n\n\n\n\nStack Repo ID\n\n\nEnter stack repo ID.\n\n\n\n\n\n\nBase URL\n\n\nEner stack repo base URL.\n\n\n\n\n\n\nUtils Repo ID\n\n\nEnter Utils repo ID.\n\n\n\n\n\n\nUtils Base URL\n\n\nEnter Utils repo base URL.\n\n\n\n\n\n\nVerify\n\n\nSelect to verify the repo information.\n\n\n\n\n\n\n\n\nConfigure Ambari Database\n\n\nBy default, Ambari stores data on an embedded database, which is sufficient for ephemeral or test clusters. However, as Ambari and Cloudbreak don't perform backups of this database, it is insufficient for long-running production clusters, and you may need to configure a remote database for Ambari and Cloudbreak.\n\n\n\n\n\n\n\n\nParameter\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nVendor\n\n\nSelect database vendor from the list.\n\n\n\n\n\n\nHost\n\n\nEnter database host IP.\n\n\n\n\n\n\nPort\n\n\nEnter port number.\n\n\n\n\n\n\nName\n\n\nEnter database name.\n\n\n\n\n\n\nUser Name\n\n\nEnter database user name.\n\n\n\n\n\n\nPassword\n\n\nEnter database password.\n\n\n\n\n\n\n\n\nAvailability Sets\n\n\nTo support fault tolerance for VMs, Azure introduced the concept of \navailability sets\n. This allows two or more VMs to be mapped to multiple fault domains, each of which defines a group of virtual machines that share a common power source and a network switch. When adding VMs to an availability set, Azure automatically assigns each VM a fault domain. This SLA includes guarantees that during OS Patching in Azure or during maintenance operations, at least one VM belonging to a given fault domain will be available.\n\n\nIn Cloudbreak UI, availability sets can be configured during cluster creation:\n\n\n\n\n\n\nEnable availability sets using the checkbox on the \nConfigure Cluster\n page. \n\n\n\n\n\n\nAdd the desired availability sets by providing a name and the desired fault domain count (2 or 3).\n\n\n\n\n\n\nThe sets defined here can be assigned to the host groups on the \nChoose Blueprint\n page. One availability set can be assigned to only one host group, so you should define in advance as many availability sets as needed for your host groups. The assignment of fault domains is automated by Azure, so there is no option for this in Cloudbreak UI.\n\n\n\n\nIMPORTANT\n: The availability sets should only be used when there is a group of two or more application-tier VMs. Single instances placed in an availability set are not subject to Azure\u2019s SLA, and you will not receive warnings of planned maintenance events. \n\n\n\n\n\n\n\n\nAfter the deployment is finished, you can check the layout of the VMs inside an availability set on Azure Portal. You will find the \"Availability set\" resources corresponding to the host groups inside the deployment's resource group. \n\n\n\n\n\n\n\n\nNext: Manage \n&\n Monitor Clusters", 
            "title": "Create a Cluster"
        }, 
        {
            "location": "/azure-create/index.html#create-a-cluster-on-azure", 
            "text": "To create a cluster via CLoudbreak UI:    Log in to the Cloudbreak UI.    In the top right corner, select the credential that you want to use to create a cluster:        Click  +create cluster  and the  Create cluster  form is displayed.    On the  Configure Cluster  page, provide the following parameters:   To view advanced options, click  Show Advanced Options . To learn about advanced options, refer to  Advanced Options .      Parameter  Description      Cluster Name  Enter a name for your cluster. The name must be between 5 and 40 characters, must start with a letter, must only include lowercase letters, numbers, and hyphens.    Tags  (Optional) You can optionally add tags, which will help you find your cluster-related resources, such as VMs, in your cloud provider account.    Region  Select the region in which you would like to launch your cluster.    Send Email When Cluster is Ready  (Optional) Check this to receive an email each time the cluster status changes.    Public In Account  (Optional) If this option is checked, all the users belonging to your account will be able to use this cluster, but they cannot delete it.      By default, Ambari Username and Ambari Password are set to  admin . You can override it in the \" Configure Cluster \" tab.     On the  Set up Network and Security  page, provide the following parameters:     Parameter  Description      Network  Select the virtual network in which you would like your cluster to be provisioned. You can define custom network configurations or use default network configurations.    Enable Knox Gateway  (Optional) Select this option to enable secure access to Ambari web UI and other cluster UIs via Knox gateway.    Enable Kerberos Security  (Optional) Select this option to enable Kerberos for your cluster. You will have an option to create a new kerberos or use an existing one. For more information refer to Kerberos  documentation .       On the  Choose Blueprint  page, select the blueprint that you would like to use for your cluster. You can either choose one of the pre-configured blueprints, or add your own in the  manage blueprints  tab.  For each host group you must provide the following:     Parameter  Description      Group Size  Enter a number defining how many nodes to create per host group. Default is 1. The \"Group Size\" for that host group on which Ambari Server is installed must be set to \"1\".    Template  If you have previously created a template for VMs and storage, you can select it here. If you don't make a selection, default will be used.    Security Group  If you have previously created a template for a security group, you can select it here. If you don't make a selection, default will be used.    Ambari Server  You must select one node for Ambari Server. The \"Group Size\" for that host group must be set to \"1\".    Recipes  You can select a previously added recipe (custom script) to be executed on all nodes of the host group. Refer to  Recipes .       On the  Add File System  page, select to use one of the following filesystems:   Local HDFS : No external storage outside of HDFS will be used  Windows Azure Data Lake Storage : If you select this option, you must provide  Data Lake Store account name .    You must configure access control for Cloudbreak's service principal manually after cluster installation. You can obtain the service principal ID from the Cloudbreak UI. For more information, refer to  Azure documentation .       Windows Azure Blob Storage : If you select this option, you must provide:     Parameter  Description      Storage Account Name  Enter your account name.    Storage Account Access Key  Enter your access key.    Use File System As Default  Select this option if you want to make WASB your default file system, instead of HDFS.         Click on  Review and Launch  and then  +create and start cluster .    You will be redirected to the Cloudbreak dashboard, and a new tile representing your cluster will appear at the top of the page.", 
            "title": "Create a Cluster on Azure"
        }, 
        {
            "location": "/azure-create/index.html#advanced-options", 
            "text": "Click on  Show Advanced Options  to enter additional configuration options.", 
            "title": "Advanced Options"
        }, 
        {
            "location": "/azure-create/index.html#configure-cluster", 
            "text": "You can optionally configure the following advanced parameters:     Parameter  Description      Ambari Username  You can log in to the Ambari UI using this username. By default, this is set to  admin .    Ambari Password  You can log in to the Ambari UI using this password. By default, this is set to  admin .    Provision Cluster  SALT  is pre-selected to provision your cluster.    Enable availability sets  Azure implements the concept of  availability sets  to support fault tolerance for VM's. You can enable availability sets by using the checkbox, and then add the desired availability sets by providing a name and the desired fault domain count (2 or 3). Next, these defined availability sets can be assigned to specific host groups in the  Choose Blueprint  tab. For more information about availability sets, refer to  Availability Sets .    Enable Lifetime Management  Check this option if you would like your cluster to be automatically terminated after a specific amount of time (defined as \"Time to Live\" in minuter) has passed.    Flex Subscription  This option will appear if you have configured your deployment for a  Flex Subscription .", 
            "title": "Configure Cluster"
        }, 
        {
            "location": "/azure-create/index.html#choose-blueprint", 
            "text": "After selecting a blueprint, you can optionally configure the following advanced parameters:     Parameter  Description      Config Recommendation Strategy (Stack Advisor)  Select how configuration recommendations generated by stack advisor will be applied. Select one of  ALWAYS_APPLY: Configuration recommendations will be applied automatically. ALWAYS_APPLY_DONT_OVERRIDE_CUSTOM_VALUES: Configuration recommendations will be applied automatically, but they will be ignored for custom configurations. NEVER_APPLY: Configuration recommendations will be ignored. ONLY_STACK_DEFAULTS_APPLY: Configuration recommendations will be applied only on the default configurations for all included services.    Validate Blueprint  Select to validate the blueprint.", 
            "title": "Choose Blueprint"
        }, 
        {
            "location": "/azure-create/index.html#add-file-system", 
            "text": "After selecting the filesystem, you can optionally configure the following advanced parameters:     Parameter  Description      Attached Storage Type  Select  single storage for all VMs  or  separate storage for every VM . Selecting single storage means that your whole cluster's OS disks will be placed in one storage account. Using separate storage for every VM will deploy as many storage accounts as the number of nodes in your cluster, avoiding the IOPS limit of a particular storage account.    Persistent Storage Name  Enter a name for the persistent storage directory. Default is  cbstore .", 
            "title": "Add File System"
        }, 
        {
            "location": "/azure-create/index.html#choose-failure-action", 
            "text": "You can optionally select what to do if cluster creation fails or if there aren't enough instances available to create all requested nodes:     Parameter  Description      Failure Action  Select one of:  do NOT rollback resources  (default) or  rollback resources .  By default, if creating a cluster fails, the Azure resources that were created up to that point will not be rolled back. This means that they will remain accessible for troubleshooting and you will need to to delete them manually.    Minimum Cluster Size  This defines the provisioning strategy in case the cloud provider cannot allocate all the requested nodes. Select  best effort  or  exact .", 
            "title": "Choose Failure Action"
        }, 
        {
            "location": "/azure-create/index.html#configure-ambari-repos", 
            "text": "You can optionally configure a different version of Ambari than the default by providing the following information:     Parameter  Description      Ambari Version  Enter Ambari version.    Ambari Repo URL  Enter Ambari repo URL.    Ambari Repo Gpg Key URL  Enter gpgkey URL.", 
            "title": "Configure Ambari Repos"
        }, 
        {
            "location": "/azure-create/index.html#configure-hdp-repos", 
            "text": "You can optionally configure a different version of HDP than the default by providing the following information:     Parameter  Description      Stack  Enter stack name.    Version  Enter stack version.    Stack Repo ID  Enter stack repo ID.    Base URL  Ener stack repo base URL.    Utils Repo ID  Enter Utils repo ID.    Utils Base URL  Enter Utils repo base URL.    Verify  Select to verify the repo information.", 
            "title": "Configure HDP Repos"
        }, 
        {
            "location": "/azure-create/index.html#configure-ambari-database", 
            "text": "By default, Ambari stores data on an embedded database, which is sufficient for ephemeral or test clusters. However, as Ambari and Cloudbreak don't perform backups of this database, it is insufficient for long-running production clusters, and you may need to configure a remote database for Ambari and Cloudbreak.     Parameter  Description      Vendor  Select database vendor from the list.    Host  Enter database host IP.    Port  Enter port number.    Name  Enter database name.    User Name  Enter database user name.    Password  Enter database password.", 
            "title": "Configure Ambari Database"
        }, 
        {
            "location": "/azure-create/index.html#availability-sets", 
            "text": "To support fault tolerance for VMs, Azure introduced the concept of  availability sets . This allows two or more VMs to be mapped to multiple fault domains, each of which defines a group of virtual machines that share a common power source and a network switch. When adding VMs to an availability set, Azure automatically assigns each VM a fault domain. This SLA includes guarantees that during OS Patching in Azure or during maintenance operations, at least one VM belonging to a given fault domain will be available.  In Cloudbreak UI, availability sets can be configured during cluster creation:    Enable availability sets using the checkbox on the  Configure Cluster  page.     Add the desired availability sets by providing a name and the desired fault domain count (2 or 3).    The sets defined here can be assigned to the host groups on the  Choose Blueprint  page. One availability set can be assigned to only one host group, so you should define in advance as many availability sets as needed for your host groups. The assignment of fault domains is automated by Azure, so there is no option for this in Cloudbreak UI.   IMPORTANT : The availability sets should only be used when there is a group of two or more application-tier VMs. Single instances placed in an availability set are not subject to Azure\u2019s SLA, and you will not receive warnings of planned maintenance events.      After the deployment is finished, you can check the layout of the VMs inside an availability set on Azure Portal. You will find the \"Availability set\" resources corresponding to the host groups inside the deployment's resource group.      Next: Manage  &  Monitor Clusters", 
            "title": "Availability Sets"
        }, 
        {
            "location": "/azure-cb-ui/index.html", 
            "text": "Manage and Monitor Clusters\n\n\nYou can manage monitor your clusters from the Cloudbreak UI. To do that, click on the title representing the cluster that you want to access: \n\n\n \n\n\nAccessing Links to Cluster Services\n\n\nYou can access links to cluster services from the \nServices\n tab.\n\n\nManaging Cluster Nodes\n\n\nYou can view details about your cluster nodes (for example, Public IP addresses) from the \nNodes\n tab. You can also delete nodes using the \nTERMINATE\n option.\n\n\nAccessing Event Log\n\n\nYou can access cluster event log from the \nEvent History\n tab.\n\n\nRepairing Your Cluster\n\n\nTo trigger repair process for your cluster, click \nrepair\n. Faulty nodes will be deleted from the cluster and new ones will be added in their place. \n\n\nTerminating Your Cluster\n\n\nTo terminate your cluster, click \nterminate\n. All cluster-related resources will be deleted, unless the network is used by other VMs, in which case it will not be deleted.", 
            "title": "Manage and Monitor Clusters"
        }, 
        {
            "location": "/azure-cb-ui/index.html#manage-and-monitor-clusters", 
            "text": "You can manage monitor your clusters from the Cloudbreak UI. To do that, click on the title representing the cluster that you want to access:", 
            "title": "Manage and Monitor Clusters"
        }, 
        {
            "location": "/azure-cb-ui/index.html#accessing-links-to-cluster-services", 
            "text": "You can access links to cluster services from the  Services  tab.", 
            "title": "Accessing Links to Cluster Services"
        }, 
        {
            "location": "/azure-cb-ui/index.html#managing-cluster-nodes", 
            "text": "You can view details about your cluster nodes (for example, Public IP addresses) from the  Nodes  tab. You can also delete nodes using the  TERMINATE  option.", 
            "title": "Managing Cluster Nodes"
        }, 
        {
            "location": "/azure-cb-ui/index.html#accessing-event-log", 
            "text": "You can access cluster event log from the  Event History  tab.", 
            "title": "Accessing Event Log"
        }, 
        {
            "location": "/azure-cb-ui/index.html#repairing-your-cluster", 
            "text": "To trigger repair process for your cluster, click  repair . Faulty nodes will be deleted from the cluster and new ones will be added in their place.", 
            "title": "Repairing Your Cluster"
        }, 
        {
            "location": "/azure-cb-ui/index.html#terminating-your-cluster", 
            "text": "To terminate your cluster, click  terminate . All cluster-related resources will be deleted, unless the network is used by other VMs, in which case it will not be deleted.", 
            "title": "Terminating Your Cluster"
        }, 
        {
            "location": "/azure-data/index.html", 
            "text": "Accessing Data on Azure\n\n\nHDP 2.6 supports reading and writing both block blobs and page blobs from/to Windows Azure Storage Blob (WASB) object store, as well as reading and writing files stored in an Azure Data Lake Storage (ADLS) account. This allows you to:\n\n\n\n\nPersist data using cloud storage services beyond the lifetime of your HDP clusters.  \n\n\nLoad data in Hadoop ecosystem applications directly from Azure storage services, without first importing or uploading data from external resources to HDFS.  \n\n\nUse other applications (not necessarily in your Hadoop ecosystem) to manipulate the data stored in Azure storage services beyond the lifetime of your HDP clusters.  \n\n\nShare data between multiple HDP clusters fast and easily by pointing to the same Azure data sets. \n\n\nMove or copy data between different Azure storage services or between Azure storage services and HDFS to facilitate different scenarios for big data analytics workloads.  \n\n\nBack up unlimited archive data at any scale from HDP cluster to fully managed, durable, and highly available Azure storage services.   \n\n\n\n\nAccessing Data in ADLS\n\n\nAzure Data Lake Store (ADLS)\n is an enterprise-wide hyper-scale repository for big data analytic workloads.\n\n\nPrerequisites\n\n\nIf you want to use \nAzure Data Lake Store\n to store your data, you must: \n\n\n\n\n\n\nEnable Azure subscription for Data Lake Store, and then create an Azure Data Lake Store \nstorage account\n in the same subscription as you use for launching Cloudbreak controller and clusters.  \n\n\n\n\n\n\nNext, in the cluster creation phase, specify the created account name only, and access to the Azure Data Lake Store will be configured automatically. For further instructions, refer to Microsoft Azure \ndocumentation\n.\n\n\n\n\n\n\nConfiguring Access to ADLS\n\n\nADLS is not supported as a default file system, but access to data in ADLS is automatically configured if you select ADLS during \ncluster creation\n, on the \nAdd File System\n page.\n\n\nAccess Path\n\n\nADLS access path syntax is:\n\n\nadl://\naccount_name\n.azuredatalakestore.net/\ndir/file\n\n\n\nFor example, the following Hadoop FileSystem shell commands demonstrate access to a storage account named \"myaccount\":\n\n\nhadoop fs -mkdir adl://myaccount.azuredatalakestore.net/testdir\n\n\n\nhadoop fs -put testfile adl://myaccount.azuredatalakestore.net/testdir/testfile\n\n\n\nTo use DistCp against ADLS, use the following syntax:\n\nhadoop distcp\n    [-D hadoop.security.credential.provider.path=localjceks://file/home/user/adls.jceks]\n    hdfs://\nnamenode_hostname\n:9001/user/foo/007020615\n    adl://\nmyaccount\n.azuredatalakestore.net/testDir/\n\n\nAccessing Data in WASB\n\n\nWindows Azure Storage Blob (WASB) is an object store service available on Azure.\n\n\nPrerequisites\n\n\nIf you want to use Windows Azure Storage Blob to store your data, you must enable Azure subscription for Blob Storage, and then create a \nstorage account\n.  \n\n\nConfiguring Access to WASB\n\n\nIn order to access data stored in your Azure blob storage account, you must configure your storage account access key in \ncore-site.xml\n. The configuration property that you must use is \nfs.azure.account.key.\naccount name\n.blob.core.windows.net\n and the value is the access key. \n\n\nFor example the following property should be used for a storage account called \"testaccount\": \n\n\nproperty\n\n  \nname\nfs.azure.account.key.testaccount.blob.core.windows.net\n/name\n\n  \nvalue\nTESTACCOUNT-ACCESS-KEY\n/value\n\n\n/property\n\n\n\n\n\nYou can obtain your access key from the Access keys in your storage account settings.\n\n\nAlternatively, it is possible, although not recommended or supported, to configure \nfs.defaultFS\n to use a wasb or wasbs URL. This causes all bare paths, such as /testDir/testFile to resolve automatically to that file system.\n\n\nAccess Path\n\n\nWASB access path syntax is:\n\n\nwasb://\ncontainer_name\n@\nstorage_account_name\n.blob.core.windows.net/\ndir/file\n\n\n\nFor example, to access a file called \"testfile\" located in a directory called \"testdir\", stored in the container called \"testcontainer\" on the account called \"hortonworks\", the URL is:\n\n\nwasb://testcontainer@hortonworks.blob.core.windows.net/testdir/testfile\n\n\n\nYou can also use \"wasbs\" prefix to utilize SSL-encrypted HTTPS access:\n\n\nwasbs://\n@\n.blob.core.windows.net/dir/file\n\n\n\nThe following Hadoop FileSystem shell commands demonstrate access to a storage account named \"myaccount\" and a container named \"mycontainer\":\n\n\nhadoop fs -ls wasb://mycontainer@myaccount.blob.core.windows.net/\n\nhadoop fs -mkdir wasb://mycontainer@myaccount.blob.core.windows.net/testDir\n\nhadoop fs -put testFile wasb://mycontainer@myaccount.blob.core.windows.net/testDir/testFile\n\nhadoop fs -cat wasb://mycontainer@myaccount.blob.core.windows.net/testDir/testFile\ntest file content\n\n\n\nLearn More\n\n\nFor more information about configuring the ADLS and WASB connectors and working with data stored in ADLS and WASB, refer to \nCloud Data Access\n documentation.", 
            "title": "Access Data on Azure"
        }, 
        {
            "location": "/azure-data/index.html#accessing-data-on-azure", 
            "text": "HDP 2.6 supports reading and writing both block blobs and page blobs from/to Windows Azure Storage Blob (WASB) object store, as well as reading and writing files stored in an Azure Data Lake Storage (ADLS) account. This allows you to:   Persist data using cloud storage services beyond the lifetime of your HDP clusters.    Load data in Hadoop ecosystem applications directly from Azure storage services, without first importing or uploading data from external resources to HDFS.    Use other applications (not necessarily in your Hadoop ecosystem) to manipulate the data stored in Azure storage services beyond the lifetime of your HDP clusters.    Share data between multiple HDP clusters fast and easily by pointing to the same Azure data sets.   Move or copy data between different Azure storage services or between Azure storage services and HDFS to facilitate different scenarios for big data analytics workloads.    Back up unlimited archive data at any scale from HDP cluster to fully managed, durable, and highly available Azure storage services.", 
            "title": "Accessing Data on Azure"
        }, 
        {
            "location": "/azure-data/index.html#accessing-data-in-adls", 
            "text": "Azure Data Lake Store (ADLS)  is an enterprise-wide hyper-scale repository for big data analytic workloads.", 
            "title": "Accessing Data in ADLS"
        }, 
        {
            "location": "/azure-data/index.html#prerequisites", 
            "text": "If you want to use  Azure Data Lake Store  to store your data, you must:     Enable Azure subscription for Data Lake Store, and then create an Azure Data Lake Store  storage account  in the same subscription as you use for launching Cloudbreak controller and clusters.      Next, in the cluster creation phase, specify the created account name only, and access to the Azure Data Lake Store will be configured automatically. For further instructions, refer to Microsoft Azure  documentation .", 
            "title": "Prerequisites"
        }, 
        {
            "location": "/azure-data/index.html#configuring-access-to-adls", 
            "text": "ADLS is not supported as a default file system, but access to data in ADLS is automatically configured if you select ADLS during  cluster creation , on the  Add File System  page.", 
            "title": "Configuring Access to ADLS"
        }, 
        {
            "location": "/azure-data/index.html#access-path", 
            "text": "ADLS access path syntax is:  adl:// account_name .azuredatalakestore.net/ dir/file  For example, the following Hadoop FileSystem shell commands demonstrate access to a storage account named \"myaccount\":  hadoop fs -mkdir adl://myaccount.azuredatalakestore.net/testdir  hadoop fs -put testfile adl://myaccount.azuredatalakestore.net/testdir/testfile  To use DistCp against ADLS, use the following syntax: hadoop distcp\n    [-D hadoop.security.credential.provider.path=localjceks://file/home/user/adls.jceks]\n    hdfs:// namenode_hostname :9001/user/foo/007020615\n    adl:// myaccount .azuredatalakestore.net/testDir/", 
            "title": "Access Path"
        }, 
        {
            "location": "/azure-data/index.html#accessing-data-in-wasb", 
            "text": "Windows Azure Storage Blob (WASB) is an object store service available on Azure.", 
            "title": "Accessing Data in WASB"
        }, 
        {
            "location": "/azure-data/index.html#prerequisites_1", 
            "text": "If you want to use Windows Azure Storage Blob to store your data, you must enable Azure subscription for Blob Storage, and then create a  storage account .", 
            "title": "Prerequisites"
        }, 
        {
            "location": "/azure-data/index.html#configuring-access-to-wasb", 
            "text": "In order to access data stored in your Azure blob storage account, you must configure your storage account access key in  core-site.xml . The configuration property that you must use is  fs.azure.account.key. account name .blob.core.windows.net  and the value is the access key.   For example the following property should be used for a storage account called \"testaccount\":   property \n   name fs.azure.account.key.testaccount.blob.core.windows.net /name \n   value TESTACCOUNT-ACCESS-KEY /value  /property   You can obtain your access key from the Access keys in your storage account settings.  Alternatively, it is possible, although not recommended or supported, to configure  fs.defaultFS  to use a wasb or wasbs URL. This causes all bare paths, such as /testDir/testFile to resolve automatically to that file system.", 
            "title": "Configuring Access to WASB"
        }, 
        {
            "location": "/azure-data/index.html#access-path_1", 
            "text": "WASB access path syntax is:  wasb:// container_name @ storage_account_name .blob.core.windows.net/ dir/file  For example, to access a file called \"testfile\" located in a directory called \"testdir\", stored in the container called \"testcontainer\" on the account called \"hortonworks\", the URL is:  wasb://testcontainer@hortonworks.blob.core.windows.net/testdir/testfile  You can also use \"wasbs\" prefix to utilize SSL-encrypted HTTPS access:  wasbs:// @ .blob.core.windows.net/dir/file  The following Hadoop FileSystem shell commands demonstrate access to a storage account named \"myaccount\" and a container named \"mycontainer\":  hadoop fs -ls wasb://mycontainer@myaccount.blob.core.windows.net/\n\nhadoop fs -mkdir wasb://mycontainer@myaccount.blob.core.windows.net/testDir\n\nhadoop fs -put testFile wasb://mycontainer@myaccount.blob.core.windows.net/testDir/testFile\n\nhadoop fs -cat wasb://mycontainer@myaccount.blob.core.windows.net/testDir/testFile\ntest file content", 
            "title": "Access Path"
        }, 
        {
            "location": "/azure-data/index.html#learn-more", 
            "text": "For more information about configuring the ADLS and WASB connectors and working with data stored in ADLS and WASB, refer to  Cloud Data Access  documentation.", 
            "title": "Learn More"
        }, 
        {
            "location": "/gcp-launch/index.html", 
            "text": "Launch Cloudbreak on GCP\n\n\nMeet the Prerequisites\n\n\nBefore launching Cloudbreak on GCP, you must meet the following prerequisites.\n\n\nGCP Account\n\n\nIn order to launch Cloudbreak on GCP, you must log in to your GCP account. If you don't have an account, you can create one at \nhttps://console.cloud.google.com\n.\n\n\nOnce you log in to your GCP account, you must either create a project or use an existing project. \n\n\nService Account\n\n\nIn order to launch clusters on GCP via Cloudbreak, you must have a Service Account that Cloudbreak can use to create resources. In addition, you must also have a P12 key associated with the account. If you need to create these, refer to \nGCP documentation\n on how to create a service account and generate a P12 key. \n\n\nOnce you have the service account that you want to use for Cloudbreak, make sure that your service account fulfills one of the following APIs are enabled for your service account:\n\n\n\n\nCompute Image User   \n\n\nCompute Instance Admin (v1)  \n\n\nCompute Network Admin  \n\n\nCompute Security Admin  \n\n\n\n\nA user with an \"Owner\" role can assign roles or access rules to service accounts from \nIAM \n Admin\n \n \nIAM\n. For example:\n\n\n \n\n\nVPC Network\n\n\nWhen launching Cloudbreak, you will be required to select an existing network in which Cloudbreak can be placed. The following ports must be open on the security group: 22 (SSH) and 443 (HTTPS). You may use the \ndefault\n network as long as the aforementioned ports are open. \n\n\nYou can manage networks under \nNetworking\n \n \nVPC Networks\n. To edit ports, click on the network name and then click on \nAdd firewall rules\n.\n\n\nRegion and Zone\n\n\nDecide in which region and zone you would like to launch Cloudbreak. You can launch Cloudbreak and provision your clusters in all regions \nsupported by GCP\n.  \n\n\nClusters created via Cloudbreak can be in the same or different region as Cloudbreak; when you launch a cluster, you select the region in which to launch it. \n\n\nLaunch the VM\n\n\n\n\n\n\nLog in to Google Cloud Platform.\n\n\n\n\n\n\nOpen the \nGoogle Cloud Shell\n by clicking on the  \n icon in the top-right corner:\n\n\n \n\n\n\n\n\n\nImport the Cloudbreak deployer image by executing the following command: \n\n\ngcloud compute images create cloudbreak-deployer-1161-2017-06-15 --source-uri gs://sequenceiqimage/cloudbreak-deployer-1161-2017-06-15.tar.gz\n\n\n\n\n\n\n\n\n\n\nTO-DO: This should be generated automatically. \n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn the GCP UI, from the \nProducts and services\n menu, select \nCompute Engine\n \n \nImages\n.\n\n\n\n\n\n\nIn the search bar, type the name of the Cloudbreak deployer image that you imported earlier.\n\n\n\n\n\n\nSelect the image and then select \nCreate Instance\n:  \n\n\n  \n\n\n\n\n\n\nYou will be redirected to \nVM instances\n \n \nCreate an instance\n form. Provide the following parameters for your VM:\n\n\n  \n\n\n\n\n\n\n\n\nParameter\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nName\n\n\nEnter a name for the VM.\n\n\n\n\n\n\nZone\n\n\nSelect the zone in which to launch the VM.\n\n\n\n\n\n\nMachine type\n\n\nThe minimum instance type suitable for Cloudbreak is \nn1-standard-2\n. The minimum requirements are 4GB RAM, 10GB disk, 2 cores.\n\n\n\n\n\n\nBoot disk\n\n\nVerify that the Cloudbreak deployer disk which you imported earlier is pre-selected.\n\n\n\n\n\n\n\n\n\n\n\n\nClick on \nManagement, disks, networking, SSH keys\n to view the options.\n\n\n\n\n\n\nUnder \nNetworking\n \n \nNetwork interfaces\n, select the network in which you want to launch Cloudbreak. \n\n\n\n\n\n\nUnder \nSSH Keys\n, check \nBlock project-wise SSH keys\n and paste your public SSH key.\n\n\n\n\n\n\nClick \nCreate\n. \n\n\n\n\n\n\nSSH to the VM\n\n\nNow that your VM is ready, access it via SSH: \n\n\n\n\nUse a private key matching the public key that you added to your  project.\n\n\nThe SSH user is called \"cloudbreak\".\n\n\nYou can obtain the VM's IP address from \nCompute Engine\n \n \nVM Instances\n, the \nExternal IP\n column.\n\n\n\n\nLaunch Cloudbreak Deployer\n\n\nAfter accessing the VM via SSH: \n\n\n\n\n\n\nNavigate to the cloudbreak-deployment directory:\n\n\ncd /var/lib/cloudbreak-deployment/\n\n\nThis directory contains configuration files and the supporting binaries for Cloudbreak deployer.\n\n\n\n\n\n\nInitialize your profile by creating a new file called \nProfile\n and adding the following content:\n\n\nexport UAA_DEFAULT_SECRET=MY-SECRET\nexport UAA_DEFAULT_USER_PW=MY-PASSWORDP\n  \n\n\nFor example: \n\n\nexport UAA_DEFAULT_SECRET=MySecret123\nexport UAA_DEFAULT_USER_PW=MySecurePassword123\n \n\n\n\n\nYou will need to provide the password when logging in to the Cloudbreak web UI and when using the Cloudbreak Shell. The secret will be used by Cloudbreak for authentication.  \n\n\n\n\n\n\n\n\nStart the Cloudbreak application by using the following command:\n\n\ncbd start\n\n\nThis will start the Docker containers and initialize the application. The first time you start the Coudbreak app, the process will take longer than usual due to the download of all the necessary docker images.\n\n\nThe \ncbd start\n command includes the \ncbd generate\n command which applies the following steps:\n\n\n\n\nCreates the \ndocker-compose.yml\n file, which describes the configuration of all the Docker containers needed for the Cloudbreak deployment.\n\n\nCreates the \nuaa.yml\n file, which holds the configuration of the identity server used to authenticate users with Cloudbreak.\n\n\n\n\n\n\nOnce the \ncbd start\n has finished, it returns the \"Uluwatu (Cloudbreak UI) url\" which you can later paste in your browser and log in to Cloudbreak web UI.\n\n\n\n\n\n\n\n\nCheck Cloudbreak deployer version and health: \n\n\ncbd doctor\n\n\n\n\n\n\nNext, check Cloudbreak Application logs: \n\n\ncbd logs cloudbreak\n\n\nYou should see a message like this in the log: \nStarted CloudbreakApplication in 36.823 seconds.\n Cloudbreak normally takes less than a minute to start.\n\n\n\n\n\n\nAccess Cloudbreak UI\n\n\n\n\n\n\nYou can log into the Cloudbreak application at  \nhttps://IP_Address\n. For example \nhttps://34.212.141.253\n.  You can obtain the VM's IP address from \nCompute Engine\n \n \nVM Instances\n, the \nExternal IP\n column.\n\n\n\n\n\n\nConfirm the security exception to proceed to the Cloudbreak web UI.\n\n\nThe first time you access Cloudbreak UI, Cloudbreak will automatically generate a self-signed certificate, due to which your browser will warn you about an untrusted connection and will ask you to confirm a security exception.\n\n\n\n\n\n\nLog in to the Cloudbreak web UI: \n\n\n\n\nThe default username is \nadmin@example.com\n but you should sign up with your own email address.    \n\n\nThe password is the value of the \nUAA_DEFAULT_USER_PW\n variable that you configured in your \nProfile\n file when \nlaunching Cloudbreak deployer\n.\n\n\n\n\n  \n\n\n\n\n\n\nCreate Cloudbreak Credential\n\n\nCloudbreak works by connecting your GCP account through this credential, and then uses it to create resources on your behalf. Before you can start provisioning cluster using Cloudbreak, you must create a Cloudbreak credential.\n\n\n\n\n\n\nIn the Cloudbreak web UI, open the \nmanage credentials\n pane. \n\n\n\n\n\n\nClick \n+create credential\n. \n\n\n\n\n\n\nProvide the following information:\n\n\n\n\n\n\n\n\nParameter\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nName\n\n\nEnter a name for your credential.\n\n\n\n\n\n\nDescription\n\n\n(Optional) Enter a description.\n\n\n\n\n\n\nProject Id\n\n\nEnter the project ID. You can obtain it from your GCP account by clicking on the name of your project at the top of the page and copying the \nID\n.\n\n\n\n\n\n\nService Account Email Address\n\n\n\"Service account ID\" value for your service account created in prerequisites. You can find it on GCP at \nIAM \n Admin\n \n \nService accounts\n.\n\n\n\n\n\n\nService Account Private (p12) Key\n\n\nPaste the P12 key that you created in the prerequisites when creating a service account.\n\n\n\n\n\n\nSSH Public Key\n\n\nPaste your SSH public key.\n\n\n\n\n\n\nSelect Platform\n\n\n(Optional) Select a platform (if previously configured).\n\n\n\n\n\n\nPublic In Account\n\n\n(Optional) If you check this, other users added to your Cloudbreak instance will be able to use this credential to create clusters.\n\n\n\n\n\n\n\n\n\n\n\n\nClick \n+create credential\n.\n\n\n\n\n\n\nYour credential should now be displayed at the top of the page and in the \nmanage credentials\n tab.\n\n\nCongratulations! You've successfully launched and configured Cloudbreak. Now you can use Cloudbreak to \ncreate clusters\n. \n\n\n\n\n\n\n\n\nNext: Define Infrastructure Templates", 
            "title": "Launch on GCP"
        }, 
        {
            "location": "/gcp-launch/index.html#launch-cloudbreak-on-gcp", 
            "text": "", 
            "title": "Launch Cloudbreak on GCP"
        }, 
        {
            "location": "/gcp-launch/index.html#meet-the-prerequisites", 
            "text": "Before launching Cloudbreak on GCP, you must meet the following prerequisites.", 
            "title": "Meet the Prerequisites"
        }, 
        {
            "location": "/gcp-launch/index.html#gcp-account", 
            "text": "In order to launch Cloudbreak on GCP, you must log in to your GCP account. If you don't have an account, you can create one at  https://console.cloud.google.com .  Once you log in to your GCP account, you must either create a project or use an existing project.", 
            "title": "GCP Account"
        }, 
        {
            "location": "/gcp-launch/index.html#service-account", 
            "text": "In order to launch clusters on GCP via Cloudbreak, you must have a Service Account that Cloudbreak can use to create resources. In addition, you must also have a P12 key associated with the account. If you need to create these, refer to  GCP documentation  on how to create a service account and generate a P12 key.   Once you have the service account that you want to use for Cloudbreak, make sure that your service account fulfills one of the following APIs are enabled for your service account:   Compute Image User     Compute Instance Admin (v1)    Compute Network Admin    Compute Security Admin     A user with an \"Owner\" role can assign roles or access rules to service accounts from  IAM   Admin     IAM . For example:", 
            "title": "Service Account"
        }, 
        {
            "location": "/gcp-launch/index.html#vpc-network", 
            "text": "When launching Cloudbreak, you will be required to select an existing network in which Cloudbreak can be placed. The following ports must be open on the security group: 22 (SSH) and 443 (HTTPS). You may use the  default  network as long as the aforementioned ports are open.   You can manage networks under  Networking     VPC Networks . To edit ports, click on the network name and then click on  Add firewall rules .", 
            "title": "VPC Network"
        }, 
        {
            "location": "/gcp-launch/index.html#region-and-zone", 
            "text": "Decide in which region and zone you would like to launch Cloudbreak. You can launch Cloudbreak and provision your clusters in all regions  supported by GCP .    Clusters created via Cloudbreak can be in the same or different region as Cloudbreak; when you launch a cluster, you select the region in which to launch it.", 
            "title": "Region and Zone"
        }, 
        {
            "location": "/gcp-launch/index.html#launch-the-vm", 
            "text": "Log in to Google Cloud Platform.    Open the  Google Cloud Shell  by clicking on the    icon in the top-right corner:       Import the Cloudbreak deployer image by executing the following command:   gcloud compute images create cloudbreak-deployer-1161-2017-06-15 --source-uri gs://sequenceiqimage/cloudbreak-deployer-1161-2017-06-15.tar.gz      TO-DO: This should be generated automatically.         In the GCP UI, from the  Products and services  menu, select  Compute Engine     Images .    In the search bar, type the name of the Cloudbreak deployer image that you imported earlier.    Select the image and then select  Create Instance :          You will be redirected to  VM instances     Create an instance  form. Provide the following parameters for your VM:         Parameter  Description      Name  Enter a name for the VM.    Zone  Select the zone in which to launch the VM.    Machine type  The minimum instance type suitable for Cloudbreak is  n1-standard-2 . The minimum requirements are 4GB RAM, 10GB disk, 2 cores.    Boot disk  Verify that the Cloudbreak deployer disk which you imported earlier is pre-selected.       Click on  Management, disks, networking, SSH keys  to view the options.    Under  Networking     Network interfaces , select the network in which you want to launch Cloudbreak.     Under  SSH Keys , check  Block project-wise SSH keys  and paste your public SSH key.    Click  Create .", 
            "title": "Launch the VM"
        }, 
        {
            "location": "/gcp-launch/index.html#ssh-to-the-vm", 
            "text": "Now that your VM is ready, access it via SSH:    Use a private key matching the public key that you added to your  project.  The SSH user is called \"cloudbreak\".  You can obtain the VM's IP address from  Compute Engine     VM Instances , the  External IP  column.", 
            "title": "SSH to the VM"
        }, 
        {
            "location": "/gcp-launch/index.html#launch-cloudbreak-deployer", 
            "text": "After accessing the VM via SSH:     Navigate to the cloudbreak-deployment directory:  cd /var/lib/cloudbreak-deployment/  This directory contains configuration files and the supporting binaries for Cloudbreak deployer.    Initialize your profile by creating a new file called  Profile  and adding the following content:  export UAA_DEFAULT_SECRET=MY-SECRET\nexport UAA_DEFAULT_USER_PW=MY-PASSWORDP     For example:   export UAA_DEFAULT_SECRET=MySecret123\nexport UAA_DEFAULT_USER_PW=MySecurePassword123     You will need to provide the password when logging in to the Cloudbreak web UI and when using the Cloudbreak Shell. The secret will be used by Cloudbreak for authentication.       Start the Cloudbreak application by using the following command:  cbd start  This will start the Docker containers and initialize the application. The first time you start the Coudbreak app, the process will take longer than usual due to the download of all the necessary docker images.  The  cbd start  command includes the  cbd generate  command which applies the following steps:   Creates the  docker-compose.yml  file, which describes the configuration of all the Docker containers needed for the Cloudbreak deployment.  Creates the  uaa.yml  file, which holds the configuration of the identity server used to authenticate users with Cloudbreak.    Once the  cbd start  has finished, it returns the \"Uluwatu (Cloudbreak UI) url\" which you can later paste in your browser and log in to Cloudbreak web UI.     Check Cloudbreak deployer version and health:   cbd doctor    Next, check Cloudbreak Application logs:   cbd logs cloudbreak  You should see a message like this in the log:  Started CloudbreakApplication in 36.823 seconds.  Cloudbreak normally takes less than a minute to start.", 
            "title": "Launch Cloudbreak Deployer"
        }, 
        {
            "location": "/gcp-launch/index.html#access-cloudbreak-ui", 
            "text": "You can log into the Cloudbreak application at   https://IP_Address . For example  https://34.212.141.253 .  You can obtain the VM's IP address from  Compute Engine     VM Instances , the  External IP  column.    Confirm the security exception to proceed to the Cloudbreak web UI.  The first time you access Cloudbreak UI, Cloudbreak will automatically generate a self-signed certificate, due to which your browser will warn you about an untrusted connection and will ask you to confirm a security exception.    Log in to the Cloudbreak web UI:    The default username is  admin@example.com  but you should sign up with your own email address.      The password is the value of the  UAA_DEFAULT_USER_PW  variable that you configured in your  Profile  file when  launching Cloudbreak deployer .", 
            "title": "Access Cloudbreak UI"
        }, 
        {
            "location": "/gcp-launch/index.html#create-cloudbreak-credential", 
            "text": "Cloudbreak works by connecting your GCP account through this credential, and then uses it to create resources on your behalf. Before you can start provisioning cluster using Cloudbreak, you must create a Cloudbreak credential.    In the Cloudbreak web UI, open the  manage credentials  pane.     Click  +create credential .     Provide the following information:     Parameter  Description      Name  Enter a name for your credential.    Description  (Optional) Enter a description.    Project Id  Enter the project ID. You can obtain it from your GCP account by clicking on the name of your project at the top of the page and copying the  ID .    Service Account Email Address  \"Service account ID\" value for your service account created in prerequisites. You can find it on GCP at  IAM   Admin     Service accounts .    Service Account Private (p12) Key  Paste the P12 key that you created in the prerequisites when creating a service account.    SSH Public Key  Paste your SSH public key.    Select Platform  (Optional) Select a platform (if previously configured).    Public In Account  (Optional) If you check this, other users added to your Cloudbreak instance will be able to use this credential to create clusters.       Click  +create credential .    Your credential should now be displayed at the top of the page and in the  manage credentials  tab.  Congratulations! You've successfully launched and configured Cloudbreak. Now you can use Cloudbreak to  create clusters .      Next: Define Infrastructure Templates", 
            "title": "Create Cloudbreak Credential"
        }, 
        {
            "location": "/gcp-config/index.html", 
            "text": "Define Infrastructure Templates\n\n\nAfter you've logged in to Cloudbreak and created a Cloudbreak credential, you have two options:\n\n\n\n\nCreate clusters using default infrastructure templates      \n\n\nDefine your own infrastructure templates   \n\n\n\n\nThe \ninfrastructure templates\n for resources such as \nnetworks\n, \nsecurity groups\n, and \nVMs and storage\n are saved to Cloudbreak's database and can be reused with multiple clusters to describe the infrastructure. When you add these resources in Cloudbreak web UI, Cloudbreak does not make any requests to your cloud provider account. Resources are only created on your cloud provider account after the create cluster button has been pushed. \n\n\nThis is illustrated and further explained in the \nArchitecture\n documentation.\n\n\nWe recommend that you review the default infrastructure  templates for networks, security groups, and VMs and storage to check if they meet your requirements. You can do this by expanding  their corresponding panes in the Cloudbreak web UI (shown in the screenshot) or by reading the documentation below.  \n\n\n \n\n\nThe following table describes the basic configurations that require an infrastructure template. If the default infrastructure templates don't work for you, you must create custom templates.\n\n\n\n\n\n\n\n\nConfiguration\n\n\nDescription\n\n\nCreate Cluster\n\n\n\n\n\n\n\n\n\n\nNetworks\n\n\n(Required) Virtual networks provide the networking infrastructure (network, subnet, Internet gateway, and so on) in which your clusters run. Virtual networks on GCP are called VPC networks. You can create new virtual networks or reuse existing virtual networks for your clusters. For basic information VPC networks, refer to \nGCP documentation\n.\n\n\nYou can select the network configuration for your clusters in the \nCreate Cluster\n wizard \n \nSet up Network and Security\n page. If no custom network is selected, default is used.\n\n\n\n\n\n\nSecurity Groups\n\n\n(Required) Security groups include rules which define inbound traffic allowed to the instances in your cluster. You can define different security group configurations for different nodes of your cluster. The security group rules in Cloudbreak correspond with the firewall rules on GCP. To learn more about firewall rules on GCP, refer to \nGCP documentation\n.\n\n\nYou can select the security group configurations for each host group in the \nCreate Cluster\n wizard \n \nChoose Blueprint\n page. If no custom security groups are selected, default is used.\n\n\n\n\n\n\nVMs and Storage\n\n\n(Required) \"Templates\" define the GCP infrastructure for the instances on which your cluster runs. You can select the VM instance types and their attached storage, including storage type, size, and count. You can reuse the same template for different cluster host groups or create different templates for different host groups.\n\n\nYou can select infrastructure templates for each host group  in the \nCreate Cluster\n wizard \n \nChoose Blueprint\n page. If no custom templates are selected, default is used.\n\n\n\n\n\n\n\n\nNetworks\n\n\nYou have five options:\n\n\n\n\nUse the default network configuration template\n: This requires no further action. Every time a cluster is created with this kind of network setup, a new virtual network and a new subnet with the specified IP range will be created for the instances on GCP.\n\n\nCreate a new virtual network and a new subnet\n: Every time a cluster is created with this kind of network setup, a new virtual network and a new subnet with the specified IP range will be created for the instances on GCP.    \n\n\nCreate a new subnet in an existing virtual network\n: Use this option if you already have a virtual network on GCP where you'd like to put the cluster but you don't want to have a separate subnet for it.  \n\n\nUse an existing subnet in an existing virtual network\n: Use this option if you have an existing virtual network with one or more subnets on GCP and you'd like to start the instances of a cluster in one of these existing subnets.  \n\n\nUse a legacy network without subnets\n: Use this option if you have a legacy virtual network on GCP that doesn't have subnet support and you'd like to start instances in that virtual network.\n\n\n\n\n\n\nIf creating a new subnet in an existing VPC, make sure that the new subnets that you define don't overlap with already deployed subnets in that VPC. \n\n\nIf using an existing subnet, make sure that you have enough room within your network space for the new instances.\n\n\n\n\nDefault Network\n\n\nCloudbreak includes one pre-defined network configuration called \ndefault-gcp-network\n, which is used by default when creating a cluster.  You can see it in the \nmanage networks\n tab. The configuration is: \n\n\n\n\n\n\n\n\nParameter\n\n\nValue\n\n\n\n\n\n\n\n\n\n\nName\n\n\ndefault-gcp-network\n\n\n\n\n\n\nDescription\n\n\nDefault network settings for Gcp clusters.\n\n\n\n\n\n\nSubnet (CIDR)\n\n\n10.0.0.0/16\n\n\n\n\n\n\n\n\nWith this default configuration, a new virtual network with a 10.0.0.0/16 subnet will be created every time a cluster is created. No resources will be created until you create a cluster using this configuration.\n\n\nAdd New Network and Subnet\n\n\nYou can define reusable network configurations for your clusters in the \nmanage networks\n tab:\n\n\n\n\n\n\nClick on \nCreate a new virtual network and a new subnet\n.\n\n\n\n\n\n\nProvide required parameters:\n\n\n\n\n\n\n\n\nParameter\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nName\n\n\nEnter a name for your configuration.\n\n\n\n\n\n\nDescription\n\n\n(Optional) Enter a description.\n\n\n\n\n\n\nSubnet (CIDR)\n\n\nEnter a valid \nCIDR\n for a new subnet that will be created within the VPC. For example \n10.0.0.0/24\n.\n\n\n\n\n\n\nPublic In Account\n\n\n(Optional) If this option is checked, all the users belonging to your account will be able to use this network template to create clusters, but they cannot delete it.\n\n\n\n\n\n\nSelect Platform\n\n\n(Optional) Select a previously created platform.\n\n\n\n\n\n\n\n\n\n\n\n\nClick on \n+create network\n.\n\n\nNo resources will be created until you create a cluster using this configuration.\n\n\n\n\n\n\nAdd New Subnet in Existing Network\n\n\nYou can define reusable network configurations for your clusters in the \nmanage networks\n tab:\n\n\n\n\n\n\nClick on \nCreate a new subnet in an existing virtual network\n. \n\n\n\n\n\n\nProvide required parameters: \n\n\n\n\nMake sure that the new subnet defined here doesn't overlap with any of your already deployed subnets in the network. \n\n\n\n\n\n\n\n\n\n\nParameter\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nName\n\n\nEnter a name for your configuration.\n\n\n\n\n\n\nDescription\n\n\n(Optional) Enter a description.\n\n\n\n\n\n\nVirtual Network Identifier\n\n\n\n\n\n\n\n\nSubnet (CIDR)\n\n\nEnter a valid \nCIDR\n for a new subnet that will be created within the VPC. For example \n10.0.0.0/24\n.\n\n\n\n\n\n\nPublic In Account\n\n\n(Optional) If this option is checked, all the users belonging to your account will be able to use this network template to create clusters, but they cannot delete it.\n\n\n\n\n\n\nSelect Platform\n\n\n(Optional) Select a previously created platform.\n\n\n\n\n\n\n\n\n\n\n\n\nClick on \n+create network\n.\n\n\nNo resources will be created until you create a cluster using this configuration.\n\n\n\n\n\n\nUse Existing Network and Subnet\n\n\nYou can define reusable network configurations for your clusters in the \nmanage networks\n tab:\n\n\n\n\n\n\nClick on \nUse an existing subnet in an existing virtual network\n. \n\n\n\n\n\n\nProvide required parameters: \n\n\n\n\n\n\n\n\nParameter\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nName\n\n\nEnter a name for your configuration.\n\n\n\n\n\n\nDescription\n\n\n(Optional) Enter a description.\n\n\n\n\n\n\nVirtual Network Identifier\n\n\nPaste the name of your existing VPC network. You can obtain it from your GCP account by coping the value of the \"Nname\" property.\n\n\n\n\n\n\nSubnet name\n\n\nPaste the name of your existing subnet. You can obtain it from your GCP account.\n\n\n\n\n\n\nDon't create public IPs\n\n\nIf you enable this option, Cloudbreak will not create security groups. You must make sure that the created instances in the subnet can reach each other.\n\n\n\n\n\n\nDon't create new firewall rules\n\n\nIf you enable this option, Cloudbreak will not create firewall rules (equivalent to security group rules). You must make sure (by openining every port in the subnet) that the created instances in the subnet can reach each other.\n\n\n\n\n\n\nPublic In Account\n\n\n(Optional) If this option is checked, all the users belonging to your account will be able to use this network template to create clusters, but they cannot delete it.\n\n\n\n\n\n\nSelect Platform\n\n\n(Optional) Select a previously created platform.\n\n\n\n\n\n\n\n\n\n\n\n\nClick on \n+create network\n.\n\n\nNo resources will be created until you create a cluster using this configuration.\n\n\n\n\n\n\nUse Legacy Network Without Subnets\n\n\nYou can define reusable network configurations for your clusters in the \nmanage networks\n tab:\n\n\n\n\n\n\nClick on \nUse a legacy network without subnets\n. \n\n\n\n\n\n\nProvide required parameters: \n\n\n\n\n\n\n\n\nParameter\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nName\n\n\nEnter a name for your configuration.\n\n\n\n\n\n\nDescription\n\n\n(Optional) Enter a description.\n\n\n\n\n\n\nVirtual Network Identifier\n\n\nPaste the name of your existing VPC network. You can obtain it from your GCP account by coping the value of the \"Nname\" property.\n\n\n\n\n\n\nPublic In Account\n\n\n(Optional) If this option is checked, all the users belonging to your account will be able to use this network template to create clusters, but they cannot delete it.\n\n\n\n\n\n\nSelect Platform\n\n\n(Optional) Select a previously created platform.\n\n\n\n\n\n\n\n\n\n\n\n\nClick on \n+create network\n.\n\n\nNo resources will be created until you create a cluster using this configuration.\n\n\n\n\n\n\nSecurity Groups\n\n\nYou have two options:\n\n\n\n\nUse the default security group configuration\n: This requires no further action.  \n\n\nAdd your own custom security group configuration\n: You can define your own security group by adding the ports, protocols, and CIDR ranges that you'd like to use. The rules defined here don't need to contain the internal rules (these are automatically added by Cloudbreak to the security group on GCP). \n\n\n\n\nYou can define different security group configurations for different nodes of your cluster.\n\n\nDefault Security Group\n\n\nCloudbreak includes one pre-defined security group configuration called \ndefault-gcp-only-ssh-and-ssl\n, which is used by default when creating a cluster. You can see it in the \nmanage security groups\n tab. The configuration is: \n\n\n\n\n\n\n\n\nCIDR\n\n\nPort\n\n\nProtocol\n\n\n\n\n\n\n\n\n\n\n0.0.0.0/0\n\n\n22\n\n\ntcp\n\n\n\n\n\n\n0.0.0.0/0\n\n\n433\n\n\ntcp\n\n\n\n\n\n\n0.0.0.0/0\n\n\n9443\n\n\ntcp\n\n\n\n\n\n\n\n\nNo resources will be created until you create a cluster using this configuration.\n\n\nAdd Custom Security Group\n\n\nYou can define reusable security group configurations for your clusters in the \nmanage security groups\n tab: \n\n\n\n\nClick on \nCreate a new security group\n.\n\n\n\n\nProvide required parameters:\n\n\n\n\n\n\n\n\nParameter\n\n\nValue\n\n\n\n\n\n\n\n\n\n\nName\n\n\nEnter a name for your security group configuration template.\n\n\n\n\n\n\nDescription\n\n\n(Optional) Enter a description.\n\n\n\n\n\n\nPublic In Account\n\n\n(Optional) If this option is checked, all the users belonging to your account will be able to use this security group template to create clusters, but they cannot delete it.\n\n\n\n\n\n\n\n\n\n\n\n\nProvide the following parameters in order to define \nSecurity Rules\n for this security group:\n\n\n\n\n\n\n\n\nParameter\n\n\nValue\n\n\n\n\n\n\n\n\n\n\nCIDR\n\n\nEnter a valid \nCIDR IP\n, from which the cluster will be accessed.\n\n\n\n\n\n\nPort\n\n\nEnter ports that you want to open. You can either list multiple ports, separated by a comma (for example \"22,443,9443\"), or you can define port ranges (for example \"1-65355\").\n\n\n\n\n\n\nProtocol\n\n\nEnter protocol that you want to use.\n\n\n\n\n\n\n\n\n\n\nPorts 22, 443, and 9443 must be open on every security group; otherwise Cloudbreak will not be able to communicate with your provisioned cluster.\n\n\n\n\n\n\n\n\nClick \n+Add Rule\n to save the security rules. If needed, click \n+Add Rule\n again to display a new \nSecurity Rules\n form and add another set of rules. \n\n\n\n\n\n\nClick \n+create security group\n to save the configuration. \n\n\nNo resources will be created until you create a cluster using this configuration.\n\n\n\n\n\n\n\n\nPorts used by Hadoop services: Ambari (8080) Consul (8500) NN (50070) RM Web (8088) Scheduler (8030RM) IPC (8050RM) Job history server (19888) HBase master (60000) HBase master web (60010) HBase RS (16020) HBase RS info (60030) Falcon (15000) Storm (8744) Hive metastore (9083) Hive server (10000) Hive server HTTP (10001) Accumulo master (9999) Accumulo Tserver (9997) Atlas (21000) KNOX (8443) Oozie (11000) Spark HS (18080) NM Web (8042) Zeppelin WebSocket (9996) Zeppelin UI (9995) Kibana (3080)  Elasticsearch (9200)\n\n\n\n\nVMs and Storage\n\n\nYou have two options:\n\n\n\n\nUse the default infrastructure template\n: This requires no further action.  \n\n\nAdd your own custom infrastructure template\n: Use this option if you have specific infrastructure requirements. A typical setup may combine multiple templates in a cluster for the different types of nodes. For example you may want to attach multiple large disks to the data nodes or have memory optimized instances for Spark nodes. \n\n\n\n\nDefault Template\n\n\nCloudbreak includes one pre-defined infrastructure template called \nminviable-gcp\n, which is used by default when creating a cluster. You can see it in the \nmanage templates\n tab. The configuration is:\n\n\n\n\n\n\n\n\nParameter\n\n\nValue\n\n\n\n\n\n\n\n\n\n\nName\n\n\nminviable-gcp\n\n\n\n\n\n\nInstance Type\n\n\nn1-standard-4\n\n\n\n\n\n\nAttached Volumes Per Instance\n\n\n1\n\n\n\n\n\n\nVolume Size (GB)\n\n\n100\n\n\n\n\n\n\nVolume Type\n\n\nSolid-state persistent disks (SSD)\n\n\n\n\n\n\n\n\nAdd Custom Template\n\n\nYou can define reusable cluster templates in the \nmanage templates\n tab: \n\n\n\n\n\n\nClick on \n+create template\n.\n\n\n\n\n\n\nProvide required parameters: \n\n\n\n\n\n\n\n\nParameter\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nName\n\n\nEnter a name for your configuration.\n\n\n\n\n\n\nDescription\n\n\n(Optional) Enter a description.\n\n\n\n\n\n\nInstance Type\n\n\nSelect a VM instance type. For more information about instance types on Azure refer to \nGCP documentation\n.\n\n\n\n\n\n\nVolume Type\n\n\nSelect the volume type. The options are:\nStandard persistent disks (HDD)\nSolid-state persistent disks (SSD)\n For more information about these options refer to \nGCP documentation\n.\n\n\n\n\n\n\nAttached Volumes Per Instance\n\n\nEnter the number of volumes attached per instance. Default is 1.\n\n\n\n\n\n\nVolume Size (GB)\n\n\nEnter the size in GBs for each volume. Default is 100.\n\n\n\n\n\n\nPublic In Account\n\n\n(Optional) If this option is checked, all the users belonging to your account will be able to use this template to create clusters, but they cannot delete it.\n\n\n\n\n\n\nPreemptible\n\n\nIf Preemptible is checked then the template will be preemptible. A \npreemptible\n VM is an instance that you can create and run at a much lower price than normal instances.\n\n\n\n\n\n\nPublic In Account\n\n\n(Optional) If this option is checked, all the users belonging to your account will be able to use this template to create clusters, but they cannot delete it.\n\n\n\n\n\n\nSelect Platform\n\n\n(Optional) Select a previously created platform.\n\n\n\n\n\n\n\n\n\n\n\n\nClick on \n+create template\n.\n\n\nNo resources will be created until you create a cluster using this configuration.\n\n\n\n\n\n\n\n\nNext: Create a Cluster", 
            "title": "Define Infrastructure Templates"
        }, 
        {
            "location": "/gcp-config/index.html#define-infrastructure-templates", 
            "text": "After you've logged in to Cloudbreak and created a Cloudbreak credential, you have two options:   Create clusters using default infrastructure templates        Define your own infrastructure templates      The  infrastructure templates  for resources such as  networks ,  security groups , and  VMs and storage  are saved to Cloudbreak's database and can be reused with multiple clusters to describe the infrastructure. When you add these resources in Cloudbreak web UI, Cloudbreak does not make any requests to your cloud provider account. Resources are only created on your cloud provider account after the create cluster button has been pushed.   This is illustrated and further explained in the  Architecture  documentation.  We recommend that you review the default infrastructure  templates for networks, security groups, and VMs and storage to check if they meet your requirements. You can do this by expanding  their corresponding panes in the Cloudbreak web UI (shown in the screenshot) or by reading the documentation below.       The following table describes the basic configurations that require an infrastructure template. If the default infrastructure templates don't work for you, you must create custom templates.     Configuration  Description  Create Cluster      Networks  (Required) Virtual networks provide the networking infrastructure (network, subnet, Internet gateway, and so on) in which your clusters run. Virtual networks on GCP are called VPC networks. You can create new virtual networks or reuse existing virtual networks for your clusters. For basic information VPC networks, refer to  GCP documentation .  You can select the network configuration for your clusters in the  Create Cluster  wizard    Set up Network and Security  page. If no custom network is selected, default is used.    Security Groups  (Required) Security groups include rules which define inbound traffic allowed to the instances in your cluster. You can define different security group configurations for different nodes of your cluster. The security group rules in Cloudbreak correspond with the firewall rules on GCP. To learn more about firewall rules on GCP, refer to  GCP documentation .  You can select the security group configurations for each host group in the  Create Cluster  wizard    Choose Blueprint  page. If no custom security groups are selected, default is used.    VMs and Storage  (Required) \"Templates\" define the GCP infrastructure for the instances on which your cluster runs. You can select the VM instance types and their attached storage, including storage type, size, and count. You can reuse the same template for different cluster host groups or create different templates for different host groups.  You can select infrastructure templates for each host group  in the  Create Cluster  wizard    Choose Blueprint  page. If no custom templates are selected, default is used.", 
            "title": "Define Infrastructure Templates"
        }, 
        {
            "location": "/gcp-config/index.html#networks", 
            "text": "You have five options:   Use the default network configuration template : This requires no further action. Every time a cluster is created with this kind of network setup, a new virtual network and a new subnet with the specified IP range will be created for the instances on GCP.  Create a new virtual network and a new subnet : Every time a cluster is created with this kind of network setup, a new virtual network and a new subnet with the specified IP range will be created for the instances on GCP.      Create a new subnet in an existing virtual network : Use this option if you already have a virtual network on GCP where you'd like to put the cluster but you don't want to have a separate subnet for it.    Use an existing subnet in an existing virtual network : Use this option if you have an existing virtual network with one or more subnets on GCP and you'd like to start the instances of a cluster in one of these existing subnets.    Use a legacy network without subnets : Use this option if you have a legacy virtual network on GCP that doesn't have subnet support and you'd like to start instances in that virtual network.    If creating a new subnet in an existing VPC, make sure that the new subnets that you define don't overlap with already deployed subnets in that VPC.   If using an existing subnet, make sure that you have enough room within your network space for the new instances.", 
            "title": "Networks"
        }, 
        {
            "location": "/gcp-config/index.html#default-network", 
            "text": "Cloudbreak includes one pre-defined network configuration called  default-gcp-network , which is used by default when creating a cluster.  You can see it in the  manage networks  tab. The configuration is:      Parameter  Value      Name  default-gcp-network    Description  Default network settings for Gcp clusters.    Subnet (CIDR)  10.0.0.0/16     With this default configuration, a new virtual network with a 10.0.0.0/16 subnet will be created every time a cluster is created. No resources will be created until you create a cluster using this configuration.", 
            "title": "Default Network"
        }, 
        {
            "location": "/gcp-config/index.html#add-new-network-and-subnet", 
            "text": "You can define reusable network configurations for your clusters in the  manage networks  tab:    Click on  Create a new virtual network and a new subnet .    Provide required parameters:     Parameter  Description      Name  Enter a name for your configuration.    Description  (Optional) Enter a description.    Subnet (CIDR)  Enter a valid  CIDR  for a new subnet that will be created within the VPC. For example  10.0.0.0/24 .    Public In Account  (Optional) If this option is checked, all the users belonging to your account will be able to use this network template to create clusters, but they cannot delete it.    Select Platform  (Optional) Select a previously created platform.       Click on  +create network .  No resources will be created until you create a cluster using this configuration.", 
            "title": "Add New Network and Subnet"
        }, 
        {
            "location": "/gcp-config/index.html#add-new-subnet-in-existing-network", 
            "text": "You can define reusable network configurations for your clusters in the  manage networks  tab:    Click on  Create a new subnet in an existing virtual network .     Provide required parameters:    Make sure that the new subnet defined here doesn't overlap with any of your already deployed subnets in the network.       Parameter  Description      Name  Enter a name for your configuration.    Description  (Optional) Enter a description.    Virtual Network Identifier     Subnet (CIDR)  Enter a valid  CIDR  for a new subnet that will be created within the VPC. For example  10.0.0.0/24 .    Public In Account  (Optional) If this option is checked, all the users belonging to your account will be able to use this network template to create clusters, but they cannot delete it.    Select Platform  (Optional) Select a previously created platform.       Click on  +create network .  No resources will be created until you create a cluster using this configuration.", 
            "title": "Add New Subnet in Existing Network"
        }, 
        {
            "location": "/gcp-config/index.html#use-existing-network-and-subnet", 
            "text": "You can define reusable network configurations for your clusters in the  manage networks  tab:    Click on  Use an existing subnet in an existing virtual network .     Provide required parameters:      Parameter  Description      Name  Enter a name for your configuration.    Description  (Optional) Enter a description.    Virtual Network Identifier  Paste the name of your existing VPC network. You can obtain it from your GCP account by coping the value of the \"Nname\" property.    Subnet name  Paste the name of your existing subnet. You can obtain it from your GCP account.    Don't create public IPs  If you enable this option, Cloudbreak will not create security groups. You must make sure that the created instances in the subnet can reach each other.    Don't create new firewall rules  If you enable this option, Cloudbreak will not create firewall rules (equivalent to security group rules). You must make sure (by openining every port in the subnet) that the created instances in the subnet can reach each other.    Public In Account  (Optional) If this option is checked, all the users belonging to your account will be able to use this network template to create clusters, but they cannot delete it.    Select Platform  (Optional) Select a previously created platform.       Click on  +create network .  No resources will be created until you create a cluster using this configuration.", 
            "title": "Use Existing Network and Subnet"
        }, 
        {
            "location": "/gcp-config/index.html#use-legacy-network-without-subnets", 
            "text": "You can define reusable network configurations for your clusters in the  manage networks  tab:    Click on  Use a legacy network without subnets .     Provide required parameters:      Parameter  Description      Name  Enter a name for your configuration.    Description  (Optional) Enter a description.    Virtual Network Identifier  Paste the name of your existing VPC network. You can obtain it from your GCP account by coping the value of the \"Nname\" property.    Public In Account  (Optional) If this option is checked, all the users belonging to your account will be able to use this network template to create clusters, but they cannot delete it.    Select Platform  (Optional) Select a previously created platform.       Click on  +create network .  No resources will be created until you create a cluster using this configuration.", 
            "title": "Use Legacy Network Without Subnets"
        }, 
        {
            "location": "/gcp-config/index.html#security-groups", 
            "text": "You have two options:   Use the default security group configuration : This requires no further action.    Add your own custom security group configuration : You can define your own security group by adding the ports, protocols, and CIDR ranges that you'd like to use. The rules defined here don't need to contain the internal rules (these are automatically added by Cloudbreak to the security group on GCP).    You can define different security group configurations for different nodes of your cluster.", 
            "title": "Security Groups"
        }, 
        {
            "location": "/gcp-config/index.html#default-security-group", 
            "text": "Cloudbreak includes one pre-defined security group configuration called  default-gcp-only-ssh-and-ssl , which is used by default when creating a cluster. You can see it in the  manage security groups  tab. The configuration is:      CIDR  Port  Protocol      0.0.0.0/0  22  tcp    0.0.0.0/0  433  tcp    0.0.0.0/0  9443  tcp     No resources will be created until you create a cluster using this configuration.", 
            "title": "Default Security Group"
        }, 
        {
            "location": "/gcp-config/index.html#add-custom-security-group", 
            "text": "You can define reusable security group configurations for your clusters in the  manage security groups  tab:    Click on  Create a new security group .   Provide required parameters:     Parameter  Value      Name  Enter a name for your security group configuration template.    Description  (Optional) Enter a description.    Public In Account  (Optional) If this option is checked, all the users belonging to your account will be able to use this security group template to create clusters, but they cannot delete it.       Provide the following parameters in order to define  Security Rules  for this security group:     Parameter  Value      CIDR  Enter a valid  CIDR IP , from which the cluster will be accessed.    Port  Enter ports that you want to open. You can either list multiple ports, separated by a comma (for example \"22,443,9443\"), or you can define port ranges (for example \"1-65355\").    Protocol  Enter protocol that you want to use.      Ports 22, 443, and 9443 must be open on every security group; otherwise Cloudbreak will not be able to communicate with your provisioned cluster.     Click  +Add Rule  to save the security rules. If needed, click  +Add Rule  again to display a new  Security Rules  form and add another set of rules.     Click  +create security group  to save the configuration.   No resources will be created until you create a cluster using this configuration.     Ports used by Hadoop services: Ambari (8080) Consul (8500) NN (50070) RM Web (8088) Scheduler (8030RM) IPC (8050RM) Job history server (19888) HBase master (60000) HBase master web (60010) HBase RS (16020) HBase RS info (60030) Falcon (15000) Storm (8744) Hive metastore (9083) Hive server (10000) Hive server HTTP (10001) Accumulo master (9999) Accumulo Tserver (9997) Atlas (21000) KNOX (8443) Oozie (11000) Spark HS (18080) NM Web (8042) Zeppelin WebSocket (9996) Zeppelin UI (9995) Kibana (3080)  Elasticsearch (9200)", 
            "title": "Add Custom Security Group"
        }, 
        {
            "location": "/gcp-config/index.html#vms-and-storage", 
            "text": "You have two options:   Use the default infrastructure template : This requires no further action.    Add your own custom infrastructure template : Use this option if you have specific infrastructure requirements. A typical setup may combine multiple templates in a cluster for the different types of nodes. For example you may want to attach multiple large disks to the data nodes or have memory optimized instances for Spark nodes.", 
            "title": "VMs and Storage"
        }, 
        {
            "location": "/gcp-config/index.html#default-template", 
            "text": "Cloudbreak includes one pre-defined infrastructure template called  minviable-gcp , which is used by default when creating a cluster. You can see it in the  manage templates  tab. The configuration is:     Parameter  Value      Name  minviable-gcp    Instance Type  n1-standard-4    Attached Volumes Per Instance  1    Volume Size (GB)  100    Volume Type  Solid-state persistent disks (SSD)", 
            "title": "Default Template"
        }, 
        {
            "location": "/gcp-config/index.html#add-custom-template", 
            "text": "You can define reusable cluster templates in the  manage templates  tab:     Click on  +create template .    Provide required parameters:      Parameter  Description      Name  Enter a name for your configuration.    Description  (Optional) Enter a description.    Instance Type  Select a VM instance type. For more information about instance types on Azure refer to  GCP documentation .    Volume Type  Select the volume type. The options are: Standard persistent disks (HDD) Solid-state persistent disks (SSD)  For more information about these options refer to  GCP documentation .    Attached Volumes Per Instance  Enter the number of volumes attached per instance. Default is 1.    Volume Size (GB)  Enter the size in GBs for each volume. Default is 100.    Public In Account  (Optional) If this option is checked, all the users belonging to your account will be able to use this template to create clusters, but they cannot delete it.    Preemptible  If Preemptible is checked then the template will be preemptible. A  preemptible  VM is an instance that you can create and run at a much lower price than normal instances.    Public In Account  (Optional) If this option is checked, all the users belonging to your account will be able to use this template to create clusters, but they cannot delete it.    Select Platform  (Optional) Select a previously created platform.       Click on  +create template .  No resources will be created until you create a cluster using this configuration.     Next: Create a Cluster", 
            "title": "Add Custom Template"
        }, 
        {
            "location": "/gcp-blueprints/index.html", 
            "text": "Define Cluster Blueprints\n\n\nCluster blueprints\n are your declarative definition of a Hadoop cluster, defining the host groups and which components to install on which host group. Ambari uses them as a base for your clusters. \n\n\nYou have three options:\n\n\n\n\nUse one of the pre-defined blueprints.  \n\n\nCopy and edit one of the pre-defined blueprints.   \n\n\nAdd your custom blueprint by uploading a JSON file or pasting the JSON text. \n\n\n\n\nWe recommend that you review the default blueprints to check if they meet your requirements. You can do this by expanding  the \nmanage bluerints\n pane in the Cloudbreak web UI (shown in the screenshot) or by reading the documentation below.  \n\n\n \n\n\nHere\n is an example of a blueprint. \n\n\nThe host groups in the JSON will be mapped to a set of instances when starting the cluster, and the specified services and components will be installed on the corresponding nodes. It is not necessary to define a complete configuration in the blueprint. If a configuration is missing, Ambari will fill that with a default value. \n\n\nA blueprint can be modified later from the Ambari UI.\n\n\nA blueprint can be exported from a running Ambari cluster and can be reused in Cloudbreak after slight modifications. When a blueprint is exported, some configurations are hardcoded for example domain names, memory configurations, and so on, that won't be applicable to the Cloudbreak cluster. There is no automatic way to modify an exported blueprint and make it instantly usable in Cloudbreak, the modifications have to be done manually.\n\n\nDefault Blueprints\n\n\nCloudbreak includes three default HDP cluster blueprints:\n\n\nHDP Version: \nHDP 2.6\n\n\n\n\n\n\n\n\nCluster Type\n\n\nServices\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nData Science\n\n\n Spark 1.6,\nZeppelin 0.7.0\n\n\nThis cluster configuration includes Spark 1.6 with Zeppelin.\n\n\n\n\n\n\nData Science\n\n\n Spark 2.1,\nZeppelin 0.7.0\n\n\nThis cluster configuration includes Spark 2.1 with Zeppelin.\n\n\n\n\n\n\nEDW - Analytics\n\n\n Hive 2 LLAP\n,\nZeppelin 0.7.0\n\n\nThis cluster configuration includes Hive 2 LLAP.\n\n\n\n\n\n\nEDW - ETL\n\n\n Hive 1.2.1,\nSpark 1.6\n\n\nThis cluster configuration includes Hive and Spark 1.6.\n\n\n\n\n\n\nEDW - ETL\n\n\n Hive 1.2.1,\n Spark 2.1\n\n\nThis cluster configuration includes Hive and Spark 2.1.\n\n\n\n\n\n\nBI\n\n\n Druid 0.9.2\n\n\nThis cluster configuration includes a Technical Preview of Druid.\n\n\n\n\n\n\n\n\nHDP Version: \nHDP 2.5\n\n\n\n\n\n\n\n\nCluster Type\n\n\nServices\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nData Science\n\n\n Spark 1.6,\nZeppelin 0.6.0\n\n\nThis cluster configuration includes Spark 1.6 and Zeppelin.\n\n\n\n\n\n\nEDW - ETL\n\n\n Hive 1.2.1,\nSpark 1.6\n\n\nThis cluster configuration includes Hive and Spark 1.6.\n\n\n\n\n\n\nEDW - ETL\n\n\n Hive 1.2.1,\n Spark 2.0\n\n\nThis cluster configuration includes a Technical Preview of Spark 2.0.\n\n\n\n\n\n\nEDW - Analytics\n\n\n Hive 2 LLAP\n,\nZeppelin 0.6.0\n\n\nThis cluster configuration includes a Technical Preview of Hive 2 LLAP.\n\n\n\n\n\n\n\n\n\n    \nChoosing Your Configuration\n\n    \n\nWhen creating a cluster, you can choose a more stable cluster configuration for a predicable experience.\nAlternatively, you can try the latest capabilities by choosing a cluster configuration\nthat is much more experimental. The following configuration classification applies:\n\n\n\n Stable configurations are the best choice if you want to avoid issues and other problems with launching and using clusters.\n\n\n If you want to use a Technical Preview version of a component in a release of HDP, use these configurations.\n\n\n These are the most cutting edge of the configurations, including Technical Preview components in a Technical Preview HDP release.\n\n\n\n\n\n\n\n\n\nCopy and Edit Existing Blueprint\n\n\nYou can modify default or previously added blueprints in the \nmanage blueprints\n tab. To do that, expand the entry in the Cloudbreak UI and then click \ncopy \n edit\n. \n\n\nAdd Custom Blueprint\n\n\nYou can define reusable blueprints for your clusters in the \nmanage blueprints\n tab. To add your own blueprint, click \n+create blueprint\n and enter the following parameters:\n\n\n\n\n\n\n\n\nParameter\n\n\nValue\n\n\n\n\n\n\n\n\n\n\nName\n\n\nEnter a name for your blueprint.\n\n\n\n\n\n\nDescription\n\n\n(Optional) Enter a description for your blueprint.\n\n\n\n\n\n\nBlueprint Source\n\n\nSelect one of: \nText\n: Paste blueprint in JSON format.\n \nFile\n: Upload a file that contains the blueprint.\n \nURL\n: Specify the URL for your blueprint.\n\n\n\n\n\n\nPublic In Account\n\n\n(Optional) If this option is checked, all the users belonging to your account will be able to use this blueprint to create clusters, but they cannot delete it.\n\n\n\n\n\n\n\n\n\n\nNext: Create a Cluster", 
            "title": "Define Cluster Blueprints"
        }, 
        {
            "location": "/gcp-blueprints/index.html#define-cluster-blueprints", 
            "text": "Cluster blueprints  are your declarative definition of a Hadoop cluster, defining the host groups and which components to install on which host group. Ambari uses them as a base for your clusters.   You have three options:   Use one of the pre-defined blueprints.    Copy and edit one of the pre-defined blueprints.     Add your custom blueprint by uploading a JSON file or pasting the JSON text.    We recommend that you review the default blueprints to check if they meet your requirements. You can do this by expanding  the  manage bluerints  pane in the Cloudbreak web UI (shown in the screenshot) or by reading the documentation below.       Here  is an example of a blueprint.   The host groups in the JSON will be mapped to a set of instances when starting the cluster, and the specified services and components will be installed on the corresponding nodes. It is not necessary to define a complete configuration in the blueprint. If a configuration is missing, Ambari will fill that with a default value.   A blueprint can be modified later from the Ambari UI.  A blueprint can be exported from a running Ambari cluster and can be reused in Cloudbreak after slight modifications. When a blueprint is exported, some configurations are hardcoded for example domain names, memory configurations, and so on, that won't be applicable to the Cloudbreak cluster. There is no automatic way to modify an exported blueprint and make it instantly usable in Cloudbreak, the modifications have to be done manually.", 
            "title": "Define Cluster Blueprints"
        }, 
        {
            "location": "/gcp-blueprints/index.html#default-blueprints", 
            "text": "Cloudbreak includes three default HDP cluster blueprints:", 
            "title": "Default Blueprints"
        }, 
        {
            "location": "/gcp-blueprints/index.html#hdp-version-hdp-26", 
            "text": "Cluster Type  Services  Description      Data Science   Spark 1.6, Zeppelin 0.7.0  This cluster configuration includes Spark 1.6 with Zeppelin.    Data Science   Spark 2.1, Zeppelin 0.7.0  This cluster configuration includes Spark 2.1 with Zeppelin.    EDW - Analytics   Hive 2 LLAP , Zeppelin 0.7.0  This cluster configuration includes Hive 2 LLAP.    EDW - ETL   Hive 1.2.1, Spark 1.6  This cluster configuration includes Hive and Spark 1.6.    EDW - ETL   Hive 1.2.1,  Spark 2.1  This cluster configuration includes Hive and Spark 2.1.    BI   Druid 0.9.2  This cluster configuration includes a Technical Preview of Druid.", 
            "title": "HDP Version: HDP 2.6"
        }, 
        {
            "location": "/gcp-blueprints/index.html#hdp-version-hdp-25", 
            "text": "Cluster Type  Services  Description      Data Science   Spark 1.6, Zeppelin 0.6.0  This cluster configuration includes Spark 1.6 and Zeppelin.    EDW - ETL   Hive 1.2.1, Spark 1.6  This cluster configuration includes Hive and Spark 1.6.    EDW - ETL   Hive 1.2.1,  Spark 2.0  This cluster configuration includes a Technical Preview of Spark 2.0.    EDW - Analytics   Hive 2 LLAP , Zeppelin 0.6.0  This cluster configuration includes a Technical Preview of Hive 2 LLAP.     \n     Choosing Your Configuration \n     \nWhen creating a cluster, you can choose a more stable cluster configuration for a predicable experience.\nAlternatively, you can try the latest capabilities by choosing a cluster configuration\nthat is much more experimental. The following configuration classification applies:   Stable configurations are the best choice if you want to avoid issues and other problems with launching and using clusters.   If you want to use a Technical Preview version of a component in a release of HDP, use these configurations.   These are the most cutting edge of the configurations, including Technical Preview components in a Technical Preview HDP release.", 
            "title": "HDP Version: HDP 2.5"
        }, 
        {
            "location": "/gcp-blueprints/index.html#copy-and-edit-existing-blueprint", 
            "text": "You can modify default or previously added blueprints in the  manage blueprints  tab. To do that, expand the entry in the Cloudbreak UI and then click  copy   edit .", 
            "title": "Copy and Edit Existing Blueprint"
        }, 
        {
            "location": "/gcp-blueprints/index.html#add-custom-blueprint", 
            "text": "You can define reusable blueprints for your clusters in the  manage blueprints  tab. To add your own blueprint, click  +create blueprint  and enter the following parameters:     Parameter  Value      Name  Enter a name for your blueprint.    Description  (Optional) Enter a description for your blueprint.    Blueprint Source  Select one of:  Text : Paste blueprint in JSON format.   File : Upload a file that contains the blueprint.   URL : Specify the URL for your blueprint.    Public In Account  (Optional) If this option is checked, all the users belonging to your account will be able to use this blueprint to create clusters, but they cannot delete it.      Next: Create a Cluster", 
            "title": "Add Custom Blueprint"
        }, 
        {
            "location": "/gcp-create/index.html", 
            "text": "Create a Cluster on GCP\n\n\nTo create a cluster via CLoudbreak UI:\n\n\n\n\n\n\nLog in to the Cloudbreak UI.\n\n\n\n\n\n\nIn the top right corner, select the credential that you want to use to create a cluster:\n\n\n  \n\n\n\n\n\n\nClick \n+create cluster\n and the \nCreate cluster\n form is displayed.\n\n\n\n\n\n\nOn the \nConfigure Cluster\n page, provide the following parameters:\n\n\n\n\nTo view advanced options, click \nShow Advanced Options\n. To learn about advanced options, refer to \nAdvanced Options\n.\n\n\n\n\n\n\n\n\n\n\nParameter\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nCluster Name\n\n\nEnter a name for your cluster. The name must be between 5 and 40 characters, must start with a letter, must only include lowercase letters, numbers, and hyphens.\n\n\n\n\n\n\nTags\n\n\n(Optional) You can optionally add tags, which will help you find your cluster-related resources, such as VMs, in your cloud provider account.\n\n\n\n\n\n\nRegion\n\n\nSelect the region in which you would like to launch your cluster.\n\n\n\n\n\n\nAvailability Zone\n\n\nSelect the availability zone in which you would like to launch your cluster.\n\n\n\n\n\n\nSend Email When Cluster is Ready\n\n\n(Optional) Check this to receive an email each time the cluster status changes.\n\n\n\n\n\n\nPublic In Account\n\n\n(Optional) If this option is checked, all the users belonging to your account will be able to use this cluster, but they cannot delete it.\n\n\n\n\n\n\n\n\n\n\nBy default, Ambari Username and Ambari Password are set to \nadmin\n. You can override it in the \"\nConfigure Cluster\n\" tab.\n\n\n\n\n\n\n\n\nOn the \nSet up Network and Security\n page, provide the following parameters:\n\n\n\n\n\n\n\n\nParameter\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nNetwork\n\n\nSelect the virtual network in which you would like your cluster to be provisioned. You can define custom network configurations or use default network configurations.\n\n\n\n\n\n\nEnable Knox Gateway\n\n\n(Optional) Select this option to enable secure access to Ambari web UI and other cluster UIs via Knox gateway.\n\n\n\n\n\n\nEnable Kerberos Security\n\n\n(Optional) Select this option to enable Kerberos for your cluster. You will have an option to create a new kerberos or use an existing one. For more information refer to Kerberos \ndocumentation\n.\n\n\n\n\n\n\n\n\n\n\n\n\nOn the \nChoose Blueprint\n page, select the blueprint that you would like to use for your cluster. You can either choose one of the pre-configured blueprints, or add your own in the \nmanage blueprints\n tab.\n\n\nFor each host group you must provide the following:\n\n\n\n\n\n\n\n\nParameter\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nGroup Size\n\n\nEnter a number defining how many nodes to create per host group. Default is 1. The \"Group Size\" for that host group on which Ambari Server is installed must be set to \"1\".\n\n\n\n\n\n\nTemplate\n\n\nIf you have previously created a template for VMs and storage, you can select it here. If you don't make a selection, default will be used.\n\n\n\n\n\n\nSecurity Group\n\n\nIf you have previously created a template for a security group, you can select it here. If you don't make a selection, default will be used.\n\n\n\n\n\n\nAmbari Server\n\n\nYou must select one node for Ambari Server. The \"Group Size\" for that host group must be set to \"1\".\n\n\n\n\n\n\nRecipes\n\n\nYou can select a previously added recipe (custom script) to be executed on all nodes of the host group. Refer to \nRecipes\n.\n\n\n\n\n\n\n\n\n\n\n\n\nOn the \nAdd File System\n page, select to use one of the following filesystems:\n\n\n\n\nLocal HDFS\n: No external storage outside of HDFS will be used\n\n\n\n\nGCS file system\n: If you select to use Google Cloud Storage option, you must provide:\n\n\n\n\n\n\n\n\nParameter\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nProject Id\n\n\nThe project ID registered when creating a credential should be pre-populated.\n\n\n\n\n\n\nService Account Email Address\n\n\nThe email address registered when creating a credential should be pre-populated.\n\n\n\n\n\n\nDefault Bucket Name\n\n\n(Deprecated) The name of an existing Google Cloud Storage bucket. This is an optional and deprecated configuration parameter (mapped to \"fs.gs.system.bucket\" in core-site.xml) to set the GCS bucket as a default bucket for URIs without having to specify the \"gs:\" prefix.  For more information about the \nGCS file system\n and \nbucket naming\n, refer to  GCP documentation.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nClick on \nReview and Launch\n and then \n+create and start cluster\n.\n\n\n\n\n\n\nYou will be redirected to the Cloudbreak dashboard, and a new tile representing your cluster will appear at the top of the page.\n\n\n\n\n\n\nAdvanced Options\n\n\nClick on \nShow Advanced Options\n to enter additional configuration options.\n\n\nConfigure Cluster\n\n\nYou can optionally configure the following advanced parameters:\n\n\n\n\n\n\n\n\nParameter\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nAmbari Username\n\n\nYou can log in to the Ambari UI using this username. By default, this is set to \nadmin\n.\n\n\n\n\n\n\nAmbari Password\n\n\nYou can log in to the Ambari UI using this password. By default, this is set to \nadmin\n.\n\n\n\n\n\n\nProvision Cluster\n\n\nSALT\n is pre-selected to provision your cluster.\n\n\n\n\n\n\nEnable Lifetime Management\n\n\nCheck this option if you would like your cluster to be automatically terminated after a specific amount of time (defined as \"Time to Live\" in minuter) has passed.\n\n\n\n\n\n\nFlex Subscription\n\n\nThis option will appear if you have configured your deployment for a \nFlex Subscription\n.\n\n\n\n\n\n\n\n\nChoose Blueprint\n\n\nAfter selecting a blueprint, you can optionally configure the following advanced parameters:\n\n\n\n\n\n\n\n\nParameter\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nConfig Recommendation Strategy (Stack Advisor)\n\n\nSelect how configuration recommendations generated by stack advisor will be applied. Select one of \nALWAYS_APPLY: Configuration recommendations will be applied automatically.\nALWAYS_APPLY_DONT_OVERRIDE_CUSTOM_VALUES: Configuration recommendations will be applied automatically, but they will be ignored for custom configurations.\nNEVER_APPLY: Configuration recommendations will be ignored.\nONLY_STACK_DEFAULTS_APPLY: Configuration recommendations will be applied only on the default configurations for all included services.\n\n\n\n\n\n\nValidate Blueprint\n\n\nSelect to validate the blueprint.\n\n\n\n\n\n\n\n\nChoose Failure Action\n\n\nYou can optionally select what to do if cluster creation fails or if there aren't enough instances available to create all requested nodes:\n\n\n\n\n\n\n\n\nParameter\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nFailure Action\n\n\nSelect one of: \ndo NOT rollback resources\n (default) or \nrollback resources\n. \nBy default, if creating a cluster fails, the Azure resources that were created up to that point will not be rolled back. This means that they will remain accessible for troubleshooting and you will need to to delete them manually.\n\n\n\n\n\n\nMinimum Cluster Size\n\n\nThis defines the provisioning strategy in case the cloud provider cannot allocate all the requested nodes. Select \nbest effort\n or \nexact\n.\n\n\n\n\n\n\n\n\nConfigure Ambari Repos\n\n\nYou can optionally configure a different version of Ambari than the default by providing the following information:\n\n\n\n\n\n\n\n\nParameter\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nAmbari Version\n\n\nEnter Ambari version.\n\n\n\n\n\n\nAmbari Repo URL\n\n\nEnter Ambari repo URL.\n\n\n\n\n\n\nAmbari Repo Gpg Key URL\n\n\nEnter gpgkey URL.\n\n\n\n\n\n\n\n\nConfigure HDP Repos\n\n\nYou can optionally configure a different version of HDP than the default by providing the following information:\n\n\n\n\n\n\n\n\nParameter\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nStack\n\n\nEnter stack name.\n\n\n\n\n\n\nVersion\n\n\nEnter stack version.\n\n\n\n\n\n\nStack Repo ID\n\n\nEnter stack repo ID.\n\n\n\n\n\n\nBase URL\n\n\nEner stack repo base URL.\n\n\n\n\n\n\nUtils Repo ID\n\n\nEnter Utils repo ID.\n\n\n\n\n\n\nUtils Base URL\n\n\nEnter Utils repo base URL.\n\n\n\n\n\n\nVerify\n\n\nSelect to verify the repo information.\n\n\n\n\n\n\n\n\nConfigure Ambari Database\n\n\nBy default, Ambari stores data on an embedded database, which is sufficient for ephemeral or test clusters. However, as Ambari and Cloudbreak don't perform backups of this database, it is insufficient for long-running production clusters, and you may need to configure a remote database for Ambari and Cloudbreak.\n\n\n\n\n\n\n\n\nParameter\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nVendor\n\n\nSelect database vendor from the list.\n\n\n\n\n\n\nHost\n\n\nEnter database host IP.\n\n\n\n\n\n\nPort\n\n\nEnter port number.\n\n\n\n\n\n\nName\n\n\nEnter database name.\n\n\n\n\n\n\nUser Name\n\n\nEnter database user name.\n\n\n\n\n\n\nPassword\n\n\nEnter database password.\n\n\n\n\n\n\n\n\n\n\nNext: Manage \n&\n Monitor Clusters", 
            "title": "Create a Cluster"
        }, 
        {
            "location": "/gcp-create/index.html#create-a-cluster-on-gcp", 
            "text": "To create a cluster via CLoudbreak UI:    Log in to the Cloudbreak UI.    In the top right corner, select the credential that you want to use to create a cluster:        Click  +create cluster  and the  Create cluster  form is displayed.    On the  Configure Cluster  page, provide the following parameters:   To view advanced options, click  Show Advanced Options . To learn about advanced options, refer to  Advanced Options .      Parameter  Description      Cluster Name  Enter a name for your cluster. The name must be between 5 and 40 characters, must start with a letter, must only include lowercase letters, numbers, and hyphens.    Tags  (Optional) You can optionally add tags, which will help you find your cluster-related resources, such as VMs, in your cloud provider account.    Region  Select the region in which you would like to launch your cluster.    Availability Zone  Select the availability zone in which you would like to launch your cluster.    Send Email When Cluster is Ready  (Optional) Check this to receive an email each time the cluster status changes.    Public In Account  (Optional) If this option is checked, all the users belonging to your account will be able to use this cluster, but they cannot delete it.      By default, Ambari Username and Ambari Password are set to  admin . You can override it in the \" Configure Cluster \" tab.     On the  Set up Network and Security  page, provide the following parameters:     Parameter  Description      Network  Select the virtual network in which you would like your cluster to be provisioned. You can define custom network configurations or use default network configurations.    Enable Knox Gateway  (Optional) Select this option to enable secure access to Ambari web UI and other cluster UIs via Knox gateway.    Enable Kerberos Security  (Optional) Select this option to enable Kerberos for your cluster. You will have an option to create a new kerberos or use an existing one. For more information refer to Kerberos  documentation .       On the  Choose Blueprint  page, select the blueprint that you would like to use for your cluster. You can either choose one of the pre-configured blueprints, or add your own in the  manage blueprints  tab.  For each host group you must provide the following:     Parameter  Description      Group Size  Enter a number defining how many nodes to create per host group. Default is 1. The \"Group Size\" for that host group on which Ambari Server is installed must be set to \"1\".    Template  If you have previously created a template for VMs and storage, you can select it here. If you don't make a selection, default will be used.    Security Group  If you have previously created a template for a security group, you can select it here. If you don't make a selection, default will be used.    Ambari Server  You must select one node for Ambari Server. The \"Group Size\" for that host group must be set to \"1\".    Recipes  You can select a previously added recipe (custom script) to be executed on all nodes of the host group. Refer to  Recipes .       On the  Add File System  page, select to use one of the following filesystems:   Local HDFS : No external storage outside of HDFS will be used   GCS file system : If you select to use Google Cloud Storage option, you must provide:     Parameter  Description      Project Id  The project ID registered when creating a credential should be pre-populated.    Service Account Email Address  The email address registered when creating a credential should be pre-populated.    Default Bucket Name  (Deprecated) The name of an existing Google Cloud Storage bucket. This is an optional and deprecated configuration parameter (mapped to \"fs.gs.system.bucket\" in core-site.xml) to set the GCS bucket as a default bucket for URIs without having to specify the \"gs:\" prefix.  For more information about the  GCS file system  and  bucket naming , refer to  GCP documentation.         Click on  Review and Launch  and then  +create and start cluster .    You will be redirected to the Cloudbreak dashboard, and a new tile representing your cluster will appear at the top of the page.", 
            "title": "Create a Cluster on GCP"
        }, 
        {
            "location": "/gcp-create/index.html#advanced-options", 
            "text": "Click on  Show Advanced Options  to enter additional configuration options.", 
            "title": "Advanced Options"
        }, 
        {
            "location": "/gcp-create/index.html#configure-cluster", 
            "text": "You can optionally configure the following advanced parameters:     Parameter  Description      Ambari Username  You can log in to the Ambari UI using this username. By default, this is set to  admin .    Ambari Password  You can log in to the Ambari UI using this password. By default, this is set to  admin .    Provision Cluster  SALT  is pre-selected to provision your cluster.    Enable Lifetime Management  Check this option if you would like your cluster to be automatically terminated after a specific amount of time (defined as \"Time to Live\" in minuter) has passed.    Flex Subscription  This option will appear if you have configured your deployment for a  Flex Subscription .", 
            "title": "Configure Cluster"
        }, 
        {
            "location": "/gcp-create/index.html#choose-blueprint", 
            "text": "After selecting a blueprint, you can optionally configure the following advanced parameters:     Parameter  Description      Config Recommendation Strategy (Stack Advisor)  Select how configuration recommendations generated by stack advisor will be applied. Select one of  ALWAYS_APPLY: Configuration recommendations will be applied automatically. ALWAYS_APPLY_DONT_OVERRIDE_CUSTOM_VALUES: Configuration recommendations will be applied automatically, but they will be ignored for custom configurations. NEVER_APPLY: Configuration recommendations will be ignored. ONLY_STACK_DEFAULTS_APPLY: Configuration recommendations will be applied only on the default configurations for all included services.    Validate Blueprint  Select to validate the blueprint.", 
            "title": "Choose Blueprint"
        }, 
        {
            "location": "/gcp-create/index.html#choose-failure-action", 
            "text": "You can optionally select what to do if cluster creation fails or if there aren't enough instances available to create all requested nodes:     Parameter  Description      Failure Action  Select one of:  do NOT rollback resources  (default) or  rollback resources .  By default, if creating a cluster fails, the Azure resources that were created up to that point will not be rolled back. This means that they will remain accessible for troubleshooting and you will need to to delete them manually.    Minimum Cluster Size  This defines the provisioning strategy in case the cloud provider cannot allocate all the requested nodes. Select  best effort  or  exact .", 
            "title": "Choose Failure Action"
        }, 
        {
            "location": "/gcp-create/index.html#configure-ambari-repos", 
            "text": "You can optionally configure a different version of Ambari than the default by providing the following information:     Parameter  Description      Ambari Version  Enter Ambari version.    Ambari Repo URL  Enter Ambari repo URL.    Ambari Repo Gpg Key URL  Enter gpgkey URL.", 
            "title": "Configure Ambari Repos"
        }, 
        {
            "location": "/gcp-create/index.html#configure-hdp-repos", 
            "text": "You can optionally configure a different version of HDP than the default by providing the following information:     Parameter  Description      Stack  Enter stack name.    Version  Enter stack version.    Stack Repo ID  Enter stack repo ID.    Base URL  Ener stack repo base URL.    Utils Repo ID  Enter Utils repo ID.    Utils Base URL  Enter Utils repo base URL.    Verify  Select to verify the repo information.", 
            "title": "Configure HDP Repos"
        }, 
        {
            "location": "/gcp-create/index.html#configure-ambari-database", 
            "text": "By default, Ambari stores data on an embedded database, which is sufficient for ephemeral or test clusters. However, as Ambari and Cloudbreak don't perform backups of this database, it is insufficient for long-running production clusters, and you may need to configure a remote database for Ambari and Cloudbreak.     Parameter  Description      Vendor  Select database vendor from the list.    Host  Enter database host IP.    Port  Enter port number.    Name  Enter database name.    User Name  Enter database user name.    Password  Enter database password.      Next: Manage  &  Monitor Clusters", 
            "title": "Configure Ambari Database"
        }, 
        {
            "location": "/gcp-cb-ui/index.html", 
            "text": "Manage and Monitor Clusters\n\n\nYou can manage monitor your clusters from the Cloudbreak UI. To do that, click on the title representing the cluster that you want to access: \n\n\n \n\n\nAccessing Links to Cluster Services\n\n\nYou can access links to cluster services from the \nServices\n tab.\n\n\nManaging Cluster Nodes\n\n\nYou can view details about your cluster nodes (for example, Public IP addresses) from the \nNodes\n tab. You can also delete nodes using the \nTERMINATE\n option.\n\n\nAccessing Event Log\n\n\nYou can access cluster event log from the \nEvent History\n tab.\n\n\nRepairing Your Cluster\n\n\nTo trigger repair process for your cluster, click \nrepair\n. Faulty nodes will be deleted from the cluster and new ones will be added in their place. \n\n\nTerminating Your Cluster\n\n\nTo terminate your cluster, click \nterminate\n. All cluster-related resources will be deleted, unless the network is used by other VMs, in which case it will not be deleted.", 
            "title": "Manage and Monitor Clusters"
        }, 
        {
            "location": "/gcp-cb-ui/index.html#manage-and-monitor-clusters", 
            "text": "You can manage monitor your clusters from the Cloudbreak UI. To do that, click on the title representing the cluster that you want to access:", 
            "title": "Manage and Monitor Clusters"
        }, 
        {
            "location": "/gcp-cb-ui/index.html#accessing-links-to-cluster-services", 
            "text": "You can access links to cluster services from the  Services  tab.", 
            "title": "Accessing Links to Cluster Services"
        }, 
        {
            "location": "/gcp-cb-ui/index.html#managing-cluster-nodes", 
            "text": "You can view details about your cluster nodes (for example, Public IP addresses) from the  Nodes  tab. You can also delete nodes using the  TERMINATE  option.", 
            "title": "Managing Cluster Nodes"
        }, 
        {
            "location": "/gcp-cb-ui/index.html#accessing-event-log", 
            "text": "You can access cluster event log from the  Event History  tab.", 
            "title": "Accessing Event Log"
        }, 
        {
            "location": "/gcp-cb-ui/index.html#repairing-your-cluster", 
            "text": "To trigger repair process for your cluster, click  repair . Faulty nodes will be deleted from the cluster and new ones will be added in their place.", 
            "title": "Repairing Your Cluster"
        }, 
        {
            "location": "/gcp-cb-ui/index.html#terminating-your-cluster", 
            "text": "To terminate your cluster, click  terminate . All cluster-related resources will be deleted, unless the network is used by other VMs, in which case it will not be deleted.", 
            "title": "Terminating Your Cluster"
        }, 
        {
            "location": "/os-launch/index.html", 
            "text": "Launch Cloudbreak on OpenStack\n\n\nMeet Minimum System Requirements\n\n\nBefore launching Cloudbreak on your OpenStack, make sure that your OpenStack deployment fulfills the following requirements.\n\n\nSupported Linux Distributions\n\n\nThe following versions of the \nRed Hat Distribution of OpenStack\n (RDO) are supported:\n\n\n\n\nJuno\n\n\nKilo\n\n\nLiberty\n\n\nMitaka\n\n\n\n\nStandard Modules\n\n\nCloudbreak requires that the following standard modules are installed and configured on OpenStack:\n\n\n\n\nKeystone V2 or Keystone V3  \n\n\nNeutron (Self-service and provider networking)  \n\n\nNova (KVM or Xen hypervisor)  \n\n\nGlance  \n\n\nCinder (Optional)  \n\n\nHeat (Optional but highly recommended, since provisioning through native API calls will be deprecated in the future)  \n\n\n\n\nMeet the Prerequisites\n\n\nBefore launching Cloudbreak on OpenStack, you must meet the following prerequisites.\n\n\nSSH Key Pair\n\n\nCreate a new SSH key pair or import an existing SSH key pair. \n\n\nSecurity Group\n\n\nIn order to launch Cloudbreak, you must have an existing security group with the following ports open: 22 (SSH) and 443 (HTTPS). \n\n\nFor information about OpenStack security groups, refer to the \nOpenStack Operations Guide\n.\n\n\nImport Images to OpenStack\n\n\nAn OpenStack administrator must perform these steps to add the Cloudbreak deployer and HDP images to your OpenStack deployment.\n\n\nImport Cloudbreak Deployer Image\n\n\n\n\n\n\nDownload the latest Cloudbreak deployer image to your local machine: \n\n\ncurl -O https://public-repo-1.hortonworks.com/HDP/cloudbreak/cloudbreak-deployer-1161-2017-06-15.img\n\n\n\n\n\n\nSet the following environment variables for the OpenStack image import: \n\n\nexport CBD_LATEST_IMAGE=cloudbreak-deployer-1161-2017-06-15.img\nexport OS_IMAGE_NAME=cloudbreak-deployer-1161-2017-06-15.img\nexport OS_USERNAME=your_os_user_name\nexport OS_AUTH_URL=your_authentication_url\nexport OS_TENANT_NAME=your_os_tenant_name\n\n\n\n\n\n\nImport the new image into your OpenStack:\n\n\nglance image-create --name \"$OS_IMAGE_NAME\" --file \"$CBD_LATEST_IMAGE\" --disk-format qcow2 --container-format bare --progress\n \n\n\n\n\n\n\nAfter performing the import, you should be able to see the Cloudbreak deployer image among your other OpenStack images. \n\n\n\n\n\n\n\n\n\n\nTO-DO: Some of this content was automatically generated. \n\n\n\n\n\n\n\n\n\n\nImport HDP Image\n\n\n\n\n\n\nDownload the latest HDP image to your local machine: \n\n\ncurl -O https://public-repo-1.hortonworks.com/HDP/cloudbreak/hdc-hdp--1705081316.img\n\n\n\n\n\n\n\nSet the following environment variables for the OpenStack image import: \n\n\nexport CB_LATEST_IMAGE=hdc-hdp--1705081316.img\nexport CB_LATEST_IMAGE_NAME=hdc-hdp--1705081316.img\nexport OS_USERNAME=your_os_user_name\nexport OS_AUTH_URL=your_authentication_url\nexport OS_TENANT_NAME=your_os_tenant_name\n\n\n\n\n\n\nImport the new image into your OpenStack:\n\n\nglance image-create --name \"$CB_LATEST_IMAGE_NAME\" --file \"$CB_LATEST_IMAGE\" --disk-format qcow2 --container-format bare --progress\n\n\n\n\n\n\nAfter performing the import, you should be able to see the Cloudbreak image among your OpenStack images. \n\n\n\n\n\n\n\n\n\n\nTO-DO: Some of this content was automatically generated.  \n\n\n\n\n\n\n\n\n\n\nLaunch the VM\n\n\nIn your OpenStack, launch and instance providing the following parameters:\n\n\n\n\nSelect a VM flavor which meets the following minimum requirements: 4GB RAM, 10GB disk, 2 cores.  \n\n\nSelect the Cloudbreak deployer image that you imported earlier and launch an instance using that image. \n\n\nSelect your SSH key pair.  \n\n\nSelect the security group which has the following ports open: 22 (SSH) and 443 (HTTPS). \n\n\nSelect your preconfigured network.  \n\n\n\n\nSSH to the VM\n\n\nNow that your VM is ready, access it via SSH: \n\n\n\n\nUse a private key matching the public key that you added to your OpenStack project.\n\n\nThe SSH user is called \"cloudbreak\".\n\n\nYou can obtain the VM's IP address from the details of your instance.\n\n\n\n\nInitialize Your Profile\n\n\nAfter accessing the VM via SSH: \n\n\n\n\n\n\nNavigate to the cloudbreak-deployment directory:\n\n\ncd /var/lib/cloudbreak-deployment/\n\n\nThis directory contains configuration files and the supporting binaries for Cloudbreak deployer.\n\n\n\n\n\n\nInitialize your profile by creating a new file called \nProfile\n and adding the following content:\n\n\nexport UAA_DEFAULT_SECRET=MY-SECRET\nexport UAA_DEFAULT_USER_PW=MY-PASSWORD\nexport PUBLIC_IP=VM-PUBLIC-IP\n  \n\n\nFor example: \n\n\nexport UAA_DEFAULT_SECRET=MySecret123\nexport UAA_DEFAULT_USER_PW=MySecurePassword123\nexport PUBLIC_IP=34.212.141.253\n \n\n\n\n\nYou will need to provide the password when logging in to the Cloudbreak web UI and when using the Cloudbreak Shell. The secret will be used by Cloudbreak for authentication.  \n\n\n\n\n\n\n\n\nPerform Optional Configurations\n\n\n\n\nThese configurations are optional. \n\n\n\n\nConfiguring a Self-Signed Certificate\n\n\nIf your OpenStack is secured with a self-signed certificate, you need to import that certificate into Cloudbreak, or else Cloudbreak won't be able to communicate with your OpenStack. \n\n\nTo import the certificate, place the certificate file in the \n/certs/trusted/\n directory:\n\n\n\n\nNavigate to the \ncerts\n directory (automatically generated).\n\n\nCreate the \ntrusted\n directory.\n\n\nCopy the certificate to the \ntrusted\n directory. \n\n\n\n\nCloudbreak will automatically pick up the certificate and import it into its truststore upon start.\n\n\nConfiguring Availability Zone and Region\n\n\nBy default, Cloudbreak uses \nRegionOne\n region with \nnova\n availability zone, but you can customize Cloudbreak deployment and enable multiple regions and availability zones by creating an \nopenstack-zone.json\n file in the \netc\n directory of Cloudbreak deployment (that is\n/var/lib/cloudbreak-deployment/etc/openstack-zone.json\n). If the etc directory does not exist in the Cloudbreak deployment directory, then create it. \n\n\nThe following is an example of \nopenstack-zone.json\n containing two regions and four availability zones:\n\n\n{\n  \"items\": [\n    {\n      \"name\": \"MyRegionOne\",\n      \"zones\": [ \"az1\", \"az2\", \"az3\"]\n    },\n    {\n      \"name\": \"MyRegionTwo\",\n      \"zones\": [ \"myaz\"]\n    }\n  ]\n}\n\n\n\n\n\n\nIf you are performing this after you have started cbd, perform \ncbd restart\n.  \n\n\n\n\nLaunch Cloudbreak Deployer\n\n\n\n\n\n\nStart the Cloudbreak application by using the following command:\n\n\ncbd start\n\n\nThis will start the Docker containers and initialize the application. The first time you start the Coudbreak app, the process will take longer than usual due to the download of all the necessary docker images.\n\n\nThe \ncbd start\n command includes the \ncbd generate\n command which applies the following steps:\n\n\n\n\nCreates the \ndocker-compose.yml\n file, which describes the configuration of all the Docker containers needed for the Cloudbreak deployment.\n\n\nCreates the \nuaa.yml\n file, which holds the configuration of the identity server used to authenticate users with Cloudbreak.\n\n\n\n\n\n\nOnce the \ncbd start\n has finished, it returns the \"Uluwatu (Cloudbreak UI) url\" which you can later paste in your browser and log in to Cloudbreak web UI.\n\n\n\n\n\n\n\n\nCheck Cloudbreak deployer version and health: \n\n\ncbd doctor\n\n\n\n\n\n\nNext, check Cloudbreak Application logs: \n\n\ncbd logs cloudbreak\n\n\nYou should see a message like this in the log: \nStarted CloudbreakApplication in 36.823 seconds.\n Cloudbreak normally takes less than a minute to start.\n\n\n\n\n\n\nAccess Cloudbreak UI\n\n\n\n\n\n\nYou can log into the Cloudbreak application at \nhttps://IP_Address\n where \"IP_Address\" if the public IP of your OpenStack VM. For example \nhttps://34.212.141.253\n.\n\n\n\n\n\n\nConfirm the security exception to proceed to the Cloudbreak web UI.\n\n\nThe first time you access Cloudbreak UI, Cloudbreak will automatically generate a self-signed certificate, due to which your browser will warn you about an untrusted connection and will ask you to confirm a security exception.\n\n\n\n\n\n\nLog in to the Cloudbreak web UI:\n\n\n\n\nThe default username is \nadmin@example.com\n but you should sign up with your own email address.\n\n\nThe password is the value of the \nUAA_DEFAULT_USER_PW\n variable that you configured in your \nProfile\n file when \nlaunching Cloudbreak deployer\n.\n\n\n\n\n  \n\n\n\n\n\n\nCreate Cloudbreak Credential\n\n\nCloudbreak works by connecting your OpenStack account through this credential, and then uses it to create resources on your behalf. Before you can start provisioning cluster using Cloudbreak, you must create a Cloudbreak credential.\n\n\n\n\n\n\nIn the Cloudbreak web UI, open the \nmanage credentials\n pane. \n\n\n\n\n\n\nClick \n+create credential\n. \n\n\n\n\n\n\nProvide the following information:\n\n\n\n\n\n\n\n\nParameter\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nKeystone Version\n\n\nSelect the keystone version.\n\n\n\n\n\n\nName\n\n\nEnter a name for your credential.\n\n\n\n\n\n\nDescription\n\n\n(Optional) Enter a description.\n\n\n\n\n\n\nUser\n\n\nEnter your OpenStack user name.\n\n\n\n\n\n\nPassword\n\n\nEnter your OpenStack password.\n\n\n\n\n\n\nTenant Name\n\n\nEnter the OpenStack tenant name.\n\n\n\n\n\n\nEndpoint\n\n\nEnter the OpenStack endpoint.\n\n\n\n\n\n\nAPI Facing\n\n\nSelect \npublic\n or \nprivate\n.\n\n\n\n\n\n\nSSH Public Key\n\n\nPaste your SSH public key.\n\n\n\n\n\n\nSelect Platform\n\n\n(Optional) Select a platform (if previously configured).\n\n\n\n\n\n\nPublic In Account\n\n\n(Optional) If you check this, other users added to your Cloudbreak instance will be able to use this credential to create clusters.\n\n\n\n\n\n\n\n\n\n\n\n\nClick \n+create credential\n.\n\n\n\n\n\n\nYour credential should now be displayed at the top of the page and in the \nmanage credentials\n tab.\n\n\nCongratulations! You've successfully launched and configured Cloudbreak. Now you can use Cloudbreak to \ncreate clusters\n. \n\n\n\n\n\n\n\n\nNext: Define Infrastructure Templates", 
            "title": "Launch on Open Stack"
        }, 
        {
            "location": "/os-launch/index.html#launch-cloudbreak-on-openstack", 
            "text": "", 
            "title": "Launch Cloudbreak on OpenStack"
        }, 
        {
            "location": "/os-launch/index.html#meet-minimum-system-requirements", 
            "text": "Before launching Cloudbreak on your OpenStack, make sure that your OpenStack deployment fulfills the following requirements.", 
            "title": "Meet Minimum System Requirements"
        }, 
        {
            "location": "/os-launch/index.html#supported-linux-distributions", 
            "text": "The following versions of the  Red Hat Distribution of OpenStack  (RDO) are supported:   Juno  Kilo  Liberty  Mitaka", 
            "title": "Supported Linux Distributions"
        }, 
        {
            "location": "/os-launch/index.html#standard-modules", 
            "text": "Cloudbreak requires that the following standard modules are installed and configured on OpenStack:   Keystone V2 or Keystone V3    Neutron (Self-service and provider networking)    Nova (KVM or Xen hypervisor)    Glance    Cinder (Optional)    Heat (Optional but highly recommended, since provisioning through native API calls will be deprecated in the future)", 
            "title": "Standard Modules"
        }, 
        {
            "location": "/os-launch/index.html#meet-the-prerequisites", 
            "text": "Before launching Cloudbreak on OpenStack, you must meet the following prerequisites.", 
            "title": "Meet the Prerequisites"
        }, 
        {
            "location": "/os-launch/index.html#ssh-key-pair", 
            "text": "Create a new SSH key pair or import an existing SSH key pair.", 
            "title": "SSH Key Pair"
        }, 
        {
            "location": "/os-launch/index.html#security-group", 
            "text": "In order to launch Cloudbreak, you must have an existing security group with the following ports open: 22 (SSH) and 443 (HTTPS).   For information about OpenStack security groups, refer to the  OpenStack Operations Guide .", 
            "title": "Security Group"
        }, 
        {
            "location": "/os-launch/index.html#import-images-to-openstack", 
            "text": "An OpenStack administrator must perform these steps to add the Cloudbreak deployer and HDP images to your OpenStack deployment.", 
            "title": "Import Images to OpenStack"
        }, 
        {
            "location": "/os-launch/index.html#import-cloudbreak-deployer-image", 
            "text": "Download the latest Cloudbreak deployer image to your local machine:   curl -O https://public-repo-1.hortonworks.com/HDP/cloudbreak/cloudbreak-deployer-1161-2017-06-15.img    Set the following environment variables for the OpenStack image import:   export CBD_LATEST_IMAGE=cloudbreak-deployer-1161-2017-06-15.img\nexport OS_IMAGE_NAME=cloudbreak-deployer-1161-2017-06-15.img\nexport OS_USERNAME=your_os_user_name\nexport OS_AUTH_URL=your_authentication_url\nexport OS_TENANT_NAME=your_os_tenant_name    Import the new image into your OpenStack:  glance image-create --name \"$OS_IMAGE_NAME\" --file \"$CBD_LATEST_IMAGE\" --disk-format qcow2 --container-format bare --progress      After performing the import, you should be able to see the Cloudbreak deployer image among your other OpenStack images.       TO-DO: Some of this content was automatically generated.", 
            "title": "Import Cloudbreak Deployer Image"
        }, 
        {
            "location": "/os-launch/index.html#import-hdp-image", 
            "text": "Download the latest HDP image to your local machine:   curl -O https://public-repo-1.hortonworks.com/HDP/cloudbreak/hdc-hdp--1705081316.img    Set the following environment variables for the OpenStack image import:   export CB_LATEST_IMAGE=hdc-hdp--1705081316.img\nexport CB_LATEST_IMAGE_NAME=hdc-hdp--1705081316.img\nexport OS_USERNAME=your_os_user_name\nexport OS_AUTH_URL=your_authentication_url\nexport OS_TENANT_NAME=your_os_tenant_name    Import the new image into your OpenStack:  glance image-create --name \"$CB_LATEST_IMAGE_NAME\" --file \"$CB_LATEST_IMAGE\" --disk-format qcow2 --container-format bare --progress    After performing the import, you should be able to see the Cloudbreak image among your OpenStack images.       TO-DO: Some of this content was automatically generated.", 
            "title": "Import HDP Image"
        }, 
        {
            "location": "/os-launch/index.html#launch-the-vm", 
            "text": "In your OpenStack, launch and instance providing the following parameters:   Select a VM flavor which meets the following minimum requirements: 4GB RAM, 10GB disk, 2 cores.    Select the Cloudbreak deployer image that you imported earlier and launch an instance using that image.   Select your SSH key pair.    Select the security group which has the following ports open: 22 (SSH) and 443 (HTTPS).   Select your preconfigured network.", 
            "title": "Launch the VM"
        }, 
        {
            "location": "/os-launch/index.html#ssh-to-the-vm", 
            "text": "Now that your VM is ready, access it via SSH:    Use a private key matching the public key that you added to your OpenStack project.  The SSH user is called \"cloudbreak\".  You can obtain the VM's IP address from the details of your instance.", 
            "title": "SSH to the VM"
        }, 
        {
            "location": "/os-launch/index.html#initialize-your-profile", 
            "text": "After accessing the VM via SSH:     Navigate to the cloudbreak-deployment directory:  cd /var/lib/cloudbreak-deployment/  This directory contains configuration files and the supporting binaries for Cloudbreak deployer.    Initialize your profile by creating a new file called  Profile  and adding the following content:  export UAA_DEFAULT_SECRET=MY-SECRET\nexport UAA_DEFAULT_USER_PW=MY-PASSWORD\nexport PUBLIC_IP=VM-PUBLIC-IP     For example:   export UAA_DEFAULT_SECRET=MySecret123\nexport UAA_DEFAULT_USER_PW=MySecurePassword123\nexport PUBLIC_IP=34.212.141.253     You will need to provide the password when logging in to the Cloudbreak web UI and when using the Cloudbreak Shell. The secret will be used by Cloudbreak for authentication.", 
            "title": "Initialize Your Profile"
        }, 
        {
            "location": "/os-launch/index.html#perform-optional-configurations", 
            "text": "These configurations are optional.", 
            "title": "Perform Optional Configurations"
        }, 
        {
            "location": "/os-launch/index.html#configuring-a-self-signed-certificate", 
            "text": "If your OpenStack is secured with a self-signed certificate, you need to import that certificate into Cloudbreak, or else Cloudbreak won't be able to communicate with your OpenStack.   To import the certificate, place the certificate file in the  /certs/trusted/  directory:   Navigate to the  certs  directory (automatically generated).  Create the  trusted  directory.  Copy the certificate to the  trusted  directory.    Cloudbreak will automatically pick up the certificate and import it into its truststore upon start.", 
            "title": "Configuring a Self-Signed Certificate"
        }, 
        {
            "location": "/os-launch/index.html#configuring-availability-zone-and-region", 
            "text": "By default, Cloudbreak uses  RegionOne  region with  nova  availability zone, but you can customize Cloudbreak deployment and enable multiple regions and availability zones by creating an  openstack-zone.json  file in the  etc  directory of Cloudbreak deployment (that is /var/lib/cloudbreak-deployment/etc/openstack-zone.json ). If the etc directory does not exist in the Cloudbreak deployment directory, then create it.   The following is an example of  openstack-zone.json  containing two regions and four availability zones:  {\n  \"items\": [\n    {\n      \"name\": \"MyRegionOne\",\n      \"zones\": [ \"az1\", \"az2\", \"az3\"]\n    },\n    {\n      \"name\": \"MyRegionTwo\",\n      \"zones\": [ \"myaz\"]\n    }\n  ]\n}   If you are performing this after you have started cbd, perform  cbd restart .", 
            "title": "Configuring Availability Zone and Region"
        }, 
        {
            "location": "/os-launch/index.html#launch-cloudbreak-deployer", 
            "text": "Start the Cloudbreak application by using the following command:  cbd start  This will start the Docker containers and initialize the application. The first time you start the Coudbreak app, the process will take longer than usual due to the download of all the necessary docker images.  The  cbd start  command includes the  cbd generate  command which applies the following steps:   Creates the  docker-compose.yml  file, which describes the configuration of all the Docker containers needed for the Cloudbreak deployment.  Creates the  uaa.yml  file, which holds the configuration of the identity server used to authenticate users with Cloudbreak.    Once the  cbd start  has finished, it returns the \"Uluwatu (Cloudbreak UI) url\" which you can later paste in your browser and log in to Cloudbreak web UI.     Check Cloudbreak deployer version and health:   cbd doctor    Next, check Cloudbreak Application logs:   cbd logs cloudbreak  You should see a message like this in the log:  Started CloudbreakApplication in 36.823 seconds.  Cloudbreak normally takes less than a minute to start.", 
            "title": "Launch Cloudbreak Deployer"
        }, 
        {
            "location": "/os-launch/index.html#access-cloudbreak-ui", 
            "text": "You can log into the Cloudbreak application at  https://IP_Address  where \"IP_Address\" if the public IP of your OpenStack VM. For example  https://34.212.141.253 .    Confirm the security exception to proceed to the Cloudbreak web UI.  The first time you access Cloudbreak UI, Cloudbreak will automatically generate a self-signed certificate, due to which your browser will warn you about an untrusted connection and will ask you to confirm a security exception.    Log in to the Cloudbreak web UI:   The default username is  admin@example.com  but you should sign up with your own email address.  The password is the value of the  UAA_DEFAULT_USER_PW  variable that you configured in your  Profile  file when  launching Cloudbreak deployer .", 
            "title": "Access Cloudbreak UI"
        }, 
        {
            "location": "/os-launch/index.html#create-cloudbreak-credential", 
            "text": "Cloudbreak works by connecting your OpenStack account through this credential, and then uses it to create resources on your behalf. Before you can start provisioning cluster using Cloudbreak, you must create a Cloudbreak credential.    In the Cloudbreak web UI, open the  manage credentials  pane.     Click  +create credential .     Provide the following information:     Parameter  Description      Keystone Version  Select the keystone version.    Name  Enter a name for your credential.    Description  (Optional) Enter a description.    User  Enter your OpenStack user name.    Password  Enter your OpenStack password.    Tenant Name  Enter the OpenStack tenant name.    Endpoint  Enter the OpenStack endpoint.    API Facing  Select  public  or  private .    SSH Public Key  Paste your SSH public key.    Select Platform  (Optional) Select a platform (if previously configured).    Public In Account  (Optional) If you check this, other users added to your Cloudbreak instance will be able to use this credential to create clusters.       Click  +create credential .    Your credential should now be displayed at the top of the page and in the  manage credentials  tab.  Congratulations! You've successfully launched and configured Cloudbreak. Now you can use Cloudbreak to  create clusters .      Next: Define Infrastructure Templates", 
            "title": "Create Cloudbreak Credential"
        }, 
        {
            "location": "/os-config/index.html", 
            "text": "Define Infrastructure Templates\n\n\nAfter you've logged in to Cloudbreak and created a Cloudbreak credential, you must define infrastructure templates for certain cluster resources.  \n\n\nThe \ninfrastructure templates\n for resources such as \nnetworks\n, \nsecurity groups\n, and \nVMs and storage\n are saved to Cloudbreak's database and can be reused with multiple clusters to describe the infrastructure. When you add these resources in Cloudbreak web UI, Cloudbreak does not make any requests to your cloud provider account. Resources are only created on your cloud provider account after the create cluster button has been pushed. \n\n\nThis is illustrated and further explained in the \nArchitecture\n documentation.\n\n\nYou can add infrastructure templates after expanding their corresponding panes in the Cloudbreak web UI (shown in the screenshot) as described in the documentation below.  \n\n\n \n\n\nThe following table describes the basic configurations for which you must create custom tempalates:\n\n\n\n\n\n\n\n\nConfiguration\n\n\nDescription\n\n\nCreate Cluster\n\n\nPreconfigured\n\n\n\n\n\n\n\n\n\n\nNetworks\n\n\n(Required) Virtual networks provide the networking infrastructure (network, subnet, Internet gateway, and so on) in which your clusters run. You can create new virtual networks or reuse existing virtual networks for your clusters.\n\n\nYou can select the network configuration for your clusters in the \nCreate Cluster\n wizard \n \nSet up Network and Security\n page.\n\n\nNo\n\n\n\n\n\n\nSecurity Groups\n\n\n(Required) Security groups include rules which define inbound traffic allowed to the instances in your cluster. You can define different security group configurations for different nodes of your cluster.\n\n\nYou can select the security group configurations for each host group in the \nCreate Cluster\n wizard \n \nChoose Blueprint\n page. If no custom security groups are selected, default is used.\n\n\nYes\n\n\n\n\n\n\nVMs and Storage\n\n\n(Required) \"Templates\" define the infrastructure for your clusters: the instances on which your clusters run and their attached storage type, size, and count. You can reuse the same template for different cluster host groups or create different templates for different host groups.\n\n\nYou can select infrastructure templates for each host group in the \nCreate Cluster\n wizard \n \nChoose Blueprint\n page.\n\n\nNo\n\n\n\n\n\n\n\n\nThe \"Preconfigured\" column indicates whether a default template is available, indicating that templates are available for security groups and blueprints. \n\n\nNetworks\n\n\nBefore you can start using Cloubreak, you must define at least one custom network that can be used for cluster instances.\n\n\nAn instance uses a public provider virtual network that connects to the physical network infrastructure. This network includes a DHCP server that provides IP addresses to instances. The admin or other privileged user must create this network because it connects directly to the physical network infrastructure. Learn more about OpenStack \nvirtual network\n and \npublic provider network\n.\n\n\nYour clusters can be created in new networks or in one of your existing networks. If you choose an existing network, it is possible to create a new subnet within the network. \n\n\nAdd New Network and Subnet\n\n\nYou can define reusable network configurations for your clusters in the \nmanage networks\n tab:\n\n\n\n\n\n\nClick on \nCreate a new virtual network and a new subnet\n.\n\n\n\n\n\n\nProvide required parameters:\n\n\n\n\n\n\n\n\nParameter\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nName\n\n\nEnter a name for your configuration.\n\n\n\n\n\n\nDescription\n\n\n(Optional) Enter a description.\n\n\n\n\n\n\nSubnet (CIDR)\n\n\nEnter a valid \nCIDR\n for a new subnet that will be created within the VPC. For example \n10.0.0.0/24\n. This defines the IP address space usable by your VMs within the cluster. Cloudbreak supports the private address space defined in \nRFC1918\n.\n\n\n\n\n\n\nFloating Pool ID\n\n\nFloating IPs are not automatically allocated to instances by default, they needs to be attached to instances after creation. The Floating IPs are used to provide access to your VMs running on OpenStack. You can figure out the available network pools and their IDs by using the nova floating-ip-pool-list and neutron net-external-list or copy-pasting it from OpenStack Horizon UI. Such networks have the External Network field set to Yes. If you are unable to find the ID then just consult with your OpenStack network administrator. Please note that if you do not set this field then your cluster might not be accessible.\n\n\n\n\n\n\nPublic In Account\n\n\n(Optional) If this option is checked, all the users belonging to your account will be able to use this network template to create clusters, but they cannot delete it.\n\n\n\n\n\n\nSelect Platform\n\n\n(Optional) Select a previously created platform.\n\n\n\n\n\n\n\n\n\n\n\n\nClick on \n+create network\n.\n\n\nNo resources will be created until you create a cluster using this configuration.\n\n\n\n\n\n\nAdd New Subnet in an Existing Network\n\n\nYou can define reusable network configurations for your clusters in the \nmanage networks\n tab:\n\n\n\n\n\n\nClick on \nCreate a new subnet in an existing virtual network\n.\n\n\n\n\n\n\nProvide required parameters:\n\n\n\n\nMake sure that the new subnet defined here doesn't overlap with any of your already deployed subnets in the network. \n\n\n\n\n\n\n\n\n\n\nParameter\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nName\n\n\nEnter a name for your configuration.\n\n\n\n\n\n\nDescription\n\n\n(Optional) Enter a description.\n\n\n\n\n\n\nSubnet (CIDR)\n\n\nEnter a valid \nCIDR\n for a new subnet that will be created within the VPC. For example \n10.0.0.0/24\n.\n\n\n\n\n\n\nFloating Pool ID\n\n\nFloating IPs are not automatically allocated to instances by default, they needs to be attached to instances after creation. The Floating IPs are used to provide access to your VMs running on OpenStack. You can figure out the available network pools and their IDs by using the nova floating-ip-pool-list and neutron net-external-list or copy-pasting it from OpenStack Horizon UI. Such networks have the External Network field set to Yes. If you are unable to find the ID then just consult with your OpenStack network administrator. Please note that if you do not set this field then your cluster might not be accessible.\n\n\n\n\n\n\nVirtual Network Identifier\n\n\nThis is the ID of an existing virtual network on OpenStack where you would like to launch the cluster.\n\n\n\n\n\n\nRouter Identifier\n\n\nSpecify the router ID that shall interconnect your existing Network with the Subnet which will be created by CLoudbreak.\n\n\n\n\n\n\nPublic In Account\n\n\n(Optional) If this option is checked, all the users belonging to your account will be able to use this network template to create clusters, but they cannot delete it.\n\n\n\n\n\n\nSelect Platform\n\n\n(Optional) Select a previously created platform.\n\n\n\n\n\n\n\n\n\n\n\n\nClick on \n+create network\n.\n\n\nNo resources will be created until you create a cluster using this configuration.\n\n\n\n\n\n\nUse Existing Network and Subnet\n\n\nYou can define reusable network configurations for your clusters in the \nmanage networks\n tab:\n\n\n\n\n\n\nClick on \nUse an existing subnet in an existing virtual network\n. \n\n\n\n\n\n\nProvide required parameters: \n\n\n\n\n\n\n\n\nParameter\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nName\n\n\nEnter a name for your configuration.\n\n\n\n\n\n\nDescription\n\n\n(Optional) Enter a description.\n\n\n\n\n\n\nFloating Pool ID\n\n\nFloating IPs are not automatically allocated to instances by default, they needs to be attached to instances after creation. The Floating IPs are used to provide access to your VMs running on OpenStack. You can figure out the available network pools and their IDs by using the nova floating-ip-pool-list and neutron net-external-list or copy-pasting it from OpenStack Horizon UI. Such networks have the External Network field set to Yes. If you are unable to find the ID then just consult with your OpenStack network administrator. Please note that if you do not set this field then your cluster might not be accessible.\n\n\n\n\n\n\nVirtual Network Identifier\n\n\nThis is the ID of an existing virtual network on OpenStack where you would like to launch the cluster.\n\n\n\n\n\n\nSubnet Identifier\n\n\nThis is the ID of an existing subnet on OpenStack where you would like to launch the cluster.\n\n\n\n\n\n\nNetworking Option\n\n\n\n\n\n\n\n\nPublic In Account\n\n\n(Optional) If this option is checked, all the users belonging to your account will be able to use this network template to create clusters, but they cannot delete it.\n\n\n\n\n\n\nSelect Platform\n\n\n(Optional) Select a previously created platform.\n\n\n\n\n\n\n\n\n\n\nWhen using an existing subnet, make sure that you have enough room within your network space for the new instances. The provided subnet CIDR will be ignored, but a proper CIDR range will be used.\n\n\n\n\n\n\n\n\nClick on \n+create network\n.\n\n\nNo resources will be created until you create a cluster using this configuration.\n\n\n\n\n\n\nSecurity Groups\n\n\nYou have two options:\n\n\n\n\nUse the default security group configuration\n: This requires no further action.  \n\n\nAdd your own custom security group configuration\n: You can define your own security group by adding the ports, protocols, and CIDR ranges that you'd like to use. The rules defined here don't need to contain the internal rules (these are automatically added by Cloudbreak to the security group on OpenStack). \n\n\n\n\nDefault Security Group\n\n\nCloudbreak includes one pre-defined security group configuration called \ndefault-openstack-only-ssh-and-ssl\n, which is used by default when creating a cluster. You can see it in the \nmanage security groups\n tab. The configuration is: \n\n\n\n\n\n\n\n\nCIDR\n\n\nPort\n\n\nProtocol\n\n\n\n\n\n\n\n\n\n\n0.0.0.0/0\n\n\n22\n\n\ntcp\n\n\n\n\n\n\n0.0.0.0/0\n\n\n433\n\n\ntcp\n\n\n\n\n\n\n0.0.0.0/0\n\n\n9443\n\n\ntcp\n\n\n\n\n\n\n\n\nNo resources will be created until you create a cluster using this configuration.\n\n\nAdd Custom Security Group\n\n\nYou can define reusable security group configurations for your clusters in the \nmanage security groups\n tab: \n\n\n\n\nClick on \nCreate a new security group\n.\n\n\n\n\nProvide required parameters:\n\n\n\n\n\n\n\n\nParameter\n\n\nValue\n\n\n\n\n\n\n\n\n\n\nName\n\n\nEnter a name for your security group configuration template.\n\n\n\n\n\n\nDescription\n\n\n(Optional) Enter a description.\n\n\n\n\n\n\nPublic In Account\n\n\n(Optional) If this option is checked, all the users belonging to your account will be able to use this security group template to create clusters, but they cannot delete it.\n\n\n\n\n\n\n\n\n\n\n\n\nProvide the following parameters in order to define \nSecurity Rules\n for this security group:\n\n\n\n\n\n\n\n\nParameter\n\n\nValue\n\n\n\n\n\n\n\n\n\n\nCIDR\n\n\nEnter a valid \nCIDR IP\n, from which the cluster will be accessed.\n\n\n\n\n\n\nPort\n\n\nEnter ports that you want to open. You can either list multiple ports, separated by a comma (for example \"22,443,9443\"), or you can define port ranges (for example \"1-65355\").\n\n\n\n\n\n\nProtocol\n\n\nEnter protocol that you want to use.\n\n\n\n\n\n\n\n\n\n\nPorts 22, 443, and 9443 must be open on every security group; otherwise Cloudbreak will not be able to communicate with your provisioned cluster.\n\n\n\n\n\n\n\n\nClick \n+Add Rule\n to save the security rules. If needed, click \n+Add Rule\n again to display a new \nSecurity Rules\n form and add another set of rules. \n\n\n\n\n\n\nClick \n+create security group\n to save the configuration. \n\n\nNo resources will be created until you create a cluster using this configuration.\n\n\n\n\n\n\nVMs and Storage\n\n\nBefore you can start using CLoubreak, you must define at least one custom template defining the OpenStack infrastructure that will be used for cluster nodes and storage.  \n\n\nAdd Custom Template\n\n\nYou can define reusable cluster templates in the \nmanage templates\n tab: \n\n\n\n\n\n\nClick on \n+create template\n.\n\n\n\n\n\n\nProvide required parameters: \n\n\n\n\n\n\n\n\nParameter\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nInstance Type\n\n\nSelect an instance type. The instance types available depend on your OpenStack implementation.\n\n\n\n\n\n\nAttached Volumes Per Instance\n\n\n\n\n\n\n\n\nVolume Size (GB)\n\n\n10\n\n\n\n\n\n\nPublic In Account\n\n\n(Optional) If this option is checked, all the users belonging to your account will be able to use this template to create clusters, but they cannot delete it.\n\n\n\n\n\n\nSelect Platform\n\n\n(Optional) Select a previously created platform.\n\n\n\n\n\n\n\n\n\n\n\n\nClick on \n+create template\n.\n\n\nNo resources will be created until you create a cluster using this configuration.\n\n\n\n\n\n\n\n\nNext: Create a Cluster", 
            "title": "Define Infrastructure Templates"
        }, 
        {
            "location": "/os-config/index.html#define-infrastructure-templates", 
            "text": "After you've logged in to Cloudbreak and created a Cloudbreak credential, you must define infrastructure templates for certain cluster resources.    The  infrastructure templates  for resources such as  networks ,  security groups , and  VMs and storage  are saved to Cloudbreak's database and can be reused with multiple clusters to describe the infrastructure. When you add these resources in Cloudbreak web UI, Cloudbreak does not make any requests to your cloud provider account. Resources are only created on your cloud provider account after the create cluster button has been pushed.   This is illustrated and further explained in the  Architecture  documentation.  You can add infrastructure templates after expanding their corresponding panes in the Cloudbreak web UI (shown in the screenshot) as described in the documentation below.       The following table describes the basic configurations for which you must create custom tempalates:     Configuration  Description  Create Cluster  Preconfigured      Networks  (Required) Virtual networks provide the networking infrastructure (network, subnet, Internet gateway, and so on) in which your clusters run. You can create new virtual networks or reuse existing virtual networks for your clusters.  You can select the network configuration for your clusters in the  Create Cluster  wizard    Set up Network and Security  page.  No    Security Groups  (Required) Security groups include rules which define inbound traffic allowed to the instances in your cluster. You can define different security group configurations for different nodes of your cluster.  You can select the security group configurations for each host group in the  Create Cluster  wizard    Choose Blueprint  page. If no custom security groups are selected, default is used.  Yes    VMs and Storage  (Required) \"Templates\" define the infrastructure for your clusters: the instances on which your clusters run and their attached storage type, size, and count. You can reuse the same template for different cluster host groups or create different templates for different host groups.  You can select infrastructure templates for each host group in the  Create Cluster  wizard    Choose Blueprint  page.  No     The \"Preconfigured\" column indicates whether a default template is available, indicating that templates are available for security groups and blueprints.", 
            "title": "Define Infrastructure Templates"
        }, 
        {
            "location": "/os-config/index.html#networks", 
            "text": "Before you can start using Cloubreak, you must define at least one custom network that can be used for cluster instances.  An instance uses a public provider virtual network that connects to the physical network infrastructure. This network includes a DHCP server that provides IP addresses to instances. The admin or other privileged user must create this network because it connects directly to the physical network infrastructure. Learn more about OpenStack  virtual network  and  public provider network .  Your clusters can be created in new networks or in one of your existing networks. If you choose an existing network, it is possible to create a new subnet within the network.", 
            "title": "Networks"
        }, 
        {
            "location": "/os-config/index.html#add-new-network-and-subnet", 
            "text": "You can define reusable network configurations for your clusters in the  manage networks  tab:    Click on  Create a new virtual network and a new subnet .    Provide required parameters:     Parameter  Description      Name  Enter a name for your configuration.    Description  (Optional) Enter a description.    Subnet (CIDR)  Enter a valid  CIDR  for a new subnet that will be created within the VPC. For example  10.0.0.0/24 . This defines the IP address space usable by your VMs within the cluster. Cloudbreak supports the private address space defined in  RFC1918 .    Floating Pool ID  Floating IPs are not automatically allocated to instances by default, they needs to be attached to instances after creation. The Floating IPs are used to provide access to your VMs running on OpenStack. You can figure out the available network pools and their IDs by using the nova floating-ip-pool-list and neutron net-external-list or copy-pasting it from OpenStack Horizon UI. Such networks have the External Network field set to Yes. If you are unable to find the ID then just consult with your OpenStack network administrator. Please note that if you do not set this field then your cluster might not be accessible.    Public In Account  (Optional) If this option is checked, all the users belonging to your account will be able to use this network template to create clusters, but they cannot delete it.    Select Platform  (Optional) Select a previously created platform.       Click on  +create network .  No resources will be created until you create a cluster using this configuration.", 
            "title": "Add New Network and Subnet"
        }, 
        {
            "location": "/os-config/index.html#add-new-subnet-in-an-existing-network", 
            "text": "You can define reusable network configurations for your clusters in the  manage networks  tab:    Click on  Create a new subnet in an existing virtual network .    Provide required parameters:   Make sure that the new subnet defined here doesn't overlap with any of your already deployed subnets in the network.       Parameter  Description      Name  Enter a name for your configuration.    Description  (Optional) Enter a description.    Subnet (CIDR)  Enter a valid  CIDR  for a new subnet that will be created within the VPC. For example  10.0.0.0/24 .    Floating Pool ID  Floating IPs are not automatically allocated to instances by default, they needs to be attached to instances after creation. The Floating IPs are used to provide access to your VMs running on OpenStack. You can figure out the available network pools and their IDs by using the nova floating-ip-pool-list and neutron net-external-list or copy-pasting it from OpenStack Horizon UI. Such networks have the External Network field set to Yes. If you are unable to find the ID then just consult with your OpenStack network administrator. Please note that if you do not set this field then your cluster might not be accessible.    Virtual Network Identifier  This is the ID of an existing virtual network on OpenStack where you would like to launch the cluster.    Router Identifier  Specify the router ID that shall interconnect your existing Network with the Subnet which will be created by CLoudbreak.    Public In Account  (Optional) If this option is checked, all the users belonging to your account will be able to use this network template to create clusters, but they cannot delete it.    Select Platform  (Optional) Select a previously created platform.       Click on  +create network .  No resources will be created until you create a cluster using this configuration.", 
            "title": "Add New Subnet in an Existing Network"
        }, 
        {
            "location": "/os-config/index.html#use-existing-network-and-subnet", 
            "text": "You can define reusable network configurations for your clusters in the  manage networks  tab:    Click on  Use an existing subnet in an existing virtual network .     Provide required parameters:      Parameter  Description      Name  Enter a name for your configuration.    Description  (Optional) Enter a description.    Floating Pool ID  Floating IPs are not automatically allocated to instances by default, they needs to be attached to instances after creation. The Floating IPs are used to provide access to your VMs running on OpenStack. You can figure out the available network pools and their IDs by using the nova floating-ip-pool-list and neutron net-external-list or copy-pasting it from OpenStack Horizon UI. Such networks have the External Network field set to Yes. If you are unable to find the ID then just consult with your OpenStack network administrator. Please note that if you do not set this field then your cluster might not be accessible.    Virtual Network Identifier  This is the ID of an existing virtual network on OpenStack where you would like to launch the cluster.    Subnet Identifier  This is the ID of an existing subnet on OpenStack where you would like to launch the cluster.    Networking Option     Public In Account  (Optional) If this option is checked, all the users belonging to your account will be able to use this network template to create clusters, but they cannot delete it.    Select Platform  (Optional) Select a previously created platform.      When using an existing subnet, make sure that you have enough room within your network space for the new instances. The provided subnet CIDR will be ignored, but a proper CIDR range will be used.     Click on  +create network .  No resources will be created until you create a cluster using this configuration.", 
            "title": "Use Existing Network and Subnet"
        }, 
        {
            "location": "/os-config/index.html#security-groups", 
            "text": "You have two options:   Use the default security group configuration : This requires no further action.    Add your own custom security group configuration : You can define your own security group by adding the ports, protocols, and CIDR ranges that you'd like to use. The rules defined here don't need to contain the internal rules (these are automatically added by Cloudbreak to the security group on OpenStack).", 
            "title": "Security Groups"
        }, 
        {
            "location": "/os-config/index.html#default-security-group", 
            "text": "Cloudbreak includes one pre-defined security group configuration called  default-openstack-only-ssh-and-ssl , which is used by default when creating a cluster. You can see it in the  manage security groups  tab. The configuration is:      CIDR  Port  Protocol      0.0.0.0/0  22  tcp    0.0.0.0/0  433  tcp    0.0.0.0/0  9443  tcp     No resources will be created until you create a cluster using this configuration.", 
            "title": "Default Security Group"
        }, 
        {
            "location": "/os-config/index.html#add-custom-security-group", 
            "text": "You can define reusable security group configurations for your clusters in the  manage security groups  tab:    Click on  Create a new security group .   Provide required parameters:     Parameter  Value      Name  Enter a name for your security group configuration template.    Description  (Optional) Enter a description.    Public In Account  (Optional) If this option is checked, all the users belonging to your account will be able to use this security group template to create clusters, but they cannot delete it.       Provide the following parameters in order to define  Security Rules  for this security group:     Parameter  Value      CIDR  Enter a valid  CIDR IP , from which the cluster will be accessed.    Port  Enter ports that you want to open. You can either list multiple ports, separated by a comma (for example \"22,443,9443\"), or you can define port ranges (for example \"1-65355\").    Protocol  Enter protocol that you want to use.      Ports 22, 443, and 9443 must be open on every security group; otherwise Cloudbreak will not be able to communicate with your provisioned cluster.     Click  +Add Rule  to save the security rules. If needed, click  +Add Rule  again to display a new  Security Rules  form and add another set of rules.     Click  +create security group  to save the configuration.   No resources will be created until you create a cluster using this configuration.", 
            "title": "Add Custom Security Group"
        }, 
        {
            "location": "/os-config/index.html#vms-and-storage", 
            "text": "Before you can start using CLoubreak, you must define at least one custom template defining the OpenStack infrastructure that will be used for cluster nodes and storage.", 
            "title": "VMs and Storage"
        }, 
        {
            "location": "/os-config/index.html#add-custom-template", 
            "text": "You can define reusable cluster templates in the  manage templates  tab:     Click on  +create template .    Provide required parameters:      Parameter  Description      Instance Type  Select an instance type. The instance types available depend on your OpenStack implementation.    Attached Volumes Per Instance     Volume Size (GB)  10    Public In Account  (Optional) If this option is checked, all the users belonging to your account will be able to use this template to create clusters, but they cannot delete it.    Select Platform  (Optional) Select a previously created platform.       Click on  +create template .  No resources will be created until you create a cluster using this configuration.     Next: Create a Cluster", 
            "title": "Add Custom Template"
        }, 
        {
            "location": "/os-blueprints/index.html", 
            "text": "Define Cluster Blueprints\n\n\nCluster blueprints\n are your declarative definition of a Hadoop cluster, defining the host groups and which components to install on which host group. Ambari uses them as a base for your clusters. \n\n\nYou have three options:\n\n\n\n\nUse one of the pre-defined blueprints.  \n\n\nCopy and edit one of the pre-defined blueprints.   \n\n\nAdd your custom blueprint by uploading a JSON file or pasting the JSON text. \n\n\n\n\nWe recommend that you review the default blueprints to check if they meet your requirements. You can do this by expanding  the \nmanage bluerints\n pane in the Cloudbreak web UI (shown in the screenshot) or by reading the documentation below.  \n\n\n \n\n\nHere\n is an example of a blueprint. \n\n\nThe host groups in the JSON will be mapped to a set of instances when starting the cluster, and the specified services and components will be installed on the corresponding nodes. It is not necessary to define a complete configuration in the blueprint. If a configuration is missing, Ambari will fill that with a default value. \n\n\nA blueprint can be modified later from the Ambari UI.\n\n\nA blueprint can be exported from a running Ambari cluster and can be reused in Cloudbreak after slight modifications. When a blueprint is exported, some configurations are hardcoded for example domain names, memory configurations, and so on, that won't be applicable to the Cloudbreak cluster. There is no automatic way to modify an exported blueprint and make it instantly usable in Cloudbreak, the modifications have to be done manually.\n\n\nDefault Blueprints\n\n\nCloudbreak includes three default HDP cluster blueprints:\n\n\nHDP Version: \nHDP 2.6\n\n\n\n\n\n\n\n\nCluster Type\n\n\nServices\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nData Science\n\n\n Spark 1.6,\nZeppelin 0.7.0\n\n\nThis cluster configuration includes Spark 1.6 with Zeppelin.\n\n\n\n\n\n\nData Science\n\n\n Spark 2.1,\nZeppelin 0.7.0\n\n\nThis cluster configuration includes Spark 2.1 with Zeppelin.\n\n\n\n\n\n\nEDW - Analytics\n\n\n Hive 2 LLAP\n,\nZeppelin 0.7.0\n\n\nThis cluster configuration includes Hive 2 LLAP.\n\n\n\n\n\n\nEDW - ETL\n\n\n Hive 1.2.1,\nSpark 1.6\n\n\nThis cluster configuration includes Hive and Spark 1.6.\n\n\n\n\n\n\nEDW - ETL\n\n\n Hive 1.2.1,\n Spark 2.1\n\n\nThis cluster configuration includes Hive and Spark 2.1.\n\n\n\n\n\n\nBI\n\n\n Druid 0.9.2\n\n\nThis cluster configuration includes a Technical Preview of Druid.\n\n\n\n\n\n\n\n\nHDP Version: \nHDP 2.5\n\n\n\n\n\n\n\n\nCluster Type\n\n\nServices\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nData Science\n\n\n Spark 1.6,\nZeppelin 0.6.0\n\n\nThis cluster configuration includes Spark 1.6 and Zeppelin.\n\n\n\n\n\n\nEDW - ETL\n\n\n Hive 1.2.1,\nSpark 1.6\n\n\nThis cluster configuration includes Hive and Spark 1.6.\n\n\n\n\n\n\nEDW - ETL\n\n\n Hive 1.2.1,\n Spark 2.0\n\n\nThis cluster configuration includes a Technical Preview of Spark 2.0.\n\n\n\n\n\n\nEDW - Analytics\n\n\n Hive 2 LLAP\n,\nZeppelin 0.6.0\n\n\nThis cluster configuration includes a Technical Preview of Hive 2 LLAP.\n\n\n\n\n\n\n\n\n\n    \nChoosing Your Configuration\n\n    \n\nWhen creating a cluster, you can choose a more stable cluster configuration for a predicable experience.\nAlternatively, you can try the latest capabilities by choosing a cluster configuration\nthat is much more experimental. The following configuration classification applies:\n\n\n\n Stable configurations are the best choice if you want to avoid issues and other problems with launching and using clusters.\n\n\n If you want to use a Technical Preview version of a component in a release of HDP, use these configurations.\n\n\n These are the most cutting edge of the configurations, including Technical Preview components in a Technical Preview HDP release.\n\n\n\n\n\n\n\n\n\nCopy and Edit Existing Blueprint\n\n\nYou can modify default or previously added blueprints in the \nmanage blueprints\n tab. To do that, expand the entry in the Cloudbreak UI and then click \ncopy \n edit\n. \n\n\nAdd Custom Blueprint\n\n\nYou can define reusable blueprints for your clusters in the \nmanage blueprints\n tab. To add your own blueprint, click \n+create blueprint\n and enter the following parameters:\n\n\n\n\n\n\n\n\nParameter\n\n\nValue\n\n\n\n\n\n\n\n\n\n\nName\n\n\nEnter a name for your blueprint.\n\n\n\n\n\n\nDescription\n\n\n(Optional) Enter a description for your blueprint.\n\n\n\n\n\n\nBlueprint Source\n\n\nSelect one of: \nText\n: Paste blueprint in JSON format.\n \nFile\n: Upload a file that contains the blueprint.\n \nURL\n: Specify the URL for your blueprint.\n\n\n\n\n\n\nPublic In Account\n\n\n(Optional) If this option is checked, all the users belonging to your account will be able to use this blueprint to create clusters, but they cannot delete it.\n\n\n\n\n\n\n\n\n\n\nNext: Create a Cluster", 
            "title": "Define Cluster Blueprints"
        }, 
        {
            "location": "/os-blueprints/index.html#define-cluster-blueprints", 
            "text": "Cluster blueprints  are your declarative definition of a Hadoop cluster, defining the host groups and which components to install on which host group. Ambari uses them as a base for your clusters.   You have three options:   Use one of the pre-defined blueprints.    Copy and edit one of the pre-defined blueprints.     Add your custom blueprint by uploading a JSON file or pasting the JSON text.    We recommend that you review the default blueprints to check if they meet your requirements. You can do this by expanding  the  manage bluerints  pane in the Cloudbreak web UI (shown in the screenshot) or by reading the documentation below.       Here  is an example of a blueprint.   The host groups in the JSON will be mapped to a set of instances when starting the cluster, and the specified services and components will be installed on the corresponding nodes. It is not necessary to define a complete configuration in the blueprint. If a configuration is missing, Ambari will fill that with a default value.   A blueprint can be modified later from the Ambari UI.  A blueprint can be exported from a running Ambari cluster and can be reused in Cloudbreak after slight modifications. When a blueprint is exported, some configurations are hardcoded for example domain names, memory configurations, and so on, that won't be applicable to the Cloudbreak cluster. There is no automatic way to modify an exported blueprint and make it instantly usable in Cloudbreak, the modifications have to be done manually.", 
            "title": "Define Cluster Blueprints"
        }, 
        {
            "location": "/os-blueprints/index.html#default-blueprints", 
            "text": "Cloudbreak includes three default HDP cluster blueprints:", 
            "title": "Default Blueprints"
        }, 
        {
            "location": "/os-blueprints/index.html#hdp-version-hdp-26", 
            "text": "Cluster Type  Services  Description      Data Science   Spark 1.6, Zeppelin 0.7.0  This cluster configuration includes Spark 1.6 with Zeppelin.    Data Science   Spark 2.1, Zeppelin 0.7.0  This cluster configuration includes Spark 2.1 with Zeppelin.    EDW - Analytics   Hive 2 LLAP , Zeppelin 0.7.0  This cluster configuration includes Hive 2 LLAP.    EDW - ETL   Hive 1.2.1, Spark 1.6  This cluster configuration includes Hive and Spark 1.6.    EDW - ETL   Hive 1.2.1,  Spark 2.1  This cluster configuration includes Hive and Spark 2.1.    BI   Druid 0.9.2  This cluster configuration includes a Technical Preview of Druid.", 
            "title": "HDP Version: HDP 2.6"
        }, 
        {
            "location": "/os-blueprints/index.html#hdp-version-hdp-25", 
            "text": "Cluster Type  Services  Description      Data Science   Spark 1.6, Zeppelin 0.6.0  This cluster configuration includes Spark 1.6 and Zeppelin.    EDW - ETL   Hive 1.2.1, Spark 1.6  This cluster configuration includes Hive and Spark 1.6.    EDW - ETL   Hive 1.2.1,  Spark 2.0  This cluster configuration includes a Technical Preview of Spark 2.0.    EDW - Analytics   Hive 2 LLAP , Zeppelin 0.6.0  This cluster configuration includes a Technical Preview of Hive 2 LLAP.     \n     Choosing Your Configuration \n     \nWhen creating a cluster, you can choose a more stable cluster configuration for a predicable experience.\nAlternatively, you can try the latest capabilities by choosing a cluster configuration\nthat is much more experimental. The following configuration classification applies:   Stable configurations are the best choice if you want to avoid issues and other problems with launching and using clusters.   If you want to use a Technical Preview version of a component in a release of HDP, use these configurations.   These are the most cutting edge of the configurations, including Technical Preview components in a Technical Preview HDP release.", 
            "title": "HDP Version: HDP 2.5"
        }, 
        {
            "location": "/os-blueprints/index.html#copy-and-edit-existing-blueprint", 
            "text": "You can modify default or previously added blueprints in the  manage blueprints  tab. To do that, expand the entry in the Cloudbreak UI and then click  copy   edit .", 
            "title": "Copy and Edit Existing Blueprint"
        }, 
        {
            "location": "/os-blueprints/index.html#add-custom-blueprint", 
            "text": "You can define reusable blueprints for your clusters in the  manage blueprints  tab. To add your own blueprint, click  +create blueprint  and enter the following parameters:     Parameter  Value      Name  Enter a name for your blueprint.    Description  (Optional) Enter a description for your blueprint.    Blueprint Source  Select one of:  Text : Paste blueprint in JSON format.   File : Upload a file that contains the blueprint.   URL : Specify the URL for your blueprint.    Public In Account  (Optional) If this option is checked, all the users belonging to your account will be able to use this blueprint to create clusters, but they cannot delete it.      Next: Create a Cluster", 
            "title": "Add Custom Blueprint"
        }, 
        {
            "location": "/os-create/index.html", 
            "text": "Create a Cluster on OpenStack\n\n\nTo create a cluster via CLoudbreak UI:\n\n\n\n\n\n\nLog in to the Cloudbreak UI.\n\n\n\n\n\n\nIn the top right corner, select the credential that you want to use to create a cluster:\n\n\n  \n\n\n\n\n\n\nClick \n+create cluster\n and the \nCreate cluster\n form is displayed.\n\n\n\n\n\n\nOn the \nConfigure Cluster\n page, provide the following parameters:\n\n\n\n\nTo view advanced options, click \nShow Advanced Options\n. To learn about advanced options, refer to \nAdvanced Options\n.\n\n\n\n\n\n\n\n\n\n\nParameter\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nCluster Name\n\n\nEnter a name for your cluster. The name must be between 5 and 40 characters, must start with a letter, must only include lowercase letters, numbers, and hyphens.\n\n\n\n\n\n\nTags\n\n\n(Optional) You can optionally add tags, which will help you find your cluster-related resources, such as VMs, in your cloud provider account.\n\n\n\n\n\n\nRegion\n\n\nSelect the region in which you would like to launch your cluster.\n\n\n\n\n\n\nAvailability Zone\n\n\nSelect the availability zone in which you would like to launch your cluster.\n\n\n\n\n\n\nConnector Variant\n\n\nSelect \"HEAT\" or \"NATIVE\".\n\n\n\n\n\n\nSend Email When Cluster is Ready\n\n\n(Optional) Check this to receive an email each time the cluster status changes.\n\n\n\n\n\n\nPublic In Account\n\n\n(Optional) If this option is checked, all the users belonging to your account will be able to use this cluster, but they cannot delete it.\n\n\n\n\n\n\n\n\n\n\nBy default, Ambari Username and Ambari Password are set to \nadmin\n. You can override it in the \"\nConfigure Cluster\n\" tab.\n\n\n\n\n\n\n\n\nOn the \nSet up Network and Security\n page, provide the following parameters:\n\n\n\n\n\n\n\n\nParameter\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nNetwork\n\n\nSelect the virtual network in which you would like your cluster to be provisioned. You can define custom network configurations or use default network configurations.\n\n\n\n\n\n\nEnable Knox Gateway\n\n\n(Optional) Select this option to enable secure access to Ambari web UI and other cluster UIs via Knox gateway.\n\n\n\n\n\n\nEnable Kerberos Security\n\n\n(Optional) Select this option to enable Kerberos for your cluster. You will have an option to create a new kerberos or use an existing one. For more information refer to Kerberos \ndocumentation\n.\n\n\n\n\n\n\n\n\n\n\n\n\nOn the \nChoose Blueprint\n page, select the blueprint that you would like to use for your cluster. You can either choose one of the pre-configured blueprints, or add your own in the \nmanage blueprints\n tab.\n\n\nFor each host group you must provide the following:\n\n\n\n\n\n\n\n\nParameter\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nGroup Size\n\n\nEnter a number defining how many nodes to create per host group. Default is 1. The \"Group Size\" for that host group on which Ambari Server is installed must be set to \"1\".\n\n\n\n\n\n\nTemplate\n\n\nIf you have previously created a template for VMs and storage, you can select it here. If you don't make a selection, default will be used.\n\n\n\n\n\n\nSecurity Group\n\n\nIf you have previously created a template for a security group, you can select it here. If you don't make a selection, default will be used.\n\n\n\n\n\n\nAmbari Server\n\n\nYou must select one node for Ambari Server. The \"Group Size\" for that host group must be set to \"1\".\n\n\n\n\n\n\nRecipes\n\n\nYou can select a previously added recipe (custom script) to be executed on all nodes of the host group. Refer to \nRecipes\n.\n\n\n\n\n\n\n\n\n\n\n\n\nClick on \nReview and Launch\n and then \n+create and start cluster\n.\n\n\n\n\n\n\nYou will be redirected to the Cloudbreak dashboard, and a new tile representing your cluster will appear at the top of the page.\n\n\n\n\n\n\nAdvanced Options\n\n\nClick on \nShow Advanced Options\n to enter additional configuration options.\n\n\nConfigure Cluster\n\n\nYou can optionally configure the following advanced parameters:\n\n\n\n\n\n\n\n\nParameter\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nAmbari Username\n\n\nYou can log in to the Ambari UI using this username. By default, this is set to \nadmin\n.\n\n\n\n\n\n\nAmbari Password\n\n\nYou can log in to the Ambari UI using this password. By default, this is set to \nadmin\n.\n\n\n\n\n\n\nProvision Cluster\n\n\nSALT\n is pre-selected to provision your cluster.\n\n\n\n\n\n\nEnable Lifetime Management\n\n\nCheck this option if you would like your cluster to be automatically terminated after a specific amount of time (defined as \"Time to Live\" in minuter) has passed.\n\n\n\n\n\n\nFlex Subscription\n\n\nThis option will appear if you have configured your deployment for a \nFlex Subscription\n.\n\n\n\n\n\n\n\n\nChoose Blueprint\n\n\nAfter selecting a blueprint, you can optionally configure the following advanced parameters:\n\n\n\n\n\n\n\n\nParameter\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nConfig Recommendation Strategy (Stack Advisor)\n\n\nSelect how configuration recommendations generated by stack advisor will be applied. Select one of \nALWAYS_APPLY: Configuration recommendations will be applied automatically.\nALWAYS_APPLY_DONT_OVERRIDE_CUSTOM_VALUES: Configuration recommendations will be applied automatically, but they will be ignored for custom configurations.\nNEVER_APPLY: Configuration recommendations will be ignored.\nONLY_STACK_DEFAULTS_APPLY: Configuration recommendations will be applied only on the default configurations for all included services.\n\n\n\n\n\n\nValidate Blueprint\n\n\nSelect to validate the blueprint.\n\n\n\n\n\n\n\n\nChoose Failure Action\n\n\nYou can optionally select what to do if cluster creation fails or if there aren't enough instances available to create all requested nodes:\n\n\n\n\n\n\n\n\nParameter\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nFailure Action\n\n\nSelect one of: \ndo NOT rollback resources\n (default) or \nrollback resources\n. \nBy default, if creating a cluster fails, the Azure resources that were created up to that point will not be rolled back. This means that they will remain accessible for troubleshooting and you will need to to delete them manually.\n\n\n\n\n\n\nMinimum Cluster Size\n\n\nThis defines the provisioning strategy in case the cloud provider cannot allocate all the requested nodes. Select \nbest effort\n or \nexact\n.\n\n\n\n\n\n\n\n\nConfigure Ambari Repos\n\n\nYou can optionally configure a different version of Ambari than the default by providing the following information:\n\n\n\n\n\n\n\n\nParameter\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nAmbari Version\n\n\nEnter Ambari version.\n\n\n\n\n\n\nAmbari Repo URL\n\n\nEnter Ambari repo URL.\n\n\n\n\n\n\nAmbari Repo Gpg Key URL\n\n\nEnter gpgkey URL.\n\n\n\n\n\n\n\n\nConfigure HDP Repos\n\n\nYou can optionally configure a different version of HDP than the default by providing the following information:\n\n\n\n\n\n\n\n\nParameter\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nStack\n\n\nEnter stack name.\n\n\n\n\n\n\nVersion\n\n\nEnter stack version.\n\n\n\n\n\n\nStack Repo ID\n\n\nEnter stack repo ID.\n\n\n\n\n\n\nBase URL\n\n\nEner stack repo base URL.\n\n\n\n\n\n\nUtils Repo ID\n\n\nEnter Utils repo ID.\n\n\n\n\n\n\nUtils Base URL\n\n\nEnter Utils repo base URL.\n\n\n\n\n\n\nVerify\n\n\nSelect to verify the repo information.\n\n\n\n\n\n\n\n\nConfigure Ambari Database\n\n\nBy default, Ambari stores data on an embedded database, which is sufficient for ephemeral or test clusters. However, as Ambari and Cloudbreak don't perform backups of this database, it is insufficient for long-running production clusters, and you may need to configure a remote database for Ambari and Cloudbreak.\n\n\n\n\n\n\n\n\nParameter\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nVendor\n\n\nSelect database vendor from the list.\n\n\n\n\n\n\nHost\n\n\nEnter database host IP.\n\n\n\n\n\n\nPort\n\n\nEnter port number.\n\n\n\n\n\n\nName\n\n\nEnter database name.\n\n\n\n\n\n\nUser Name\n\n\nEnter database user name.\n\n\n\n\n\n\nPassword\n\n\nEnter database password.\n\n\n\n\n\n\n\n\n\n\nNext: Manage \n&\n Monitor Clusters", 
            "title": "Create a Cluster"
        }, 
        {
            "location": "/os-create/index.html#create-a-cluster-on-openstack", 
            "text": "To create a cluster via CLoudbreak UI:    Log in to the Cloudbreak UI.    In the top right corner, select the credential that you want to use to create a cluster:        Click  +create cluster  and the  Create cluster  form is displayed.    On the  Configure Cluster  page, provide the following parameters:   To view advanced options, click  Show Advanced Options . To learn about advanced options, refer to  Advanced Options .      Parameter  Description      Cluster Name  Enter a name for your cluster. The name must be between 5 and 40 characters, must start with a letter, must only include lowercase letters, numbers, and hyphens.    Tags  (Optional) You can optionally add tags, which will help you find your cluster-related resources, such as VMs, in your cloud provider account.    Region  Select the region in which you would like to launch your cluster.    Availability Zone  Select the availability zone in which you would like to launch your cluster.    Connector Variant  Select \"HEAT\" or \"NATIVE\".    Send Email When Cluster is Ready  (Optional) Check this to receive an email each time the cluster status changes.    Public In Account  (Optional) If this option is checked, all the users belonging to your account will be able to use this cluster, but they cannot delete it.      By default, Ambari Username and Ambari Password are set to  admin . You can override it in the \" Configure Cluster \" tab.     On the  Set up Network and Security  page, provide the following parameters:     Parameter  Description      Network  Select the virtual network in which you would like your cluster to be provisioned. You can define custom network configurations or use default network configurations.    Enable Knox Gateway  (Optional) Select this option to enable secure access to Ambari web UI and other cluster UIs via Knox gateway.    Enable Kerberos Security  (Optional) Select this option to enable Kerberos for your cluster. You will have an option to create a new kerberos or use an existing one. For more information refer to Kerberos  documentation .       On the  Choose Blueprint  page, select the blueprint that you would like to use for your cluster. You can either choose one of the pre-configured blueprints, or add your own in the  manage blueprints  tab.  For each host group you must provide the following:     Parameter  Description      Group Size  Enter a number defining how many nodes to create per host group. Default is 1. The \"Group Size\" for that host group on which Ambari Server is installed must be set to \"1\".    Template  If you have previously created a template for VMs and storage, you can select it here. If you don't make a selection, default will be used.    Security Group  If you have previously created a template for a security group, you can select it here. If you don't make a selection, default will be used.    Ambari Server  You must select one node for Ambari Server. The \"Group Size\" for that host group must be set to \"1\".    Recipes  You can select a previously added recipe (custom script) to be executed on all nodes of the host group. Refer to  Recipes .       Click on  Review and Launch  and then  +create and start cluster .    You will be redirected to the Cloudbreak dashboard, and a new tile representing your cluster will appear at the top of the page.", 
            "title": "Create a Cluster on OpenStack"
        }, 
        {
            "location": "/os-create/index.html#advanced-options", 
            "text": "Click on  Show Advanced Options  to enter additional configuration options.", 
            "title": "Advanced Options"
        }, 
        {
            "location": "/os-create/index.html#configure-cluster", 
            "text": "You can optionally configure the following advanced parameters:     Parameter  Description      Ambari Username  You can log in to the Ambari UI using this username. By default, this is set to  admin .    Ambari Password  You can log in to the Ambari UI using this password. By default, this is set to  admin .    Provision Cluster  SALT  is pre-selected to provision your cluster.    Enable Lifetime Management  Check this option if you would like your cluster to be automatically terminated after a specific amount of time (defined as \"Time to Live\" in minuter) has passed.    Flex Subscription  This option will appear if you have configured your deployment for a  Flex Subscription .", 
            "title": "Configure Cluster"
        }, 
        {
            "location": "/os-create/index.html#choose-blueprint", 
            "text": "After selecting a blueprint, you can optionally configure the following advanced parameters:     Parameter  Description      Config Recommendation Strategy (Stack Advisor)  Select how configuration recommendations generated by stack advisor will be applied. Select one of  ALWAYS_APPLY: Configuration recommendations will be applied automatically. ALWAYS_APPLY_DONT_OVERRIDE_CUSTOM_VALUES: Configuration recommendations will be applied automatically, but they will be ignored for custom configurations. NEVER_APPLY: Configuration recommendations will be ignored. ONLY_STACK_DEFAULTS_APPLY: Configuration recommendations will be applied only on the default configurations for all included services.    Validate Blueprint  Select to validate the blueprint.", 
            "title": "Choose Blueprint"
        }, 
        {
            "location": "/os-create/index.html#choose-failure-action", 
            "text": "You can optionally select what to do if cluster creation fails or if there aren't enough instances available to create all requested nodes:     Parameter  Description      Failure Action  Select one of:  do NOT rollback resources  (default) or  rollback resources .  By default, if creating a cluster fails, the Azure resources that were created up to that point will not be rolled back. This means that they will remain accessible for troubleshooting and you will need to to delete them manually.    Minimum Cluster Size  This defines the provisioning strategy in case the cloud provider cannot allocate all the requested nodes. Select  best effort  or  exact .", 
            "title": "Choose Failure Action"
        }, 
        {
            "location": "/os-create/index.html#configure-ambari-repos", 
            "text": "You can optionally configure a different version of Ambari than the default by providing the following information:     Parameter  Description      Ambari Version  Enter Ambari version.    Ambari Repo URL  Enter Ambari repo URL.    Ambari Repo Gpg Key URL  Enter gpgkey URL.", 
            "title": "Configure Ambari Repos"
        }, 
        {
            "location": "/os-create/index.html#configure-hdp-repos", 
            "text": "You can optionally configure a different version of HDP than the default by providing the following information:     Parameter  Description      Stack  Enter stack name.    Version  Enter stack version.    Stack Repo ID  Enter stack repo ID.    Base URL  Ener stack repo base URL.    Utils Repo ID  Enter Utils repo ID.    Utils Base URL  Enter Utils repo base URL.    Verify  Select to verify the repo information.", 
            "title": "Configure HDP Repos"
        }, 
        {
            "location": "/os-create/index.html#configure-ambari-database", 
            "text": "By default, Ambari stores data on an embedded database, which is sufficient for ephemeral or test clusters. However, as Ambari and Cloudbreak don't perform backups of this database, it is insufficient for long-running production clusters, and you may need to configure a remote database for Ambari and Cloudbreak.     Parameter  Description      Vendor  Select database vendor from the list.    Host  Enter database host IP.    Port  Enter port number.    Name  Enter database name.    User Name  Enter database user name.    Password  Enter database password.      Next: Manage  &  Monitor Clusters", 
            "title": "Configure Ambari Database"
        }, 
        {
            "location": "/os-cb-ui/index.html", 
            "text": "Manage and Monitor Clusters\n\n\nYou can manage monitor your clusters from the Cloudbreak UI. To do that, click on the title representing the cluster that you want to access: \n\n\n \n\n\nAccessing Links to Cluster Services\n\n\nYou can access links to cluster services from the \nServices\n tab.\n\n\nManaging Cluster Nodes\n\n\nYou can view details about your cluster nodes (for example, Public IP addresses) from the \nNodes\n tab. You can also delete nodes using the \nTERMINATE\n option.\n\n\nAccessing Event Log\n\n\nYou can access cluster event log from the \nEvent History\n tab.\n\n\nRepairing Your Cluster\n\n\nTo trigger repair process for your cluster, click \nrepair\n. Faulty nodes will be deleted from the cluster and new ones will be added in their place. \n\n\nTerminating Your Cluster\n\n\nTo terminate your cluster, click \nterminate\n. All cluster-related resources will be deleted, unless the network is used by other VMs, in which case it will not be deleted.", 
            "title": "Manage and Monitor Clusters"
        }, 
        {
            "location": "/os-cb-ui/index.html#manage-and-monitor-clusters", 
            "text": "You can manage monitor your clusters from the Cloudbreak UI. To do that, click on the title representing the cluster that you want to access:", 
            "title": "Manage and Monitor Clusters"
        }, 
        {
            "location": "/os-cb-ui/index.html#accessing-links-to-cluster-services", 
            "text": "You can access links to cluster services from the  Services  tab.", 
            "title": "Accessing Links to Cluster Services"
        }, 
        {
            "location": "/os-cb-ui/index.html#managing-cluster-nodes", 
            "text": "You can view details about your cluster nodes (for example, Public IP addresses) from the  Nodes  tab. You can also delete nodes using the  TERMINATE  option.", 
            "title": "Managing Cluster Nodes"
        }, 
        {
            "location": "/os-cb-ui/index.html#accessing-event-log", 
            "text": "You can access cluster event log from the  Event History  tab.", 
            "title": "Accessing Event Log"
        }, 
        {
            "location": "/os-cb-ui/index.html#repairing-your-cluster", 
            "text": "To trigger repair process for your cluster, click  repair . Faulty nodes will be deleted from the cluster and new ones will be added in their place.", 
            "title": "Repairing Your Cluster"
        }, 
        {
            "location": "/os-cb-ui/index.html#terminating-your-cluster", 
            "text": "To terminate your cluster, click  terminate . All cluster-related resources will be deleted, unless the network is used by other VMs, in which case it will not be deleted.", 
            "title": "Terminating Your Cluster"
        }, 
        {
            "location": "/credentials/index.html", 
            "text": "Credentials\n\n\nYou can manage Cloudbreak credentials in the \nmanage credentials\n tab by clicking on \n+create credential\n and providing required parameters. You must create at least one credential in order to be able to create a cluster. \n\n\nCreating Cloudbreak Credental\n\n\nFor steps, refer to:\n\n\n\n\nCreate Credential on AWS\n  \n\n\nCreate Credential on Azure\n  \n\n\nCreate Credential on GCP\n \n\n\nCreate Credential on OpenStack\n\n\n\n\nManaging Cloudbrek Credentials\n\n\nYou can manage (add and delete) your credentials from the \nmanage credentials\n tab. \n\n\nAll credentials that was cerated with \"Public In Account\" unchecked (which is the default behavior) are only visible to the user who created them. \n\n\nAll credentials that were cerated with \"Public In Account\" checked are visible to all users of the Cloudbreak instance, but only the user who created them can delete them.", 
            "title": "Cloudbreak Credentials"
        }, 
        {
            "location": "/credentials/index.html#credentials", 
            "text": "You can manage Cloudbreak credentials in the  manage credentials  tab by clicking on  +create credential  and providing required parameters. You must create at least one credential in order to be able to create a cluster.", 
            "title": "Credentials"
        }, 
        {
            "location": "/credentials/index.html#creating-cloudbreak-credental", 
            "text": "For steps, refer to:   Create Credential on AWS     Create Credential on Azure     Create Credential on GCP    Create Credential on OpenStack", 
            "title": "Creating Cloudbreak Credental"
        }, 
        {
            "location": "/credentials/index.html#managing-cloudbrek-credentials", 
            "text": "You can manage (add and delete) your credentials from the  manage credentials  tab.   All credentials that was cerated with \"Public In Account\" unchecked (which is the default behavior) are only visible to the user who created them.   All credentials that were cerated with \"Public In Account\" checked are visible to all users of the Cloudbreak instance, but only the user who created them can delete them.", 
            "title": "Managing Cloudbrek Credentials"
        }, 
        {
            "location": "/tags/index.html", 
            "text": "Resource Tagging\n\n\nWhen you manually create resources (such as VMs) in the cloud, you have an option to add custom tags that help you track these resources. Likewise, when creating clusters, you can instruct Cloudbreak to tag the cloud resources that it creates on your behalf.\n\n\nThe tags added during cluster creation will be displayed on your cloud account, allowing you to track your resources. \n\n\nYou can use tags to categorize your cloud resources by purpose, owner, and so on. Tags come in especially handy when you are using a corporate AWS account and you want to quickly identify which resources belong to your cluster(s). In fact, your corporate cloud account admin may require you to tag all the resources that you create, in particular resources, such as VMs, which incur charges.\n\n\nAdd Tags When Creating a Cluster\n\n\nYou can tag the cloud resources used for a cluster by providing custom tag names and values when creating a cluster via UI or CLI. In the UI, this option is available on the \nConfigure Cluster\n page \n \nTags\n.\n\n\nNote that:\n\n\n\n\nIt is not possible to add tags after your cluster has been created.  \n\n\nWhen you clone your cluster, all tags associated with the source cluster will be added to the template of the clone.  \n\n\nWhen you save a cluster template, all tags will be saved as part of the template, and they will be listed on the cluster template page.  \n\n\n\n\nAdd Tags in Profile (AWS)\n\n\nIn order to differentiate launched instances, you can optionally define custom tags for your AWS resources deployed by Cloudbreak. \n\n\n\n\n\n\nIf you want just one custom tag for your Cloudformation resources, set this variable in the \nProfile\n:\n\n\nexport CB_AWS_DEFAULT_CF_TAG=mytagcontent\n\n\nIn this example, the name of the tag will be \nCloudbreakId\n and the value will be \nmytagcontent\n.\n\n\n\n\n\n\nIf you prefer to customize the tag name, set this variable:\n\n\nexport CB_AWS_CUSTOM_CF_TAGS=mytagname:mytagvalue\n\n\nIn this example the name of the tag will be \nmytagname\n and the value will be \nmytagvalue\n. \n\n\n\n\n\n\nYou can specify a list of tags with a comma separated list: \n\n\nexport CB_AWS_CUSTOM_CF_TAGS=tag1:value1,tag2:value2,tag3:value3\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTO-DO: What exactly gets tagged? \nTO-DO: This configuration is available on AWS only??\n\n\n\n\n\n\n\n\n\n\nCloud Provider Documentation\n\n\nTo learn more about tags and their restrictions, refer to the cloud provider documentation:\n\n\n\n\nTags on AWS\n    \n\n\nTags on Azure\n  \n\n\nLabels on GCP\n  \n\n\nTags on OpenStack", 
            "title": "Resource Tagging"
        }, 
        {
            "location": "/tags/index.html#resource-tagging", 
            "text": "When you manually create resources (such as VMs) in the cloud, you have an option to add custom tags that help you track these resources. Likewise, when creating clusters, you can instruct Cloudbreak to tag the cloud resources that it creates on your behalf.  The tags added during cluster creation will be displayed on your cloud account, allowing you to track your resources.   You can use tags to categorize your cloud resources by purpose, owner, and so on. Tags come in especially handy when you are using a corporate AWS account and you want to quickly identify which resources belong to your cluster(s). In fact, your corporate cloud account admin may require you to tag all the resources that you create, in particular resources, such as VMs, which incur charges.", 
            "title": "Resource Tagging"
        }, 
        {
            "location": "/tags/index.html#add-tags-when-creating-a-cluster", 
            "text": "You can tag the cloud resources used for a cluster by providing custom tag names and values when creating a cluster via UI or CLI. In the UI, this option is available on the  Configure Cluster  page    Tags .  Note that:   It is not possible to add tags after your cluster has been created.    When you clone your cluster, all tags associated with the source cluster will be added to the template of the clone.    When you save a cluster template, all tags will be saved as part of the template, and they will be listed on the cluster template page.", 
            "title": "Add Tags When Creating a Cluster"
        }, 
        {
            "location": "/tags/index.html#add-tags-in-profile-aws", 
            "text": "In order to differentiate launched instances, you can optionally define custom tags for your AWS resources deployed by Cloudbreak.     If you want just one custom tag for your Cloudformation resources, set this variable in the  Profile :  export CB_AWS_DEFAULT_CF_TAG=mytagcontent  In this example, the name of the tag will be  CloudbreakId  and the value will be  mytagcontent .    If you prefer to customize the tag name, set this variable:  export CB_AWS_CUSTOM_CF_TAGS=mytagname:mytagvalue  In this example the name of the tag will be  mytagname  and the value will be  mytagvalue .     You can specify a list of tags with a comma separated list:   export CB_AWS_CUSTOM_CF_TAGS=tag1:value1,tag2:value2,tag3:value3        TO-DO: What exactly gets tagged? \nTO-DO: This configuration is available on AWS only??", 
            "title": "Add Tags in Profile (AWS)"
        }, 
        {
            "location": "/tags/index.html#cloud-provider-documentation", 
            "text": "To learn more about tags and their restrictions, refer to the cloud provider documentation:   Tags on AWS       Tags on Azure     Labels on GCP     Tags on OpenStack", 
            "title": "Cloud Provider Documentation"
        }, 
        {
            "location": "/recipes/index.html", 
            "text": "Recipes (Custom Scripts)\n\n\nWhen creating a cluster, you can optionally upload one or more recipes (i.e. scripts) and they will be executed on specific host group before or after the cluster installation. You can use recipes for tasks such as installing additional software or performing advanced cluster configuration. \n\n\nWriting Recipes\n\n\nWhen using recipes, consider the following:\n\n\n\n\nThe scripts will be executed on the node types you specify (such as \"master\", \"worker\", \"compute\"). If you want to run a a script on all nodes, define the recipe one per node type.  \n\n\nThe script will execute on all of the nodes of that type as root.  \n\n\nIn order to be executed, your script must be in a network location which is accessible from the cloud controller and cluster instances VPC.  \n\n\nMake sure to follow Linux best practices when creating your scripts. For example, don't forget to script \"Yes\" auto-answers where needed.  \n\n\nDo not execute yum update \u2013y since it may update other components on the instances (such as salt), which can create unintended or unstable behavior.  \n\n\n\n\nAdding Node Recipes\n\n\nTo add node recipes:\n\n\n\n\n\n\nPlace your scripts in a network location accessible from Cloudbreak and cluster instances virtual network. \n\n\n\n\n\n\nDefine the recipe when creating a cluster using the Cloudbreak UI or Cloudbreak Shell. You must provide:\n\n\n\n\n\n\n\n\nParameter\n\n\nValue\n\n\n\n\n\n\n\n\n\n\nName\n\n\nEnter a name for your recipe.\n\n\n\n\n\n\nDescription\n\n\n(Optional) Enter a description for your recipe.\n\n\n\n\n\n\nExecution Type\n\n\nSelect \nPRE\n or \nPOST\n, depending on whether you want the script to be executed prior to or post Ambari cluster deployment.\n\n\n\n\n\n\nScript\n\n\nSelect one of: \nScript\n: Paste the script.\n \nFile\n: Point to a file on your machine that contains the recipe.\n \nURL\n: Specify the URL for your recipe.\n\n\n\n\n\n\nPublic In Account\n\n\n(Optional) If this option is checked, all the users belonging to your account will be able to use this recipe to create clusters, but they cannot delete it.\n\n\n\n\n\n\n\n\n\n\n\n\nWhen creating a cluster, select \nShow Advanced Options\n \n \nChoose Blueprint\n and specify which recipe you want to execute on which host group. \n\n\n\n\n\n\nManaging Recipes\n\n\nYou can define reusable cluster recipes (i.e. custom scripts that will be run on selected cluster nodes before or after Ambari cluster deployment) in the \nmanage recipes\n tab by clicking on \n+create recipee\n and providing required parameters.\n\n\nYou can delete previously defined items using the \ndelete\n option.\n\n\nExecuting Recipes\n\n\nThe scripts will be executed as root. The recipe output is written to \n/var/log/recipes\n on each node on which it was executed.\n\n\nSample Recipe for Yum Proxy Setting\n\n\n#!/bin/bash\ncat >> /etc/yum.conf \n<\n\n\n\n\n\n\n\n\n\n\n\nTO-DO: Move Shell commands to the Cb Shell doc.", 
            "title": "Recipes (Custom Scripts)"
        }, 
        {
            "location": "/recipes/index.html#recipes-custom-scripts", 
            "text": "When creating a cluster, you can optionally upload one or more recipes (i.e. scripts) and they will be executed on specific host group before or after the cluster installation. You can use recipes for tasks such as installing additional software or performing advanced cluster configuration.", 
            "title": "Recipes (Custom Scripts)"
        }, 
        {
            "location": "/recipes/index.html#writing-recipes", 
            "text": "When using recipes, consider the following:   The scripts will be executed on the node types you specify (such as \"master\", \"worker\", \"compute\"). If you want to run a a script on all nodes, define the recipe one per node type.    The script will execute on all of the nodes of that type as root.    In order to be executed, your script must be in a network location which is accessible from the cloud controller and cluster instances VPC.    Make sure to follow Linux best practices when creating your scripts. For example, don't forget to script \"Yes\" auto-answers where needed.    Do not execute yum update \u2013y since it may update other components on the instances (such as salt), which can create unintended or unstable behavior.", 
            "title": "Writing Recipes"
        }, 
        {
            "location": "/recipes/index.html#adding-node-recipes", 
            "text": "To add node recipes:    Place your scripts in a network location accessible from Cloudbreak and cluster instances virtual network.     Define the recipe when creating a cluster using the Cloudbreak UI or Cloudbreak Shell. You must provide:     Parameter  Value      Name  Enter a name for your recipe.    Description  (Optional) Enter a description for your recipe.    Execution Type  Select  PRE  or  POST , depending on whether you want the script to be executed prior to or post Ambari cluster deployment.    Script  Select one of:  Script : Paste the script.   File : Point to a file on your machine that contains the recipe.   URL : Specify the URL for your recipe.    Public In Account  (Optional) If this option is checked, all the users belonging to your account will be able to use this recipe to create clusters, but they cannot delete it.       When creating a cluster, select  Show Advanced Options     Choose Blueprint  and specify which recipe you want to execute on which host group.", 
            "title": "Adding Node Recipes"
        }, 
        {
            "location": "/recipes/index.html#managing-recipes", 
            "text": "You can define reusable cluster recipes (i.e. custom scripts that will be run on selected cluster nodes before or after Ambari cluster deployment) in the  manage recipes  tab by clicking on  +create recipee  and providing required parameters.  You can delete previously defined items using the  delete  option.", 
            "title": "Managing Recipes"
        }, 
        {
            "location": "/recipes/index.html#executing-recipes", 
            "text": "The scripts will be executed as root. The recipe output is written to  /var/log/recipes  on each node on which it was executed.", 
            "title": "Executing Recipes"
        }, 
        {
            "location": "/recipes/index.html#sample-recipe-for-yum-proxy-setting", 
            "text": "#!/bin/bash\ncat >> /etc/yum.conf  <      TO-DO: Move Shell commands to the Cb Shell doc.", 
            "title": "Sample Recipe for Yum Proxy Setting"
        }, 
        {
            "location": "/autoscaling/index.html", 
            "text": "Auto Scaling", 
            "title": "Auto Scaling"
        }, 
        {
            "location": "/autoscaling/index.html#auto-scaling", 
            "text": "", 
            "title": "Auto Scaling"
        }, 
        {
            "location": "/platforms/index.html", 
            "text": "Platforms\n\n\nManage Platforms (TP)\n\n\n\n\nThis feature is a Technical Preview: it is not ready for production deployment.\n\n\n\n\nYou can define reusable \"platforms\", i.e. platform-related tags that are used to bundle together different configurations. Next, you can attach them to credentials, networks, and templates, creating multi-component platform-specific configurations defining your cluster's infrastructure.\n\n\n\n\n\n\nYou can define platforms in the \nmanage platform\n tab by clicking on \n+create platform\n and providing required parameters:\n\n\n\n\n\n\n\n\nParameter\n\n\nValue\n\n\n\n\n\n\n\n\n\n\nName\n\n\nEnter a name for your platform.\n\n\n\n\n\n\nDescription\n\n\n(Optional) Enter a description for your platform.\n\n\n\n\n\n\n\n\n\n\n\n\nAfter defining a platform, you will be able to attach a newly created resource (credential, network, or template, and so on) to it. You can apply your platform configuration in the following tabs by specifying your chosen platform. \n\n\n\n\n\n\nYou can delete previously defined items using the \ndelete\n option.\n\n\nFor more information, refer to \nPlatforms\n.", 
            "title": "Platforms (TP)"
        }, 
        {
            "location": "/platforms/index.html#platforms", 
            "text": "", 
            "title": "Platforms"
        }, 
        {
            "location": "/platforms/index.html#manage-platforms-tp", 
            "text": "This feature is a Technical Preview: it is not ready for production deployment.   You can define reusable \"platforms\", i.e. platform-related tags that are used to bundle together different configurations. Next, you can attach them to credentials, networks, and templates, creating multi-component platform-specific configurations defining your cluster's infrastructure.    You can define platforms in the  manage platform  tab by clicking on  +create platform  and providing required parameters:     Parameter  Value      Name  Enter a name for your platform.    Description  (Optional) Enter a description for your platform.       After defining a platform, you will be able to attach a newly created resource (credential, network, or template, and so on) to it. You can apply your platform configuration in the following tabs by specifying your chosen platform.     You can delete previously defined items using the  delete  option.  For more information, refer to  Platforms .", 
            "title": "Manage Platforms (TP)"
        }, 
        {
            "location": "/ambari-db/index.html", 
            "text": "Ambari Database", 
            "title": "Ambari Database (TP)"
        }, 
        {
            "location": "/ambari-db/index.html#ambari-database", 
            "text": "", 
            "title": "Ambari Database"
        }, 
        {
            "location": "/cb-db/index.html", 
            "text": "Ambari Database", 
            "title": "Cloudbreak Database"
        }, 
        {
            "location": "/cb-db/index.html#ambari-database", 
            "text": "", 
            "title": "Ambari Database"
        }, 
        {
            "location": "/images/index.html", 
            "text": "Images", 
            "title": "Custom Cloud Images (TP)"
        }, 
        {
            "location": "/images/index.html#images", 
            "text": "", 
            "title": "Images"
        }, 
        {
            "location": "/cb-account/index.html", 
            "text": "Manage Your Account\n\n\nYou can manage your Cloudbreak account from the Cloudbreak UI by clicking \naccount\n in the top right corner.\n\n\nGet Azure Usage Report\n\n\nYou can generate a usage report for all cluster resources related to your Cloudbreak instance. To generate a report:\n\n\n\n\nFrom the Cloudbreak dashboard, click on \naccount\n in the top right corner.  \n\n\nNavigate to the \nusage report\n tab.  \n\n\nSelect the range of dates for which you want the report.  \n\n\nSelect a specific user or \nall\n.  \n\n\nSelect a region.  \n\n\nClick \ngenerate\n to generate the report.  \n\n\nThe report will be displayed, including instance types and running time for each node group.   \n\n\n\n\nCheck Account Details\n\n\nTo view your account details, navigate to the \naccount details\n tab. \n\n\nManage Users\n\n\nYou can manage existing users (activate and deactivate) and invite new users to use your Cloudbreak deployment from the \nmanage users\n tab.\n\n\nInvite a New User\n\n\n\n    \nNote\n\n    \nSMTP is not supported by Azure, so in order to use this feature you have to configure an external email service using the steps described in the \n Cloudbreak\n documentation.\n\n\n\n\n\nTo invite a new user:\n\n\n\n\nFrom the Cloudbreak dashboard, click on \naccount\n in the top right corner.  \n\n\nNavigate to the \nmanage users\n tab.   \n\n\nClick on \n+invite new user\n. \n\n\nSpecify the email address and the scope of access for the user. \n\n\nClick \n+invite new user\n and you will see the name of the new user added to the user list.\n\n\nClick on the name of the user.\n\n\nClick \nactivate\n. \n\n\n\n\nActivate an Existing User\n\n\nTo activate an existing user:\n\n\n\n\nFrom the Cloudbreak dashboard, click on \naccount\n in the top right corner.  \n\n\nNavigate to the \nmanage users\n tab. \n\n\nClick on the name of the user.\n\n\nClick \nactivate\n. \n\n\n\n\nDeactivate an Existing User\n\n\nTo deactivate an existing user:\n\n\n\n\nFrom the Cloudbreak dashboard, click on \naccount\n in the top right corner.  \n\n\nNavigate to the \nmanage users\n tab. \n\n\nClick on the name of the user.\n\n\nClick \ndeactivate\n.", 
            "title": "Manage Your Account"
        }, 
        {
            "location": "/cb-account/index.html#manage-your-account", 
            "text": "You can manage your Cloudbreak account from the Cloudbreak UI by clicking  account  in the top right corner.", 
            "title": "Manage Your Account"
        }, 
        {
            "location": "/cb-account/index.html#get-azure-usage-report", 
            "text": "You can generate a usage report for all cluster resources related to your Cloudbreak instance. To generate a report:   From the Cloudbreak dashboard, click on  account  in the top right corner.    Navigate to the  usage report  tab.    Select the range of dates for which you want the report.    Select a specific user or  all .    Select a region.    Click  generate  to generate the report.    The report will be displayed, including instance types and running time for each node group.", 
            "title": "Get Azure Usage Report"
        }, 
        {
            "location": "/cb-account/index.html#check-account-details", 
            "text": "To view your account details, navigate to the  account details  tab.", 
            "title": "Check Account Details"
        }, 
        {
            "location": "/cb-account/index.html#manage-users", 
            "text": "You can manage existing users (activate and deactivate) and invite new users to use your Cloudbreak deployment from the  manage users  tab.", 
            "title": "Manage Users"
        }, 
        {
            "location": "/cb-account/index.html#invite-a-new-user", 
            "text": "Note \n     SMTP is not supported by Azure, so in order to use this feature you have to configure an external email service using the steps described in the   Cloudbreak  documentation.   To invite a new user:   From the Cloudbreak dashboard, click on  account  in the top right corner.    Navigate to the  manage users  tab.     Click on  +invite new user .   Specify the email address and the scope of access for the user.   Click  +invite new user  and you will see the name of the new user added to the user list.  Click on the name of the user.  Click  activate .", 
            "title": "Invite a New User"
        }, 
        {
            "location": "/cb-account/index.html#activate-an-existing-user", 
            "text": "To activate an existing user:   From the Cloudbreak dashboard, click on  account  in the top right corner.    Navigate to the  manage users  tab.   Click on the name of the user.  Click  activate .", 
            "title": "Activate an Existing User"
        }, 
        {
            "location": "/cb-account/index.html#deactivate-an-existing-user", 
            "text": "To deactivate an existing user:   From the Cloudbreak dashboard, click on  account  in the top right corner.    Navigate to the  manage users  tab.   Click on the name of the user.  Click  deactivate .", 
            "title": "Deactivate an Existing User"
        }, 
        {
            "location": "/upgrade/index.html", 
            "text": "Upgrade Cloudbreak\n\n\nUpdate Cloudbreak Deployer\n\n\nTo upgrade Cloudbreak to the newest version, perform the following steps:\n\n\n\n\n\n\nOn the VM where Cloudbreak ir running, navigate to the directory where your Profile file is located:\n\n\ncd /var/lib/cloudbreak-deployment/\n\n\n\n\n\n\nStop all of the running Cloudbreak components:\n\n\ncbd kill\n\n\n\n\n\n\nUpdate Cloudbreak deployer:\n\n\ncbd update\n\n\n\n\n\n\nUpdate the \ndocker-compose.yml\n file with new Docker containers needed for the cbd:\n\n\ncbd regenerate\n\n\n\n\n\n\nIf there are no other Cloudbreak instances that still use old Cloudbreak versions, remove the obsolete containers:\n\n\ncbd util cleanup\n\n\n\n\n\n\nCheck the health and version of the updated cbd:\n\n\ncbd doctor\n\n\n\n\n\n\nStart the new version of the cbd:\n\n\ncbd start\n\n\n\n\n\n\n\n\nCloudbreak needs to download updated docker images for the new version, so this step may take a while.\n\n\n\n\nIn addition, if you have any clusters running, you must update them using the folloing steps. \n\n\nUpdate Existing Clusters\n\n\n\n\n\n\n\n\n\n\nTO-DO: Maybe the sentence below should say \"Upgrading from version 1.4.0 \nor newer\n to the newest version\"??\n\n\n\n\n\n\n\n\n\n\nUpgrading from version 1.4.0 to the newest version does not require any manual modification from the users.\n\n\nUpgrading from version 1.3.0 to the newest version requires that you update existing clusters. To update existing clusters, run the following commands on the \ncbgateway\n node of the cluster:\n\n\n\n\n\n\nUpdate the version of the Salt-Bootsrap tool on the nodes:\n    \nsalt '*' cmd.run 'curl -Ls https://github.com/sequenceiq/salt-bootstrap/releases/download/v0.1.2/salt-bootstrap_0.1.2_Linux_x86_64.tgz | tar -zx -C /usr/sbin/ salt-bootstrap'\n\n\n\n\n\n\nTrigger restart of the tool on the nodes:\n\n\nsalt '*' service.dead salt-bootstrap\n\n\n\n\nTo check the version of the Salt-Bootsrap on the nodes, use \nsalt '*' cmd.run 'salt-bootstrap --version'", 
            "title": "Upgrade Clodbreak"
        }, 
        {
            "location": "/upgrade/index.html#upgrade-cloudbreak", 
            "text": "", 
            "title": "Upgrade Cloudbreak"
        }, 
        {
            "location": "/upgrade/index.html#update-cloudbreak-deployer", 
            "text": "To upgrade Cloudbreak to the newest version, perform the following steps:    On the VM where Cloudbreak ir running, navigate to the directory where your Profile file is located:  cd /var/lib/cloudbreak-deployment/    Stop all of the running Cloudbreak components:  cbd kill    Update Cloudbreak deployer:  cbd update    Update the  docker-compose.yml  file with new Docker containers needed for the cbd:  cbd regenerate    If there are no other Cloudbreak instances that still use old Cloudbreak versions, remove the obsolete containers:  cbd util cleanup    Check the health and version of the updated cbd:  cbd doctor    Start the new version of the cbd:  cbd start     Cloudbreak needs to download updated docker images for the new version, so this step may take a while.   In addition, if you have any clusters running, you must update them using the folloing steps.", 
            "title": "Update Cloudbreak Deployer"
        }, 
        {
            "location": "/upgrade/index.html#update-existing-clusters", 
            "text": "TO-DO: Maybe the sentence below should say \"Upgrading from version 1.4.0  or newer  to the newest version\"??      Upgrading from version 1.4.0 to the newest version does not require any manual modification from the users.  Upgrading from version 1.3.0 to the newest version requires that you update existing clusters. To update existing clusters, run the following commands on the  cbgateway  node of the cluster:    Update the version of the Salt-Bootsrap tool on the nodes:\n     salt '*' cmd.run 'curl -Ls https://github.com/sequenceiq/salt-bootstrap/releases/download/v0.1.2/salt-bootstrap_0.1.2_Linux_x86_64.tgz | tar -zx -C /usr/sbin/ salt-bootstrap'    Trigger restart of the tool on the nodes:  salt '*' service.dead salt-bootstrap   To check the version of the Salt-Bootsrap on the nodes, use  salt '*' cmd.run 'salt-bootstrap --version'", 
            "title": "Update Existing Clusters"
        }, 
        {
            "location": "/delete/index.html", 
            "text": "Deleting Resources\n\n\nDelete Cloudbreak Controller\n\n\nTo delete Cloudbreak Controller, delete the whole related resource group:\n\n\n\n\nFrom the Microsoft Azure Portal dashboard, select \n.\n\n\n\n\nFind the resource group that you want to delete, click on \n...\n and select \nDelete\n:\n\n\n  \n\n\n\n\n\n\nType the name of the resource group to delete and click \nDelete\n.\n\n\n\n\n\n\nDeleting Clusters\n\n\nYou can delete clusters from the Cloudbreak UI. If needed, you can also delete the cluster manually by deleting the whole resource group created when the cluster was deployed. \n\n\nThe name of the resource group, under which the cluster-related resources are organized always includes the name of the cluster, so you should be able to find the group by searching for that name in the \nResource groups\n.", 
            "title": "Delete Cloudbreak"
        }, 
        {
            "location": "/delete/index.html#deleting-resources", 
            "text": "", 
            "title": "Deleting Resources"
        }, 
        {
            "location": "/delete/index.html#delete-cloudbreak-controller", 
            "text": "To delete Cloudbreak Controller, delete the whole related resource group:   From the Microsoft Azure Portal dashboard, select  .   Find the resource group that you want to delete, click on  ...  and select  Delete :        Type the name of the resource group to delete and click  Delete .", 
            "title": "Delete Cloudbreak Controller"
        }, 
        {
            "location": "/delete/index.html#deleting-clusters", 
            "text": "You can delete clusters from the Cloudbreak UI. If needed, you can also delete the cluster manually by deleting the whole resource group created when the cluster was deployed.   The name of the resource group, under which the cluster-related resources are organized always includes the name of the cluster, so you should be able to find the group by searching for that name in the  Resource groups .", 
            "title": "Deleting Clusters"
        }, 
        {
            "location": "/vm-launch/index.html", 
            "text": "Install Cloudbreak in Your Own VM\n\n\nThis is an advanced deployment option. Select this option if you have custom VM requirements. Otherwise, you should use one of the pre-built images and follow these instructions:\n\n\n\n\nLaunch on AWS\n  \n\n\nLaunch on Azure\n  \n\n\nLaunch on GCP\n  \n\n\nLaunch on OpenStack\n   \n\n\n\n\nSystem Requirements\n\n\nTo launch the Cloudbreak deployer and install the Cloudbreak application, your system must meet the following requirements:\n\n\n\n\nMinimum VM requirements: 8GB RAM, 10GB disk, 2 cores\n\n\nSupported operating systems: RHEL, CentOS, and Oracle Linux 7 (64-bit)\n\n\nDocker 1.9.1 must be installed \n\n\n\n\n\n\nYou can install Cloudbreak on Mac OS X for evaluation purposes only. Mac OS X is not supported for a production deployment of Cloudbreak.\n\n\n\n\nPrerequisites\n\n\nTo launch the Cloudbreak deployer and install the Cloudbreak application, you must first meet the following prerequisites:\n\n\nPorts\n\n\nPorts 22 (SSH) and 443 (HTTPS) must be open.\n\n\nRoot Access\n\n\nEvery command must be executed as root. In order to get root privileges execute: \n\n\nsudo -i\n\n\n\nSystem Updates\n\n\nEnsure that your system is up-to-date by executing:\n\n\nyum -y update\n\n\n\nReboot it if necessary.\n\n\nIptables\n\n\nInstall iptables-services:\n\n\nyum -y install iptables-services net-tools\n\n\n\nWithout iptables-services installed the \niptables save\n command will not be available.\n\n\nNext, configure permissive iptables on your machine:\n\n\n\niptables --flush INPUT \n&\n&\n \\\niptables --flush FORWARD \n&\n&\n \\\nservice iptables save\n\n\n\n\nInstall Cloudbreak on Your Own VM\n\n\nInstall Cloudbreak using the following steps\"\n\n\n\n\n\n\nInstall the Cloudbreak deployer and unzip the platform-specific single binary to your PATH. For example:\n\n\nyum -y install unzip tar\ncurl -Ls s3.amazonaws.com/public-repo-1.hortonworks.com/HDP/cloudbreak/cloudbreak-deployer_1.16.1_$(uname)_x86_64.tgz | sudo tar -xz -C /bin cbd\ncbd --version\n\n\nOnce the Cloudbreak Deployer is installed, you can set up the Cloudbreak application.\n\n\n\n\n\n\nCreate a Cloudbreak deployment directory and navigate to it:\n\n\nmkdir cloudbreak-deployment\ncd cloudbreak-deployment\n\n\n\n\n\n\nIn the directory, create a file called \nProfile\n with the following content:\n\n\nexport UAA_DEFAULT_SECRET=MY-SECRET\nexport UAA_DEFAULT_USER_PW=MY-PASSWORD\n\n\nFor example:\n\n\nexport UAA_DEFAULT_SECRET=MySecret123\nexport UAA_DEFAULT_USER_PW=MySecurePassword123\n\n\n\n\nYou will need to provide the password when logging in to the Cloudbreak web UI and when using the Cloudbreak Shell. The secret will be used by Cloudbreak for authentication.\n\n\n\n\n\n\n\n\nGenerate configurations by executing:\n\n\nrm *.yml\ncbd generate\n   \n\n\nThe cbd start command includes the cbd generate command which applies the following steps:\n\n\n\n\nCreates the \ndocker-compose.yml\n file, which describes the configuration of all the Docker containers required for the Cloudbreak deployment.  \n\n\nCreates the \nuaa.yml\n file, which holds the configuration of the identity server used to authenticate users with Cloudbreak.   \n\n\n\n\n\n\n\n\nStart the Cloudbreak application by using the following commands:\n\n\ncbd pull\ncbd start\n\n\nThis will start the Docker containers and initialize the application. The first time you start the Coudbreak app, the process will take longer than usual due to the download of all the necessary docker images.\n\n\n\n\n\n\nNext, check Cloudbreak Application logs: \n\n\ncbd logs cloudbreak\n\n\nYou should see a message like this in the log: \nStarted CloudbreakApplication in 36.823 seconds.\n Cloudbreak normally takes less than a minute to start.\n\n\n\n\n\n\nTroubleshooting\n\n\nCbd Cannot Get VM's Public IP\n\n\nBy default the \ncbd\n tool tries to get the VM's public IP to bind Cloudbreak UI to it. But if \ncbd\n cannot get the IP address during the initialization, you must set it manually. Check your \nProfile\n and if \nPUBLIC_IP\n is not set, add the \nPUBLIC_IP\n variable and set it to the public IP of the VM. For example: \n\n\nexport PUBLIC_IP=192.134.23.10\n\n\n\nPermission or Connection Problems\n\n\nIf you face permission or connection issues, disable SELinux:\n\n\n\n\nSet \nSELINUX=disabled\n in \n/etc/selinux/config\n.  \n\n\nReboot the machine.  \n\n\n\n\nEnsure the SELinux is not turned on afterwards:\n\n\n\n\n\n\n\n\nNext Steps\n\n\nFollow the platform-specific instructions. Make sure to review the prerequisites for creating a Cloudbreak credential and then log in to the Cloudbreak web UI and create a credential for Cloubdreak.\n\n\n\n\nLaunch on AWS\n\n\nLaunch on Azure\n\n\nLaunch on GCP\n\n\nLaunch on OpenStack", 
            "title": "Install on Your Own VM"
        }, 
        {
            "location": "/vm-launch/index.html#install-cloudbreak-in-your-own-vm", 
            "text": "This is an advanced deployment option. Select this option if you have custom VM requirements. Otherwise, you should use one of the pre-built images and follow these instructions:   Launch on AWS     Launch on Azure     Launch on GCP     Launch on OpenStack", 
            "title": "Install Cloudbreak in Your Own VM"
        }, 
        {
            "location": "/vm-launch/index.html#system-requirements", 
            "text": "To launch the Cloudbreak deployer and install the Cloudbreak application, your system must meet the following requirements:   Minimum VM requirements: 8GB RAM, 10GB disk, 2 cores  Supported operating systems: RHEL, CentOS, and Oracle Linux 7 (64-bit)  Docker 1.9.1 must be installed     You can install Cloudbreak on Mac OS X for evaluation purposes only. Mac OS X is not supported for a production deployment of Cloudbreak.", 
            "title": "System Requirements"
        }, 
        {
            "location": "/vm-launch/index.html#prerequisites", 
            "text": "To launch the Cloudbreak deployer and install the Cloudbreak application, you must first meet the following prerequisites:", 
            "title": "Prerequisites"
        }, 
        {
            "location": "/vm-launch/index.html#ports", 
            "text": "Ports 22 (SSH) and 443 (HTTPS) must be open.", 
            "title": "Ports"
        }, 
        {
            "location": "/vm-launch/index.html#root-access", 
            "text": "Every command must be executed as root. In order to get root privileges execute:   sudo -i", 
            "title": "Root Access"
        }, 
        {
            "location": "/vm-launch/index.html#system-updates", 
            "text": "Ensure that your system is up-to-date by executing:  yum -y update  Reboot it if necessary.", 
            "title": "System Updates"
        }, 
        {
            "location": "/vm-launch/index.html#iptables", 
            "text": "Install iptables-services:  yum -y install iptables-services net-tools  Without iptables-services installed the  iptables save  command will not be available.  Next, configure permissive iptables on your machine:  \niptables --flush INPUT  & &  \\\niptables --flush FORWARD  & &  \\\nservice iptables save", 
            "title": "Iptables"
        }, 
        {
            "location": "/vm-launch/index.html#install-cloudbreak-on-your-own-vm", 
            "text": "Install Cloudbreak using the following steps\"    Install the Cloudbreak deployer and unzip the platform-specific single binary to your PATH. For example:  yum -y install unzip tar\ncurl -Ls s3.amazonaws.com/public-repo-1.hortonworks.com/HDP/cloudbreak/cloudbreak-deployer_1.16.1_$(uname)_x86_64.tgz | sudo tar -xz -C /bin cbd\ncbd --version  Once the Cloudbreak Deployer is installed, you can set up the Cloudbreak application.    Create a Cloudbreak deployment directory and navigate to it:  mkdir cloudbreak-deployment\ncd cloudbreak-deployment    In the directory, create a file called  Profile  with the following content:  export UAA_DEFAULT_SECRET=MY-SECRET\nexport UAA_DEFAULT_USER_PW=MY-PASSWORD  For example:  export UAA_DEFAULT_SECRET=MySecret123\nexport UAA_DEFAULT_USER_PW=MySecurePassword123   You will need to provide the password when logging in to the Cloudbreak web UI and when using the Cloudbreak Shell. The secret will be used by Cloudbreak for authentication.     Generate configurations by executing:  rm *.yml\ncbd generate      The cbd start command includes the cbd generate command which applies the following steps:   Creates the  docker-compose.yml  file, which describes the configuration of all the Docker containers required for the Cloudbreak deployment.    Creates the  uaa.yml  file, which holds the configuration of the identity server used to authenticate users with Cloudbreak.        Start the Cloudbreak application by using the following commands:  cbd pull\ncbd start  This will start the Docker containers and initialize the application. The first time you start the Coudbreak app, the process will take longer than usual due to the download of all the necessary docker images.    Next, check Cloudbreak Application logs:   cbd logs cloudbreak  You should see a message like this in the log:  Started CloudbreakApplication in 36.823 seconds.  Cloudbreak normally takes less than a minute to start.", 
            "title": "Install Cloudbreak on Your Own VM"
        }, 
        {
            "location": "/vm-launch/index.html#troubleshooting", 
            "text": "", 
            "title": "Troubleshooting"
        }, 
        {
            "location": "/vm-launch/index.html#cbd-cannot-get-vms-public-ip", 
            "text": "By default the  cbd  tool tries to get the VM's public IP to bind Cloudbreak UI to it. But if  cbd  cannot get the IP address during the initialization, you must set it manually. Check your  Profile  and if  PUBLIC_IP  is not set, add the  PUBLIC_IP  variable and set it to the public IP of the VM. For example:   export PUBLIC_IP=192.134.23.10", 
            "title": "Cbd Cannot Get VM's Public IP"
        }, 
        {
            "location": "/vm-launch/index.html#permission-or-connection-problems", 
            "text": "If you face permission or connection issues, disable SELinux:   Set  SELINUX=disabled  in  /etc/selinux/config .    Reboot the machine.     Ensure the SELinux is not turned on afterwards:", 
            "title": "Permission or Connection Problems"
        }, 
        {
            "location": "/vm-launch/index.html#next-steps", 
            "text": "Follow the platform-specific instructions. Make sure to review the prerequisites for creating a Cloudbreak credential and then log in to the Cloudbreak web UI and create a credential for Cloubdreak.   Launch on AWS  Launch on Azure  Launch on GCP  Launch on OpenStack", 
            "title": "Next Steps"
        }, 
        {
            "location": "/security/index.html", 
            "text": "Network and Security\n\n\nVirtual Network\n\n\nAzure uses Virtual network (VNet) service to create virtual networks that resembles a traditional networks. Your Cloudbreak controller and clusters are launched into the virtual network infrastructure, with a new VNet created for each resource (Cloudbreak controller, cluster1, cluster2, and so on).\n\n\nNetwork Security Groups\n\n\nNetwork security groups are set up to control network traffic to the VMs in the system. By default, the system is configured to restrict inbound network traffic to the minimal set of ports. You can add or modify rules to each security group that allow traffic to or from its associated instances.\n\n\nThis section describes the default security group configuration for the various components in the system.\n\n\n\n\nThe inbound and outbound rules (protocols, port and IP ranges) for the security groups can be modified later using the Network Security Groups dashboard.\n\n\n\n\nThe naming convention for the security groups that are automatically created is:\n\n\n\n\nCloudbreak controller VM: cbdeployerNsg\n\n\nCluster node VMs: {host_group_name}{cluster_name}sg\n\n\n\n\nThe following security groups are created automatically:\n\n\nCloudbreak Security Group\n\n\nThe \ncbdeployerNsg\n security group is created when launching  Cloudbreak and is associated with the Cloudbreak VM. The following table lists the security group port configuration for the cloud controller instance.\nThe security group \nSource\n for these ports is set to the \nRemote Access\n CIDR IP specified when\nlaunching Cloudbreak.\n\n\n\n\n\n\n\n\nInbound Port\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\n22\n\n\nSSH access to the Cloudbreak VM.\n\n\n\n\n\n\n80\n\n\nHTTP access to the Cloudbreak UI. This is automatically redirected to the HTTPS (443) port.\n\n\n\n\n\n\n443\n\n\nHTTPS access to the Cloudbreak UI.\n\n\n\n\n\n\n\n\nCluster Security Groups\n\n\nMultiple security groups are created when you create a cluster, one for each host group. The\nsecurity group \nSource\n for these ports is set to the \nRemote Access\n CIDR IP specified when creating the cluster.\n\n\nThe following table lists the \nmaster node\n security group port configuration.\n\n\n\n\n\n\n\n\nInbound Port\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\n22\n\n\nSSH access to the node instance.\n\n\n\n\n\n\n9443\n\n\nInternal management port, used by the cloud controller to communicate with the cluster master node.\n\n\n\n\n\n\n8443\n1\n\n\nSecured HTTPS gateway access to the Ambari, Zeppelin, Hive JDBC, and other Cluster Components.\n\n\n\n\n\n\n\n\n\n\n1\n Port 8443 is only opened on the master node if when you create cluster, you check the checkbox under \nSetup Network and Security \n Enable Knox Gateway\n (to Ambari and Zeppelin Web UIs, Hive JDBC and/or Cluster Components UIs).\n\n\n\n\nThe following table lists the security group port configuration for other host groups:\n\n\n\n\n\n\n\n\nInbound Port\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\n22\n\n\nSSH access to the node instance.\n\n\n\n\n\n\n\n\n\n    \nLearn More\n\n    \n\nRefer to the Azure network security groups \n documentation\n\nfor more information about viewing and modifying network security group rules for VMs.", 
            "title": "Network and Security"
        }, 
        {
            "location": "/security/index.html#network-and-security", 
            "text": "", 
            "title": "Network and Security"
        }, 
        {
            "location": "/security/index.html#virtual-network", 
            "text": "Azure uses Virtual network (VNet) service to create virtual networks that resembles a traditional networks. Your Cloudbreak controller and clusters are launched into the virtual network infrastructure, with a new VNet created for each resource (Cloudbreak controller, cluster1, cluster2, and so on).", 
            "title": "Virtual Network"
        }, 
        {
            "location": "/security/index.html#network-security-groups", 
            "text": "Network security groups are set up to control network traffic to the VMs in the system. By default, the system is configured to restrict inbound network traffic to the minimal set of ports. You can add or modify rules to each security group that allow traffic to or from its associated instances.  This section describes the default security group configuration for the various components in the system.   The inbound and outbound rules (protocols, port and IP ranges) for the security groups can be modified later using the Network Security Groups dashboard.   The naming convention for the security groups that are automatically created is:   Cloudbreak controller VM: cbdeployerNsg  Cluster node VMs: {host_group_name}{cluster_name}sg   The following security groups are created automatically:", 
            "title": "Network Security Groups"
        }, 
        {
            "location": "/security/index.html#cloudbreak-security-group", 
            "text": "The  cbdeployerNsg  security group is created when launching  Cloudbreak and is associated with the Cloudbreak VM. The following table lists the security group port configuration for the cloud controller instance.\nThe security group  Source  for these ports is set to the  Remote Access  CIDR IP specified when\nlaunching Cloudbreak.     Inbound Port  Description      22  SSH access to the Cloudbreak VM.    80  HTTP access to the Cloudbreak UI. This is automatically redirected to the HTTPS (443) port.    443  HTTPS access to the Cloudbreak UI.", 
            "title": "Cloudbreak Security Group"
        }, 
        {
            "location": "/security/index.html#cluster-security-groups", 
            "text": "Multiple security groups are created when you create a cluster, one for each host group. The\nsecurity group  Source  for these ports is set to the  Remote Access  CIDR IP specified when creating the cluster.  The following table lists the  master node  security group port configuration.     Inbound Port  Description      22  SSH access to the node instance.    9443  Internal management port, used by the cloud controller to communicate with the cluster master node.    8443 1  Secured HTTPS gateway access to the Ambari, Zeppelin, Hive JDBC, and other Cluster Components.      1  Port 8443 is only opened on the master node if when you create cluster, you check the checkbox under  Setup Network and Security   Enable Knox Gateway  (to Ambari and Zeppelin Web UIs, Hive JDBC and/or Cluster Components UIs).   The following table lists the security group port configuration for other host groups:     Inbound Port  Description      22  SSH access to the node instance.     \n     Learn More \n     \nRefer to the Azure network security groups   documentation \nfor more information about viewing and modifying network security group rules for VMs.", 
            "title": "Cluster Security Groups"
        }, 
        {
            "location": "/security-profile/index.html", 
            "text": "Securing Cloudbreak Profile", 
            "title": "Securing Profile"
        }, 
        {
            "location": "/security-profile/index.html#securing-cloudbreak-profile", 
            "text": "", 
            "title": "Securing Cloudbreak Profile"
        }, 
        {
            "location": "/ssl-certificate/index.html", 
            "text": "Kerberos", 
            "title": "SSL Certificate"
        }, 
        {
            "location": "/ssl-certificate/index.html#kerberos", 
            "text": "", 
            "title": "Kerberos"
        }, 
        {
            "location": "/ldap/index.html", 
            "text": "LDAP", 
            "title": "LDAP/AD"
        }, 
        {
            "location": "/ldap/index.html#ldap", 
            "text": "", 
            "title": "LDAP"
        }, 
        {
            "location": "/kerberos/index.html", 
            "text": "Kerberos", 
            "title": "Kerberos"
        }, 
        {
            "location": "/kerberos/index.html#kerberos", 
            "text": "", 
            "title": "Kerberos"
        }, 
        {
            "location": "/releasenotes/index.html", 
            "text": "Release Notes\n\n\nNew Features\n\n\nChange Log\n\n\nSystem Info\n\n\n\n\n\n\n\n\n\n\nTO-DO: Which info is common for all cloud providers and which is per platform.\n\n\n\n\n\n\n\n\n\n\nCloudbreak\n\n\n\n\n\n\n\n\nComponent\n\n\nDetails\n\n\n\n\n\n\n\n\n\n\nOperating System\n\n\nCentOS Linux release 7.3.1611\n\n\n\n\n\n\nJDK\n\n\nOpenJDK 1.8.0_111\n\n\n\n\n\n\n\n\nHDP Services\n\n\n\n\n\n\n\n\nComponent\n\n\nDetails\n\n\n\n\n\n\n\n\n\n\nOperating System\n\n\nCentOS Linux release 7.3.1611\n\n\n\n\n\n\nJDK\n\n\nOpenJDK 1.8.0_111\n\n\n\n\n\n\nApache Ambari\n\n\n2.4.2.2-1\n\n\n\n\n\n\nHortonworks Data Platform\n\n\n2.5.0.1-210\n\n\n\n\n\n\n\n\nKnown Issues", 
            "title": "Release Notes"
        }, 
        {
            "location": "/releasenotes/index.html#release-notes", 
            "text": "", 
            "title": "Release Notes"
        }, 
        {
            "location": "/releasenotes/index.html#new-features", 
            "text": "", 
            "title": "New Features"
        }, 
        {
            "location": "/releasenotes/index.html#change-log", 
            "text": "", 
            "title": "Change Log"
        }, 
        {
            "location": "/releasenotes/index.html#system-info", 
            "text": "TO-DO: Which info is common for all cloud providers and which is per platform.", 
            "title": "System Info"
        }, 
        {
            "location": "/releasenotes/index.html#cloudbreak", 
            "text": "Component  Details      Operating System  CentOS Linux release 7.3.1611    JDK  OpenJDK 1.8.0_111", 
            "title": "Cloudbreak"
        }, 
        {
            "location": "/releasenotes/index.html#hdp-services", 
            "text": "Component  Details      Operating System  CentOS Linux release 7.3.1611    JDK  OpenJDK 1.8.0_111    Apache Ambari  2.4.2.2-1    Hortonworks Data Platform  2.5.0.1-210", 
            "title": "HDP Services"
        }, 
        {
            "location": "/releasenotes/index.html#known-issues", 
            "text": "", 
            "title": "Known Issues"
        }, 
        {
            "location": "/cb-shell/index.html", 
            "text": "Cloudbreak Shell\n\n\nThe goal with the Cloudbreak Shell is to provide an interactive command line tool which:\n\n\n\n\nSupports all functionality available through the REST API and Cloudbreak web UI\n\n\nMakes possible complete automation of management task via scripts\n\n\nIncludes context-aware commands\n\n\nAllows tab completion\n\n\nSupports required and optional parameters\n\n\nIncludes a hint command to guide you\n\n\n\n\nInstall and Start Cloudbreak Shell\n\n\nThere are three ways to install and run Cloudbreak Shell:\n\n\n\n\nFrom the Cloudbreak VM (Recommended) \n\n\nFrom the Docker Image  \n\n\nBuild From Source  \n\n\n\n\n\n\nThe latter two methods run the CLI on your local machine.\n\n\n\n\nFrom the Cloudbreak VM\n\n\nThe easiest way to install and start Cloudbreak Shell is from the VM on which you have deployed Cloudbreak. On the VM, navigate to the \n/var/lib/cloudbreak-deployment/\n directory and execute:\n\n\ncbd util cloudbreak-shell\n\n\n\nIf you would like to use Cloudbreak Shell from your local machine:\n\n\n\n\n\n\nExecute \ncbd util cloudbreak-shell-remote\n on the VM where Cloudbreak is running.\n\n\n\n\n\n\nCopy the output of the above command. \n\n\n\n\n\n\nPaste and execute the output on your local machine.\n\n\n\n\n\n\nFrom the Docker Image\n\n\nYou can find the docker image and its documentation \nhere\n.\n\n\n\n\n\n\n\n\n\n\nTO-DO: Add from the github doc? Is this still valid? \n\n\n\n\n\n\n\n\n\n\nBuild From Source\n\n\n\n\n\n\n\n\n\n\nTO-DO: Add from the old doc. Is this still valid? \n\n\nTO-DO: Include documentation from: (the repository url change because the project is now under hwx)\n\n\n\n\n\n\n\n\n\n\n\n\nCloudbreak docs\n \n\n\nCloudbreak Shell\n \n\n\nProvisioning clusters via Cloudbreak Shell", 
            "title": "Cloudbreak Shell"
        }, 
        {
            "location": "/cb-shell/index.html#cloudbreak-shell", 
            "text": "The goal with the Cloudbreak Shell is to provide an interactive command line tool which:   Supports all functionality available through the REST API and Cloudbreak web UI  Makes possible complete automation of management task via scripts  Includes context-aware commands  Allows tab completion  Supports required and optional parameters  Includes a hint command to guide you", 
            "title": "Cloudbreak Shell"
        }, 
        {
            "location": "/cb-shell/index.html#install-and-start-cloudbreak-shell", 
            "text": "There are three ways to install and run Cloudbreak Shell:   From the Cloudbreak VM (Recommended)   From the Docker Image    Build From Source      The latter two methods run the CLI on your local machine.", 
            "title": "Install and Start Cloudbreak Shell"
        }, 
        {
            "location": "/cb-shell/index.html#from-the-cloudbreak-vm", 
            "text": "The easiest way to install and start Cloudbreak Shell is from the VM on which you have deployed Cloudbreak. On the VM, navigate to the  /var/lib/cloudbreak-deployment/  directory and execute:  cbd util cloudbreak-shell  If you would like to use Cloudbreak Shell from your local machine:    Execute  cbd util cloudbreak-shell-remote  on the VM where Cloudbreak is running.    Copy the output of the above command.     Paste and execute the output on your local machine.", 
            "title": "From the Cloudbreak VM"
        }, 
        {
            "location": "/cb-shell/index.html#from-the-docker-image", 
            "text": "You can find the docker image and its documentation  here .      TO-DO: Add from the github doc? Is this still valid?", 
            "title": "From the Docker Image"
        }, 
        {
            "location": "/cb-shell/index.html#build-from-source", 
            "text": "TO-DO: Add from the old doc. Is this still valid?   TO-DO: Include documentation from: (the repository url change because the project is now under hwx)       Cloudbreak docs    Cloudbreak Shell    Provisioning clusters via Cloudbreak Shell", 
            "title": "Build From Source"
        }, 
        {
            "location": "/profile/index.html", 
            "text": "Profile", 
            "title": "Profile File"
        }, 
        {
            "location": "/profile/index.html#profile", 
            "text": "", 
            "title": "Profile"
        }, 
        {
            "location": "/faq/index.html", 
            "text": "FAQ\n\n\nHow to...\n\n\nGenerate a New SSH Key Pair\n\n\nAll the instances created by Cloudbreak are configured to allow key-based SSH, so you'll need to provide an SSH public key that can be used later to SSH onto the instances in the clusters you'll create with Cloudbreak. You can use one of your existing keys or you can generate a new one.\n\n\nTo generate a new SSH key pair, execute:\n\n\nssh-keygen -t rsa -b 4096 -C \"your_email@example.com\"\n# Creates a new ssh key, using the provided email as a label\n# Generating public/private rsa key pair.\n# Enter file in which to save the key (/Users/you/.ssh/id_rsa): [Press enter]\n\n\n\nYou'll be asked to enter a passphrase, but you can leave it empty:\n\n\n# Enter passphrase (empty for no passphrase): [Type a passphrase]\n# Enter same passphrase again: [Type passphrase again]\n\n\n\nAfter you enter (or not) a passphrase, the key pair is generated. The output should look similar to:\n\n\n# Your identification has been saved in /Users/you/.ssh/id_rsa.\n# Your public key has been saved in /Users/you/.ssh/id_rsa.pub.\n# The key fingerprint is:\n# 01:0f:f4:3b:ca:85:sd:17:sd:7d:sd:68:9d:sd:a2:sd your_email@example.com\n\n\n\nLater you'll need to pass the content of the \n.pub\n file to Cloudbreak and use the private key file to SSH to the instances. \n\n\nRecover My Public SSH Key\n\n\nThe \n-y\n option of \nssh-keygen\n outputs the public key. For example:\n\n\nssh-keygen -y -f ~/.ssh/id_rsa > ~/.ssh/id_rsa.pub\n\n\n\nSSH to the Hosts\n\n\nAccess Cloudbreak Logs\n\n\nCheck Cloudbreak Version", 
            "title": "FAQ"
        }, 
        {
            "location": "/faq/index.html#faq", 
            "text": "How to...", 
            "title": "FAQ"
        }, 
        {
            "location": "/faq/index.html#generate-a-new-ssh-key-pair", 
            "text": "All the instances created by Cloudbreak are configured to allow key-based SSH, so you'll need to provide an SSH public key that can be used later to SSH onto the instances in the clusters you'll create with Cloudbreak. You can use one of your existing keys or you can generate a new one.  To generate a new SSH key pair, execute:  ssh-keygen -t rsa -b 4096 -C \"your_email@example.com\"\n# Creates a new ssh key, using the provided email as a label\n# Generating public/private rsa key pair.\n# Enter file in which to save the key (/Users/you/.ssh/id_rsa): [Press enter]  You'll be asked to enter a passphrase, but you can leave it empty:  # Enter passphrase (empty for no passphrase): [Type a passphrase]\n# Enter same passphrase again: [Type passphrase again]  After you enter (or not) a passphrase, the key pair is generated. The output should look similar to:  # Your identification has been saved in /Users/you/.ssh/id_rsa.\n# Your public key has been saved in /Users/you/.ssh/id_rsa.pub.\n# The key fingerprint is:\n# 01:0f:f4:3b:ca:85:sd:17:sd:7d:sd:68:9d:sd:a2:sd your_email@example.com  Later you'll need to pass the content of the  .pub  file to Cloudbreak and use the private key file to SSH to the instances.", 
            "title": "Generate a New SSH Key Pair"
        }, 
        {
            "location": "/faq/index.html#recover-my-public-ssh-key", 
            "text": "The  -y  option of  ssh-keygen  outputs the public key. For example:  ssh-keygen -y -f ~/.ssh/id_rsa > ~/.ssh/id_rsa.pub", 
            "title": "Recover My Public SSH Key"
        }, 
        {
            "location": "/faq/index.html#ssh-to-the-hosts", 
            "text": "", 
            "title": "SSH to the Hosts"
        }, 
        {
            "location": "/faq/index.html#access-cloudbreak-logs", 
            "text": "", 
            "title": "Access Cloudbreak Logs"
        }, 
        {
            "location": "/faq/index.html#check-cloudbreak-version", 
            "text": "", 
            "title": "Check Cloudbreak Version"
        }, 
        {
            "location": "/trouble-cb/index.html", 
            "text": "Troubleshooting Cloudbreak\n\n\nChecking the Logs\n\n\nWhen troubleshooting, you can access the following Cloudbreak logs.\n\n\nCloudbreak Logs\n\n\nWhen installing Cloudbreak using a pre-built cloud image, the  Cloudbreak Deployer location and the cbd root folder is \n/var/lib/cloudbreak-deployment\n. You must execute all cbd actions from the cbd root folder as a cloudbreak user. \n\n\n\n\nYour cbd root directory may be different if you installed Cloudbreak on your own VM. \n\n\n\n\nCloudbreak consists of multiple microservices deployed into Docker containers. \n\n\nAggregated Logs\n\n\nTo check aggregated service logs, use the following commands:\n\n\ncbd logs\n shows all service logs.\n\n\ncbd logs | tee cloudbreak.log\n allows you to redirect the input into a file for sharing these logs.\n\n\nIndividual Service Logs\n\n\nTo check individual service logs, use the following commands:\n\n\ncbd logs cloudbreak\n shows Cloudbreak logs. This service is the backend service that handles all deployments.\n\n\ncbd logs uluwatu\n shows Cloudbreak UI logs. Uluwatu is the UI component of Cloudbreak.\n\n\ncbd logs identity\n shows Identity logs. Identity is responsible for authentication and authorization.\n\n\n\n\n\n\n\n\n\n\nTO-DO: Wasn't this previously called UAA? In teh Architecture section we call this component \"UAA\". Should I just call it \"Identity\" everywhere? \n\n\n\n\n\n\n\n\n\n\ncbd logs periscope\n shows Periscope logs. Periscope is responsible for triggering autoscaling rules.\n\n\nDocker Logs\n\n\nThe same logs can be accessed via Docker commands:\n\n\ndocker logs cbreak_cloudbreak_1\n shows the same logs as \ncbd logs cloudbreak\n.\n\n\nCloudbreak logs are also rotated and can be accessed later from the Cloudbreak deployment folder. \n\n\n\n\n\n\n\n\n\n\nTO-DO: I don't understand hat the sentence above means. Can you rephrase? \n\n\n\n\n\n\n\n\nThere is a symlink called \ncbreak.log\n which points to the latest log file. Sharing this symlink does not share the log itself.\n\n\n\n\nSaltstack Logs\n\n\nCloudbreak uses Saltstack to install Ambari and the necessary packages for the HDP provisioning. Salt Master always runs alongside the Ambari Server node. Each instance in the cluster runs a Salt Minion, which connects to the Salt Master. There can be multiple Salt Masters if the cluster is configured to run in HA (High Availability) mode and in this case each Salt Minion connects to each Salt Master.\n\n\nCloudbreak also uses SaltStack to execute user-provided customization scripts called \"recipes\". \n\n\nSalt Master and Salt Minion logs can be found at the following location: \n/var/log/salt\n\n\nAmbari Logs\n\n\nCloudbreak uses Ambari to orchestrate the installation of the different HDP components. Each instance in the cluster runs an Ambari agent which connects to the Ambari server. Ambari server is declared by the user during the cluster installation wizard. \n\n\nAmbari Server Logs\n\n\nAmbari server logs can be found in the following locations:\n\n\n/var/log/ambari-server/ambari-server.log\n\n\n/var/log/ambari-server/ambari-server.out\n\n\nBoth files contain important information about the root cause of a certain issue so it is advised to check both.\n\n\nAmbari Agent Logs\n\n\nAmbari agent logs can be found in the following locations:\n\n\n/var/log/ambari-agent/ambari-agent.log\n\n\nRecipe Logs\n\n\nCloudbreak supports \"recipes\" - user-provided customization scripts that can be run prior to or after cluster installtion. It is the user\u2019s responsibility to provide an idempotent well tested script. However, if the execution fails, the recipe logs can be found at \n/var/log/recipes\n.\n\n\nIt is advised, but not required to have an advanced logging mechanism in the script, as Cloudbreak always logs every script that are run. Recipes are often the sources of installation failures as users might try to remove necessary packages or reconfigure services.\n\n\n\n\n\n\n\n\n\n\nTO-DO: Which of these logs are on the Cloudbreak node and which on the cluster nodes (and which specific nodes)?\n\n\n\n\n\n\n\n\n\n\nCommon Errors\n\n\nQuota Limitations\n\n\nEach cloud provider has quota limitations on various cloud resources, and these quotas can usually be increased on request. If there is an error message in Cloudbreak saying that there are no more available EIPs (Elastic IP Address) or VPCs, you need to request more of these resources. \n\n\nTo see the limitations visit the cloud provider\u2019s site:\n\n\n\n\nAWS Service Limits\n \n\n\nAzure subscription and service limits, quotas, and constraints\n\n\nGCP Resource Quotas\n \n\n\n\n\nBlueprints: Invalid Services and Configurations\n\n\nAmbari blueprints are a declarative definition of a cluster. With a blueprint, you specify a stack, the component layout, and the configurations to materialize a Hadoop cluster instance via a REST API without having to use the Ambari cluster install wizard. \n\n\nCloudbreak supports any type of blueprints, which is a common source of errors. These errors are only visible once the core infrastructure is up and running and Cloudbreak tries to initiate the cluster installation through Ambari. Ambari validates the blueprint and  rejects it if it's invalid. \n\n\nFor example, if there are configurations for a certain service like Hive but Hive as a service is not mapped to any host group, the blueprint is invalid.\n\n\nTo fix these type of issues, edit your blueprint and then reinstall your cluster. Cloudbreak UI has support for this so the infrastructure does not have to be terminated.\n\n\nThere are some cases when Ambari cannot validate your blueprint beforehand. In these cases, the issues are only visible in the Ambari server logs. To trubleshoot, check Ambari server logs.\n\n\nBlueprints: High Availability\n\n\nCloudbreak always tries to validate that a blueprint not to include multiple master services into different host groups. However, this exact setup is required for HA clusters. To overcome this, you can disable blueprint validation in the UI, but you must include the necessary configurations.\n\n\n\n\n\n\n\n\n\n\nTO-DO: Where can you disable that in the UI? \n\n\n\n\n\n\n\n\n\n\nBlueprints: Wrong HDP Version\n\n\nIn the blueprint, only the major and minor HDP version should be defined (for example, \"2.6\"). If wrong version number is provided, the following error can be found in the logs:\n\n\n5/15/2017 12:23:19 PM testcluster26 - create failed: Cannot use the specified Ambari stack: HDPRepo\n{stack='null'; utils='null'}\n. Error: org.apache.ambari.server.controller.spi.NoSuchResourceException: The specified resource doesn't exist: Stack data, Stack HDP 2.6.0.3 is not found in Ambari metainfo\n\n\nFor correct blueprint layout, refer to the \nAmbari cwiki\n page.\n\n\nConnection Timeout: Ports Not Open\n\n\nIn the cluster installation wizard, you must specify on which node you want to run the Ambari server. Cloudbreak communicates with this node to orchestrate the installation.\n\n\nA common reason for connection timeout is security group misconfiguration. Cloudbreak allows configuring different security groups for the different instance groups; however, there are certain requirements for the Ambari server node. Specifically, the following ports must be open in order to communicate with that node:\n\n\n\n\n22 (SSH)  \n\n\n9443 (two-way-ssl through nginx)   \n\n\n\n\nRecipes: Recipe Execution Times Out\n\n\nIf the scripts are taking too much time to execute, the processes will time out, as the threshold for this is set to 15 minutes. To change this threashold, you must override the default value by adding the following to the cbd Profile file:\n\n\n\n\n\n\n\n\n\n\nTO-DO: 15 minutes for all scripts or for each script?\n\n\n\n\n\n\n\n\n\n\nexport CB_JAVA_OPTS=\u201d -Dcb.max.salt.recipe.execution.retry=90\u201d\n \n\n\nThis property indicates the number of tries for checking if the scripts have finished with a sleep time of 10 seconds. The default value is 90. To increase the threshold provide a number greater than 90. You must restart Cloudbreak after changing properties in the Profile file.\n\n\n\n\n\n\n\n\n\n\nTO-DO: you mean \"slip time of 10 seconds\"?\n\n\n\n\n\n\n\n\n\n\nRecipes: Recipe Execution Fails\n\n\nIt often happens that a script cannot be executed successfully because there are typos or errors in the script. To verify this you can check the recipe logs at\n\n/var/log/recipes\n. For each script, there will be a separate log file with the name of the script that you provided on the Cloudbreak UI.\n\n\nChanging Amari Credentials\n\n\nIn Cloudbreak versions earlier than 1.14 it is not possible to change the password in the Ambari UI. That is, if you change the admin credentials in the Ambari UI, Cloudbreak is no longer able to orchestrate Ambari. To change the password, you must use the Cloudbreak UI. \n\n\nCloudbreak 1.14 and later creates a new admin user in Ambari, so it\u2019s safe to change the credentials of the admin user. This credential can also be changed in the cluster installation wizard.\n\n\n\n\n\n\n\n\n\n\nTO-DO: Can you clarify this? In the first paragraph (Cloudbreak \n 1.14) you talk about users being unable to change password and then changing credentials. Do you just mean password or also admin user name? \nTO-DO: In the second paragraph (Cloudbreak \n=1.14), are we talking about the password or also user name? \n\n\n\n\n\n\n\n\n\n\nChanging Properties in the Cloudbreak Profile File\n\n\nThere are many properties that can be changed in the Cloudbreak application. These values must be changed in the Cloudbreak \nProfil\ne file. To see all possible options, use the following command:\n\ncbd env show\n.\n\n\nAfter changing a property, you must regenerate the config file and restart the application. There are two ways to do this:\n\n\nIn newer versions of the cbd command line, you can regenerate the config file and restart the application with a single command:\n\n\ncbd restart\n - same as cbd regenerate/kill/start.\n\n\n\n\n\n\n\n\n\n\nTO-DO: Starting with which version of cbd? \n\n\n\n\n\n\n\n\n\n\nIn older versions of the cbd command line, you must run the following three commands:\n\n\ncbd regenerate\n regenerates the Docker compose file\n\ncbd kill\n removes all Docker containers (there is no stop command for this).\n\ncbd start\n starts the application with the new compose file.\n\n\nInvalid PUBLIC_IP in CBD Profile\n\n\nThe \nPUBLIC_IP\n property must be set in the cbd Profile file or else you won\u2019t be able to log in on the Cloudbreak UI. \n\n\nIf you are migrating your instance, make sure that after the start the IP remains valid. If you need to edit the \nPUBLIC_IP\n property in Profile, make sure to restart Cloudbreak using \ncbd restart\n.", 
            "title": "General Troubleshooting"
        }, 
        {
            "location": "/trouble-cb/index.html#troubleshooting-cloudbreak", 
            "text": "", 
            "title": "Troubleshooting Cloudbreak"
        }, 
        {
            "location": "/trouble-cb/index.html#checking-the-logs", 
            "text": "When troubleshooting, you can access the following Cloudbreak logs.", 
            "title": "Checking the Logs"
        }, 
        {
            "location": "/trouble-cb/index.html#cloudbreak-logs", 
            "text": "When installing Cloudbreak using a pre-built cloud image, the  Cloudbreak Deployer location and the cbd root folder is  /var/lib/cloudbreak-deployment . You must execute all cbd actions from the cbd root folder as a cloudbreak user.    Your cbd root directory may be different if you installed Cloudbreak on your own VM.    Cloudbreak consists of multiple microservices deployed into Docker containers.   Aggregated Logs  To check aggregated service logs, use the following commands:  cbd logs  shows all service logs.  cbd logs | tee cloudbreak.log  allows you to redirect the input into a file for sharing these logs.  Individual Service Logs  To check individual service logs, use the following commands:  cbd logs cloudbreak  shows Cloudbreak logs. This service is the backend service that handles all deployments.  cbd logs uluwatu  shows Cloudbreak UI logs. Uluwatu is the UI component of Cloudbreak.  cbd logs identity  shows Identity logs. Identity is responsible for authentication and authorization.      TO-DO: Wasn't this previously called UAA? In teh Architecture section we call this component \"UAA\". Should I just call it \"Identity\" everywhere?       cbd logs periscope  shows Periscope logs. Periscope is responsible for triggering autoscaling rules.  Docker Logs  The same logs can be accessed via Docker commands:  docker logs cbreak_cloudbreak_1  shows the same logs as  cbd logs cloudbreak .  Cloudbreak logs are also rotated and can be accessed later from the Cloudbreak deployment folder.       TO-DO: I don't understand hat the sentence above means. Can you rephrase?      There is a symlink called  cbreak.log  which points to the latest log file. Sharing this symlink does not share the log itself.", 
            "title": "Cloudbreak Logs"
        }, 
        {
            "location": "/trouble-cb/index.html#saltstack-logs", 
            "text": "Cloudbreak uses Saltstack to install Ambari and the necessary packages for the HDP provisioning. Salt Master always runs alongside the Ambari Server node. Each instance in the cluster runs a Salt Minion, which connects to the Salt Master. There can be multiple Salt Masters if the cluster is configured to run in HA (High Availability) mode and in this case each Salt Minion connects to each Salt Master.  Cloudbreak also uses SaltStack to execute user-provided customization scripts called \"recipes\".   Salt Master and Salt Minion logs can be found at the following location:  /var/log/salt", 
            "title": "Saltstack Logs"
        }, 
        {
            "location": "/trouble-cb/index.html#ambari-logs", 
            "text": "Cloudbreak uses Ambari to orchestrate the installation of the different HDP components. Each instance in the cluster runs an Ambari agent which connects to the Ambari server. Ambari server is declared by the user during the cluster installation wizard.   Ambari Server Logs  Ambari server logs can be found in the following locations:  /var/log/ambari-server/ambari-server.log  /var/log/ambari-server/ambari-server.out  Both files contain important information about the root cause of a certain issue so it is advised to check both.  Ambari Agent Logs  Ambari agent logs can be found in the following locations:  /var/log/ambari-agent/ambari-agent.log", 
            "title": "Ambari Logs"
        }, 
        {
            "location": "/trouble-cb/index.html#recipe-logs", 
            "text": "Cloudbreak supports \"recipes\" - user-provided customization scripts that can be run prior to or after cluster installtion. It is the user\u2019s responsibility to provide an idempotent well tested script. However, if the execution fails, the recipe logs can be found at  /var/log/recipes .  It is advised, but not required to have an advanced logging mechanism in the script, as Cloudbreak always logs every script that are run. Recipes are often the sources of installation failures as users might try to remove necessary packages or reconfigure services.      TO-DO: Which of these logs are on the Cloudbreak node and which on the cluster nodes (and which specific nodes)?", 
            "title": "Recipe Logs"
        }, 
        {
            "location": "/trouble-cb/index.html#common-errors", 
            "text": "", 
            "title": "Common Errors"
        }, 
        {
            "location": "/trouble-cb/index.html#quota-limitations", 
            "text": "Each cloud provider has quota limitations on various cloud resources, and these quotas can usually be increased on request. If there is an error message in Cloudbreak saying that there are no more available EIPs (Elastic IP Address) or VPCs, you need to request more of these resources.   To see the limitations visit the cloud provider\u2019s site:   AWS Service Limits    Azure subscription and service limits, quotas, and constraints  GCP Resource Quotas", 
            "title": "Quota Limitations"
        }, 
        {
            "location": "/trouble-cb/index.html#blueprints-invalid-services-and-configurations", 
            "text": "Ambari blueprints are a declarative definition of a cluster. With a blueprint, you specify a stack, the component layout, and the configurations to materialize a Hadoop cluster instance via a REST API without having to use the Ambari cluster install wizard.   Cloudbreak supports any type of blueprints, which is a common source of errors. These errors are only visible once the core infrastructure is up and running and Cloudbreak tries to initiate the cluster installation through Ambari. Ambari validates the blueprint and  rejects it if it's invalid.   For example, if there are configurations for a certain service like Hive but Hive as a service is not mapped to any host group, the blueprint is invalid.  To fix these type of issues, edit your blueprint and then reinstall your cluster. Cloudbreak UI has support for this so the infrastructure does not have to be terminated.  There are some cases when Ambari cannot validate your blueprint beforehand. In these cases, the issues are only visible in the Ambari server logs. To trubleshoot, check Ambari server logs.", 
            "title": "Blueprints: Invalid Services and Configurations"
        }, 
        {
            "location": "/trouble-cb/index.html#blueprints-high-availability", 
            "text": "Cloudbreak always tries to validate that a blueprint not to include multiple master services into different host groups. However, this exact setup is required for HA clusters. To overcome this, you can disable blueprint validation in the UI, but you must include the necessary configurations.      TO-DO: Where can you disable that in the UI?", 
            "title": "Blueprints: High Availability"
        }, 
        {
            "location": "/trouble-cb/index.html#blueprints-wrong-hdp-version", 
            "text": "In the blueprint, only the major and minor HDP version should be defined (for example, \"2.6\"). If wrong version number is provided, the following error can be found in the logs:  5/15/2017 12:23:19 PM testcluster26 - create failed: Cannot use the specified Ambari stack: HDPRepo\n{stack='null'; utils='null'}\n. Error: org.apache.ambari.server.controller.spi.NoSuchResourceException: The specified resource doesn't exist: Stack data, Stack HDP 2.6.0.3 is not found in Ambari metainfo  For correct blueprint layout, refer to the  Ambari cwiki  page.", 
            "title": "Blueprints: Wrong HDP Version"
        }, 
        {
            "location": "/trouble-cb/index.html#connection-timeout-ports-not-open", 
            "text": "In the cluster installation wizard, you must specify on which node you want to run the Ambari server. Cloudbreak communicates with this node to orchestrate the installation.  A common reason for connection timeout is security group misconfiguration. Cloudbreak allows configuring different security groups for the different instance groups; however, there are certain requirements for the Ambari server node. Specifically, the following ports must be open in order to communicate with that node:   22 (SSH)    9443 (two-way-ssl through nginx)", 
            "title": "Connection Timeout: Ports Not Open"
        }, 
        {
            "location": "/trouble-cb/index.html#recipes-recipe-execution-times-out", 
            "text": "If the scripts are taking too much time to execute, the processes will time out, as the threshold for this is set to 15 minutes. To change this threashold, you must override the default value by adding the following to the cbd Profile file:      TO-DO: 15 minutes for all scripts or for each script?      export CB_JAVA_OPTS=\u201d -Dcb.max.salt.recipe.execution.retry=90\u201d    This property indicates the number of tries for checking if the scripts have finished with a sleep time of 10 seconds. The default value is 90. To increase the threshold provide a number greater than 90. You must restart Cloudbreak after changing properties in the Profile file.      TO-DO: you mean \"slip time of 10 seconds\"?", 
            "title": "Recipes: Recipe Execution Times Out"
        }, 
        {
            "location": "/trouble-cb/index.html#recipes-recipe-execution-fails", 
            "text": "It often happens that a script cannot be executed successfully because there are typos or errors in the script. To verify this you can check the recipe logs at /var/log/recipes . For each script, there will be a separate log file with the name of the script that you provided on the Cloudbreak UI.", 
            "title": "Recipes: Recipe Execution Fails"
        }, 
        {
            "location": "/trouble-cb/index.html#changing-amari-credentials", 
            "text": "In Cloudbreak versions earlier than 1.14 it is not possible to change the password in the Ambari UI. That is, if you change the admin credentials in the Ambari UI, Cloudbreak is no longer able to orchestrate Ambari. To change the password, you must use the Cloudbreak UI.   Cloudbreak 1.14 and later creates a new admin user in Ambari, so it\u2019s safe to change the credentials of the admin user. This credential can also be changed in the cluster installation wizard.      TO-DO: Can you clarify this? In the first paragraph (Cloudbreak   1.14) you talk about users being unable to change password and then changing credentials. Do you just mean password or also admin user name? \nTO-DO: In the second paragraph (Cloudbreak  =1.14), are we talking about the password or also user name?", 
            "title": "Changing Amari Credentials"
        }, 
        {
            "location": "/trouble-cb/index.html#changing-properties-in-the-cloudbreak-profile-file", 
            "text": "There are many properties that can be changed in the Cloudbreak application. These values must be changed in the Cloudbreak  Profil e file. To see all possible options, use the following command: cbd env show .  After changing a property, you must regenerate the config file and restart the application. There are two ways to do this:  In newer versions of the cbd command line, you can regenerate the config file and restart the application with a single command:  cbd restart  - same as cbd regenerate/kill/start.      TO-DO: Starting with which version of cbd?       In older versions of the cbd command line, you must run the following three commands:  cbd regenerate  regenerates the Docker compose file cbd kill  removes all Docker containers (there is no stop command for this). cbd start  starts the application with the new compose file.", 
            "title": "Changing Properties in the Cloudbreak Profile File"
        }, 
        {
            "location": "/trouble-cb/index.html#invalid-public_ip-in-cbd-profile", 
            "text": "The  PUBLIC_IP  property must be set in the cbd Profile file or else you won\u2019t be able to log in on the Cloudbreak UI.   If you are migrating your instance, make sure that after the start the IP remains valid. If you need to edit the  PUBLIC_IP  property in Profile, make sure to restart Cloudbreak using  cbd restart .", 
            "title": "Invalid PUBLIC_IP in CBD Profile"
        }, 
        {
            "location": "/trouble-aws/index.html", 
            "text": "Troubleshooting Cloudbreak on AWS", 
            "title": "Troubleshooting AWS"
        }, 
        {
            "location": "/trouble-aws/index.html#troubleshooting-cloudbreak-on-aws", 
            "text": "", 
            "title": "Troubleshooting Cloudbreak on AWS"
        }, 
        {
            "location": "/trouble-azure/index.html", 
            "text": "Troubleshooting Cloudbreak on Azure\n\n\nCredential Creation Errors\n\n\nRole already exists\n\n\nSymptom\n: You specified that you want to create a new role for Cloudbreak credential, but an existing role with the same name already exists in Azure.\n\n\n\n\nSolution\n: You should either rename the role during credential creation or select the \nReuse existing custom role\n option. \n\n\nRole does not exist\n\n\nSymptom\n: You specified that you want to reuse an existing role for your Cloudbreak credential, but that particular role does not exist in Azure.\n\n\n\n\nSolution\n: You should either rename the new role during the credential creation to match the existing role's name or select the \nLet Cloudbreak create a custom role\n option. \n\n\nRole does not have enough privileges\n\n\nSymptom\n: You specified that you want to reuse an  existing role for your Cloudbreak credential, but that particular role does not have the necessary privileges for Cloudbreak cluster management.\n\n\n\n\nSolution\n: You should either select an existing role with enough privileges or select the \nLet Cloudbreak create a custom role\n option.\n\n\nThe necessary action set for Cloudbreak to be able to manage the clusters includes:\n        \n\"Microsoft.Compute/*\",\n        \"Microsoft.Network/*\",\n        \"Microsoft.Storage/*\",\n        \"Microsoft.Resources/*\"\n\n\nCloud not validate publickey certificate\n\n\nSymptom\n: The syntax of your SSH public key is incorrect.\n\n\n\n\nSolution\n: You must correct the syntax of your SSH key. For information about the correct syntax, refer to \nthis\n page.", 
            "title": "Troubleshooting Azure"
        }, 
        {
            "location": "/trouble-azure/index.html#troubleshooting-cloudbreak-on-azure", 
            "text": "", 
            "title": "Troubleshooting Cloudbreak on Azure"
        }, 
        {
            "location": "/trouble-azure/index.html#credential-creation-errors", 
            "text": "", 
            "title": "Credential Creation Errors"
        }, 
        {
            "location": "/trouble-azure/index.html#role-already-exists", 
            "text": "Symptom : You specified that you want to create a new role for Cloudbreak credential, but an existing role with the same name already exists in Azure.   Solution : You should either rename the role during credential creation or select the  Reuse existing custom role  option.", 
            "title": "Role already exists"
        }, 
        {
            "location": "/trouble-azure/index.html#role-does-not-exist", 
            "text": "Symptom : You specified that you want to reuse an existing role for your Cloudbreak credential, but that particular role does not exist in Azure.   Solution : You should either rename the new role during the credential creation to match the existing role's name or select the  Let Cloudbreak create a custom role  option.", 
            "title": "Role does not exist"
        }, 
        {
            "location": "/trouble-azure/index.html#role-does-not-have-enough-privileges", 
            "text": "Symptom : You specified that you want to reuse an  existing role for your Cloudbreak credential, but that particular role does not have the necessary privileges for Cloudbreak cluster management.   Solution : You should either select an existing role with enough privileges or select the  Let Cloudbreak create a custom role  option.  The necessary action set for Cloudbreak to be able to manage the clusters includes:\n         \"Microsoft.Compute/*\",\n        \"Microsoft.Network/*\",\n        \"Microsoft.Storage/*\",\n        \"Microsoft.Resources/*\"", 
            "title": "Role does not have enough privileges"
        }, 
        {
            "location": "/trouble-azure/index.html#cloud-not-validate-publickey-certificate", 
            "text": "Symptom : The syntax of your SSH public key is incorrect.   Solution : You must correct the syntax of your SSH key. For information about the correct syntax, refer to  this  page.", 
            "title": "Cloud not validate publickey certificate"
        }, 
        {
            "location": "/trouble-gcp/index.html", 
            "text": "Troubleshooting Cloudbreak on GCP", 
            "title": "Troubleshooting GCP"
        }, 
        {
            "location": "/trouble-gcp/index.html#troubleshooting-cloudbreak-on-gcp", 
            "text": "", 
            "title": "Troubleshooting Cloudbreak on GCP"
        }, 
        {
            "location": "/trouble-os/index.html", 
            "text": "Troubleshooting Cloudbreak on OpenStack", 
            "title": "Troubleshooting OpenStack"
        }, 
        {
            "location": "/trouble-os/index.html#troubleshooting-cloudbreak-on-openstack", 
            "text": "", 
            "title": "Troubleshooting Cloudbreak on OpenStack"
        }, 
        {
            "location": "/get-help/index.html", 
            "text": "Get Help\n\n\nIf you need help with Cloudbreak, you have two options:\n\n\n\n\n\n\n\n\nOption\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nHortonworks Community Connection\n\n\nThis is free optional support via Hortonworks Community Connection (HCC).\n\n\n\n\n\n\nHortonworks Flex Support Subscription\n\n\nThis is paid Hortonworks enterprise support.\n\n\n\n\n\n\n\n\nHCC\n\n\nYou can optionally register for optional free community support at \nHortonworks Community Connection\n where you can browse articles and previously answered questions, and ask questions of your own. When posting questions related to Cloudbreak, make sure to use the \"Cloudbreak\" tag.\n\n\nFlex Subscription\n\n\nYou can optionally use your existing Hortonworks \nFlex subscription(s)\n to cover the Cloudbreak node and all clusters created. \n\n\nPrerequisites\n: You must have an existing SmartSense ID and a Flex subscription. For general information about the Hortonworks Flex Support Subscription, visit the Hortonworks Support page at \nhttps://hortonworks.com/services/support/enterprise/\n.\n\n\nThe general steps are:\n\n\n\n\nConfigure Smart Sense in your \nProfile\n file.   \n\n\nRegister your Flex subscription in the Cloudbreak web UI in the the \nmanage flex subscriptions\n pane. You can register and manage multiple Flex subscriptions.   \n\n\n\n\n\n\nAlternatively, you can perform these steps using the Cloudbreak Shell. \n\n\n\n\nConfiguring SmartSense\n\n\nTo configure SmartSense in Cloudbreak, enable SmartSense and add your SmartSense ID to the \nProfile\n by adding the following variables:\n\n\nexport CB_SMARTSENSE_CONFIGURE=true\nexport CB_SMARTSENSE_ID=YOUR-SMARTSENSE-ID\n\n\n\nFor example:\n\n\nexport CB_SMARTSENSE_CONFIGURE=true\nexport CB_SMARTSENSE_ID=A-00000000-C-00000000\n\n\n\nYou can do this in one of the two ways:\n\n\n\n\nWhen initiating Cloudbreak Deployer  \n\n\nAfter you've already initiated Cloudbreak Deployer. If you choose this option, you must restart Cloudbreak using \ncbd restart\n.\n\n\n\n\n\n\nSmartSense ID defined in the \nProfile\n file always overrides the ID registered via Cloudbreak Shell.\n\n\n\n\nManaging Flex Subscriptions\n\n\nOnce you log in to the Cloudbreak web UI, you can manage your Flex subscriptions from the \nmanage flex subscriptions\n pane. You can:\n\n\n\n\nRegister a new Flex subscription.  \n\n\nSet a default Flex subscription.  \n\n\nSelect a Flex subscription to be used for cloud controller.  \n\n\nDelete a Flex subscription.  \n\n\nCheck which clusters are connected to a specific subscription.  \n\n\n\n\nWhen creating a cluster using the advanced options, in the \nCONFIGURE CLUSTER\n \n \nFlex Subscriptions\n, you can select the Flex subscription that you want to use.\n\n\nMore Resources\n\n\nCheck out the following documentation to learn more:\n\n\n\n\n Resource \nDescription\n\n\nHortonworks documentation \n\n\nDuring cluster create process, Hortonworks Data Cloud automatically installs Ambari and sets up a cluster for you. After this deployment is complete, refer to the \nAmbari documentation\n and \nHDP documentation\n for help.\n\n\n\n\n\n\nHortonworks tutorials\n\n\n\n\nUse Hortonworks tutorials to get started with Apache Spark, Apache Hive, Apache Zeppelin, and more.\n\n\nApache documentation\n\n\n\n\n In addition to Hortonworks documentation, refer to the Apache Software Foundation documentation to get information on specific Hadoop services. \n\n\n\n\n\nAmbari Blueprints\nLearn about Ambari Bleuprints. Ambari Blueprints are a declarative definition of a Hadoop cluster that Ambari can use to create Hadoop clusters.\n\n\nCloudbreak Project\nVisit the Hortonworks website to see Cloudbreak-related news and updates.\n\n\nApache Ambari Project\nLearn about the Apache Ambari Project. Apache Ambari is an operational platform for provisioning, managing, and monitoring Apache Hadoop clusters. Ambari exposes a robust set of REST APIs and a rich web interface for cluster management.", 
            "title": "Getting Help"
        }, 
        {
            "location": "/get-help/index.html#get-help", 
            "text": "If you need help with Cloudbreak, you have two options:     Option  Description      Hortonworks Community Connection  This is free optional support via Hortonworks Community Connection (HCC).    Hortonworks Flex Support Subscription  This is paid Hortonworks enterprise support.", 
            "title": "Get Help"
        }, 
        {
            "location": "/get-help/index.html#hcc", 
            "text": "You can optionally register for optional free community support at  Hortonworks Community Connection  where you can browse articles and previously answered questions, and ask questions of your own. When posting questions related to Cloudbreak, make sure to use the \"Cloudbreak\" tag.", 
            "title": "HCC"
        }, 
        {
            "location": "/get-help/index.html#flex-subscription", 
            "text": "You can optionally use your existing Hortonworks  Flex subscription(s)  to cover the Cloudbreak node and all clusters created.   Prerequisites : You must have an existing SmartSense ID and a Flex subscription. For general information about the Hortonworks Flex Support Subscription, visit the Hortonworks Support page at  https://hortonworks.com/services/support/enterprise/ .  The general steps are:   Configure Smart Sense in your  Profile  file.     Register your Flex subscription in the Cloudbreak web UI in the the  manage flex subscriptions  pane. You can register and manage multiple Flex subscriptions.       Alternatively, you can perform these steps using the Cloudbreak Shell.", 
            "title": "Flex Subscription"
        }, 
        {
            "location": "/get-help/index.html#configuring-smartsense", 
            "text": "To configure SmartSense in Cloudbreak, enable SmartSense and add your SmartSense ID to the  Profile  by adding the following variables:  export CB_SMARTSENSE_CONFIGURE=true\nexport CB_SMARTSENSE_ID=YOUR-SMARTSENSE-ID  For example:  export CB_SMARTSENSE_CONFIGURE=true\nexport CB_SMARTSENSE_ID=A-00000000-C-00000000  You can do this in one of the two ways:   When initiating Cloudbreak Deployer    After you've already initiated Cloudbreak Deployer. If you choose this option, you must restart Cloudbreak using  cbd restart .    SmartSense ID defined in the  Profile  file always overrides the ID registered via Cloudbreak Shell.", 
            "title": "Configuring SmartSense"
        }, 
        {
            "location": "/get-help/index.html#managing-flex-subscriptions", 
            "text": "Once you log in to the Cloudbreak web UI, you can manage your Flex subscriptions from the  manage flex subscriptions  pane. You can:   Register a new Flex subscription.    Set a default Flex subscription.    Select a Flex subscription to be used for cloud controller.    Delete a Flex subscription.    Check which clusters are connected to a specific subscription.     When creating a cluster using the advanced options, in the  CONFIGURE CLUSTER     Flex Subscriptions , you can select the Flex subscription that you want to use.", 
            "title": "Managing Flex Subscriptions"
        }, 
        {
            "location": "/get-help/index.html#more-resources", 
            "text": "Check out the following documentation to learn more:    Resource  Description  Hortonworks documentation   During cluster create process, Hortonworks Data Cloud automatically installs Ambari and sets up a cluster for you. After this deployment is complete, refer to the  Ambari documentation  and  HDP documentation  for help.    Hortonworks tutorials   Use Hortonworks tutorials to get started with Apache Spark, Apache Hive, Apache Zeppelin, and more.  Apache documentation    In addition to Hortonworks documentation, refer to the Apache Software Foundation documentation to get information on specific Hadoop services.    Ambari Blueprints Learn about Ambari Bleuprints. Ambari Blueprints are a declarative definition of a Hadoop cluster that Ambari can use to create Hadoop clusters.  Cloudbreak Project Visit the Hortonworks website to see Cloudbreak-related news and updates.  Apache Ambari Project Learn about the Apache Ambari Project. Apache Ambari is an operational platform for provisioning, managing, and monitoring Apache Hadoop clusters. Ambari exposes a robust set of REST APIs and a rich web interface for cluster management.", 
            "title": "More Resources"
        }, 
        {
            "location": "/api/index.html", 
            "text": "Cloudbreak APIs\n\n\nCloudbreak is a RESTful application development platform whose goal is to help developers deploy HDP clusters in various cloud environments. Once Cloudbreak is deployed in your favorite servlet container, it exposes REST APIs, allowing you to spin up Hadoop clusters of any size with your chosen cloud provider.\n\n\nAPI Documentation\n\n\nThe Cloudbreak API documentation is available \nhere\n. \n\n\n\n\nThis documentation was generated from the code using \nSwagger\n.", 
            "title": "API"
        }, 
        {
            "location": "/api/index.html#cloudbreak-apis", 
            "text": "Cloudbreak is a RESTful application development platform whose goal is to help developers deploy HDP clusters in various cloud environments. Once Cloudbreak is deployed in your favorite servlet container, it exposes REST APIs, allowing you to spin up Hadoop clusters of any size with your chosen cloud provider.", 
            "title": "Cloudbreak APIs"
        }, 
        {
            "location": "/api/index.html#api-documentation", 
            "text": "The Cloudbreak API documentation is available  here .    This documentation was generated from the code using  Swagger .", 
            "title": "API Documentation"
        }, 
        {
            "location": "/spi/index.html", 
            "text": "SPI", 
            "title": "SPI"
        }, 
        {
            "location": "/spi/index.html#spi", 
            "text": "", 
            "title": "SPI"
        }, 
        {
            "location": "/flows/index.html", 
            "text": "Flows", 
            "title": "Flows"
        }, 
        {
            "location": "/flows/index.html#flows", 
            "text": "", 
            "title": "Flows"
        }
    ]
}